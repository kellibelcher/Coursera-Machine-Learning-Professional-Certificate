{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 5, Part d: Keras Intro LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "from keras.models  import Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set \n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('data/diabetes.csv', names=names, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>54</td>\n",
       "      <td>19</td>\n",
       "      <td>86</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.154</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>75</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.396</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>4</td>\n",
       "      <td>109</td>\n",
       "      <td>64</td>\n",
       "      <td>44</td>\n",
       "      <td>99</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.905</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>7</td>\n",
       "      <td>62</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.6</td>\n",
       "      <td>0.391</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.727</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "514               3                      99              54              19   \n",
       "74                1                      79              75              30   \n",
       "198               4                     109              64              44   \n",
       "76                7                      62              78               0   \n",
       "502               6                       0              68              41   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "514       86  25.6              0.154   24             0  \n",
       "74         0  32.0              0.396   22             0  \n",
       "198       99  34.8              0.905   26             1  \n",
       "76         0  32.6              0.391   41             0  \n",
       "502        0  39.0              0.727   41             1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise 1: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.760\n",
      "roc-auc is 0.837\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(12,input_shape = (8,),activation = 'sigmoid'))\n",
    "model_1.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                108       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?  \n",
    "Yes, to get the total parameters, we take the sum of the 108 parameters in the first dense layer, which come from the 8 input features + 1 bias term that are multiplied by the 12 units in that layer, plus the 13 parameters in the second dense layer, which come from the 12 units + 1 bias term in the first layer that connect to the final output unit.\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.9058 - accuracy: 0.3455 - val_loss: 0.8764 - val_accuracy: 0.3594\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8809 - accuracy: 0.3455 - val_loss: 0.8541 - val_accuracy: 0.3594\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8582 - accuracy: 0.3472 - val_loss: 0.8339 - val_accuracy: 0.3594\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8375 - accuracy: 0.3472 - val_loss: 0.8156 - val_accuracy: 0.3646\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8187 - accuracy: 0.3490 - val_loss: 0.7990 - val_accuracy: 0.3646\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8017 - accuracy: 0.3472 - val_loss: 0.7839 - val_accuracy: 0.3646\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7863 - accuracy: 0.3490 - val_loss: 0.7704 - val_accuracy: 0.3698\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7723 - accuracy: 0.3524 - val_loss: 0.7581 - val_accuracy: 0.3698\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7597 - accuracy: 0.3524 - val_loss: 0.7471 - val_accuracy: 0.3750\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7482 - accuracy: 0.3472 - val_loss: 0.7371 - val_accuracy: 0.3854\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7379 - accuracy: 0.3576 - val_loss: 0.7281 - val_accuracy: 0.3854\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7285 - accuracy: 0.3785 - val_loss: 0.7200 - val_accuracy: 0.3854\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7200 - accuracy: 0.3976 - val_loss: 0.7126 - val_accuracy: 0.4010\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7123 - accuracy: 0.4201 - val_loss: 0.7060 - val_accuracy: 0.4167\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7053 - accuracy: 0.4531 - val_loss: 0.7000 - val_accuracy: 0.4531\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6990 - accuracy: 0.4878 - val_loss: 0.6945 - val_accuracy: 0.4740\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5104 - val_loss: 0.6896 - val_accuracy: 0.5208\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.5503 - val_loss: 0.6852 - val_accuracy: 0.5625\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.5851 - val_loss: 0.6811 - val_accuracy: 0.5781\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6788 - accuracy: 0.6146 - val_loss: 0.6774 - val_accuracy: 0.5938\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.6267 - val_loss: 0.6740 - val_accuracy: 0.6146\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6712 - accuracy: 0.6354 - val_loss: 0.6709 - val_accuracy: 0.6198\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6678 - accuracy: 0.6406 - val_loss: 0.6681 - val_accuracy: 0.6406\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6647 - accuracy: 0.6372 - val_loss: 0.6655 - val_accuracy: 0.6667\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6618 - accuracy: 0.6424 - val_loss: 0.6630 - val_accuracy: 0.6771\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6592 - accuracy: 0.6458 - val_loss: 0.6608 - val_accuracy: 0.6719\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6568 - accuracy: 0.6493 - val_loss: 0.6588 - val_accuracy: 0.6667\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6545 - accuracy: 0.6545 - val_loss: 0.6568 - val_accuracy: 0.6615\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6523 - accuracy: 0.6562 - val_loss: 0.6551 - val_accuracy: 0.6667\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6504 - accuracy: 0.6649 - val_loss: 0.6534 - val_accuracy: 0.6823\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6485 - accuracy: 0.6649 - val_loss: 0.6518 - val_accuracy: 0.6771\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6684 - val_loss: 0.6504 - val_accuracy: 0.6719\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6451 - accuracy: 0.6649 - val_loss: 0.6490 - val_accuracy: 0.6719\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6436 - accuracy: 0.6632 - val_loss: 0.6477 - val_accuracy: 0.6719\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6421 - accuracy: 0.6649 - val_loss: 0.6464 - val_accuracy: 0.6719\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6407 - accuracy: 0.6649 - val_loss: 0.6452 - val_accuracy: 0.6719\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6394 - accuracy: 0.6684 - val_loss: 0.6441 - val_accuracy: 0.6719\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6381 - accuracy: 0.6667 - val_loss: 0.6430 - val_accuracy: 0.6719\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6369 - accuracy: 0.6649 - val_loss: 0.6420 - val_accuracy: 0.6667\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6357 - accuracy: 0.6649 - val_loss: 0.6410 - val_accuracy: 0.6667\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6346 - accuracy: 0.6649 - val_loss: 0.6400 - val_accuracy: 0.6667\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6335 - accuracy: 0.6649 - val_loss: 0.6391 - val_accuracy: 0.6667\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6325 - accuracy: 0.6632 - val_loss: 0.6381 - val_accuracy: 0.6615\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6315 - accuracy: 0.6580 - val_loss: 0.6373 - val_accuracy: 0.6510\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6305 - accuracy: 0.6580 - val_loss: 0.6364 - val_accuracy: 0.6510\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6295 - accuracy: 0.6580 - val_loss: 0.6356 - val_accuracy: 0.6510\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6286 - accuracy: 0.6580 - val_loss: 0.6347 - val_accuracy: 0.6510\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.6580 - val_loss: 0.6339 - val_accuracy: 0.6510\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6268 - accuracy: 0.6580 - val_loss: 0.6331 - val_accuracy: 0.6510\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6259 - accuracy: 0.6580 - val_loss: 0.6324 - val_accuracy: 0.6458\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6251 - accuracy: 0.6597 - val_loss: 0.6316 - val_accuracy: 0.6458\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6243 - accuracy: 0.6597 - val_loss: 0.6308 - val_accuracy: 0.6458\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6234 - accuracy: 0.6597 - val_loss: 0.6301 - val_accuracy: 0.6458\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.6597 - val_loss: 0.6294 - val_accuracy: 0.6458\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6219 - accuracy: 0.6597 - val_loss: 0.6286 - val_accuracy: 0.6458\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6211 - accuracy: 0.6597 - val_loss: 0.6279 - val_accuracy: 0.6458\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.6597 - val_loss: 0.6272 - val_accuracy: 0.6458\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6195 - accuracy: 0.6597 - val_loss: 0.6265 - val_accuracy: 0.6458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6188 - accuracy: 0.6597 - val_loss: 0.6258 - val_accuracy: 0.6458\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.6597 - val_loss: 0.6251 - val_accuracy: 0.6458\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6173 - accuracy: 0.6597 - val_loss: 0.6244 - val_accuracy: 0.6458\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6166 - accuracy: 0.6597 - val_loss: 0.6237 - val_accuracy: 0.6458\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6159 - accuracy: 0.6597 - val_loss: 0.6231 - val_accuracy: 0.6458\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6152 - accuracy: 0.6580 - val_loss: 0.6224 - val_accuracy: 0.6510\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6144 - accuracy: 0.6580 - val_loss: 0.6217 - val_accuracy: 0.6510\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6138 - accuracy: 0.6580 - val_loss: 0.6211 - val_accuracy: 0.6510\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6131 - accuracy: 0.6580 - val_loss: 0.6204 - val_accuracy: 0.6510\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6124 - accuracy: 0.6580 - val_loss: 0.6197 - val_accuracy: 0.6510\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6117 - accuracy: 0.6580 - val_loss: 0.6191 - val_accuracy: 0.6510\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6110 - accuracy: 0.6580 - val_loss: 0.6184 - val_accuracy: 0.6510\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6104 - accuracy: 0.6580 - val_loss: 0.6178 - val_accuracy: 0.6510\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.6580 - val_loss: 0.6171 - val_accuracy: 0.6510\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6090 - accuracy: 0.6580 - val_loss: 0.6165 - val_accuracy: 0.6510\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6083 - accuracy: 0.6580 - val_loss: 0.6159 - val_accuracy: 0.6510\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6077 - accuracy: 0.6580 - val_loss: 0.6152 - val_accuracy: 0.6510\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.6562 - val_loss: 0.6146 - val_accuracy: 0.6458\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6064 - accuracy: 0.6562 - val_loss: 0.6140 - val_accuracy: 0.6458\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6057 - accuracy: 0.6562 - val_loss: 0.6133 - val_accuracy: 0.6458\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.6545 - val_loss: 0.6127 - val_accuracy: 0.6458\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6044 - accuracy: 0.6545 - val_loss: 0.6121 - val_accuracy: 0.6458\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6038 - accuracy: 0.6562 - val_loss: 0.6115 - val_accuracy: 0.6458\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6032 - accuracy: 0.6562 - val_loss: 0.6109 - val_accuracy: 0.6458\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6026 - accuracy: 0.6562 - val_loss: 0.6102 - val_accuracy: 0.6458\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6019 - accuracy: 0.6562 - val_loss: 0.6096 - val_accuracy: 0.6458\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6013 - accuracy: 0.6562 - val_loss: 0.6090 - val_accuracy: 0.6458\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6007 - accuracy: 0.6562 - val_loss: 0.6084 - val_accuracy: 0.6458\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6001 - accuracy: 0.6562 - val_loss: 0.6078 - val_accuracy: 0.6458\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5995 - accuracy: 0.6562 - val_loss: 0.6072 - val_accuracy: 0.6458\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5988 - accuracy: 0.6562 - val_loss: 0.6066 - val_accuracy: 0.6458\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5982 - accuracy: 0.6562 - val_loss: 0.6060 - val_accuracy: 0.6458\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5976 - accuracy: 0.6580 - val_loss: 0.6054 - val_accuracy: 0.6458\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.6580 - val_loss: 0.6048 - val_accuracy: 0.6458\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5964 - accuracy: 0.6580 - val_loss: 0.6042 - val_accuracy: 0.6458\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.6580 - val_loss: 0.6036 - val_accuracy: 0.6458\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5952 - accuracy: 0.6580 - val_loss: 0.6030 - val_accuracy: 0.6458\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5946 - accuracy: 0.6580 - val_loss: 0.6025 - val_accuracy: 0.6458\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5941 - accuracy: 0.6580 - val_loss: 0.6019 - val_accuracy: 0.6510\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5935 - accuracy: 0.6580 - val_loss: 0.6013 - val_accuracy: 0.6510\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5929 - accuracy: 0.6580 - val_loss: 0.6007 - val_accuracy: 0.6562\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5923 - accuracy: 0.6580 - val_loss: 0.6001 - val_accuracy: 0.6562\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5917 - accuracy: 0.6597 - val_loss: 0.5996 - val_accuracy: 0.6562\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5911 - accuracy: 0.6580 - val_loss: 0.5990 - val_accuracy: 0.6562\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5906 - accuracy: 0.6580 - val_loss: 0.5984 - val_accuracy: 0.6562\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5900 - accuracy: 0.6615 - val_loss: 0.5979 - val_accuracy: 0.6562\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.6615 - val_loss: 0.5973 - val_accuracy: 0.6562\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5888 - accuracy: 0.6632 - val_loss: 0.5967 - val_accuracy: 0.6562\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5883 - accuracy: 0.6649 - val_loss: 0.5962 - val_accuracy: 0.6562\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5877 - accuracy: 0.6649 - val_loss: 0.5956 - val_accuracy: 0.6562\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 0.6667 - val_loss: 0.5951 - val_accuracy: 0.6615\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5866 - accuracy: 0.6667 - val_loss: 0.5945 - val_accuracy: 0.6615\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5860 - accuracy: 0.6667 - val_loss: 0.5940 - val_accuracy: 0.6615\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5855 - accuracy: 0.6667 - val_loss: 0.5934 - val_accuracy: 0.6615\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.6667 - val_loss: 0.5929 - val_accuracy: 0.6615\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5844 - accuracy: 0.6701 - val_loss: 0.5923 - val_accuracy: 0.6615\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5838 - accuracy: 0.6719 - val_loss: 0.5918 - val_accuracy: 0.6615\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5833 - accuracy: 0.6719 - val_loss: 0.5912 - val_accuracy: 0.6615\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.6719 - val_loss: 0.5907 - val_accuracy: 0.6615\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.6719 - val_loss: 0.5902 - val_accuracy: 0.6615\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.6719 - val_loss: 0.5896 - val_accuracy: 0.6615\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.6719 - val_loss: 0.5891 - val_accuracy: 0.6615\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.6719 - val_loss: 0.5886 - val_accuracy: 0.6615\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5800 - accuracy: 0.6736 - val_loss: 0.5880 - val_accuracy: 0.6667\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.6736 - val_loss: 0.5875 - val_accuracy: 0.6719\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5790 - accuracy: 0.6736 - val_loss: 0.5870 - val_accuracy: 0.6719\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.6736 - val_loss: 0.5865 - val_accuracy: 0.6719\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.6736 - val_loss: 0.5860 - val_accuracy: 0.6719\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.6753 - val_loss: 0.5854 - val_accuracy: 0.6719\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.6788 - val_loss: 0.5849 - val_accuracy: 0.6719\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5764 - accuracy: 0.6806 - val_loss: 0.5844 - val_accuracy: 0.6771\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5758 - accuracy: 0.6806 - val_loss: 0.5839 - val_accuracy: 0.6771\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5754 - accuracy: 0.6840 - val_loss: 0.5834 - val_accuracy: 0.6771\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5748 - accuracy: 0.6858 - val_loss: 0.5829 - val_accuracy: 0.6771\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.6858 - val_loss: 0.5824 - val_accuracy: 0.6771\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5738 - accuracy: 0.6875 - val_loss: 0.5819 - val_accuracy: 0.6771\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 0.6875 - val_loss: 0.5814 - val_accuracy: 0.6875\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5728 - accuracy: 0.6875 - val_loss: 0.5809 - val_accuracy: 0.6875\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5723 - accuracy: 0.6875 - val_loss: 0.5804 - val_accuracy: 0.6927\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5718 - accuracy: 0.6875 - val_loss: 0.5799 - val_accuracy: 0.6927\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.6875 - val_loss: 0.5794 - val_accuracy: 0.6927\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5708 - accuracy: 0.6892 - val_loss: 0.5789 - val_accuracy: 0.6927\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.6910 - val_loss: 0.5784 - val_accuracy: 0.6875\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5698 - accuracy: 0.6927 - val_loss: 0.5780 - val_accuracy: 0.6875\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.6927 - val_loss: 0.5775 - val_accuracy: 0.6875\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.6944 - val_loss: 0.5770 - val_accuracy: 0.6875\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.6944 - val_loss: 0.5765 - val_accuracy: 0.6875\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5679 - accuracy: 0.6944 - val_loss: 0.5760 - val_accuracy: 0.6875\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5674 - accuracy: 0.6944 - val_loss: 0.5756 - val_accuracy: 0.6875\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.6944 - val_loss: 0.5751 - val_accuracy: 0.6875\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.6962 - val_loss: 0.5746 - val_accuracy: 0.6875\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.6962 - val_loss: 0.5742 - val_accuracy: 0.6927\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5655 - accuracy: 0.6962 - val_loss: 0.5737 - val_accuracy: 0.6927\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5650 - accuracy: 0.6962 - val_loss: 0.5732 - val_accuracy: 0.6927\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.6962 - val_loss: 0.5728 - val_accuracy: 0.6927\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.6927 - val_loss: 0.5723 - val_accuracy: 0.6979\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.6927 - val_loss: 0.5718 - val_accuracy: 0.6979\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.6927 - val_loss: 0.5714 - val_accuracy: 0.7031\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.6962 - val_loss: 0.5709 - val_accuracy: 0.7031\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.6997 - val_loss: 0.5705 - val_accuracy: 0.7083\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.7014 - val_loss: 0.5700 - val_accuracy: 0.7031\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.7014 - val_loss: 0.5696 - val_accuracy: 0.7083\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.6997 - val_loss: 0.5691 - val_accuracy: 0.7083\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.7014 - val_loss: 0.5687 - val_accuracy: 0.7135\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.6997 - val_loss: 0.5683 - val_accuracy: 0.7135\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.5678 - val_accuracy: 0.7135\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.6997 - val_loss: 0.5674 - val_accuracy: 0.7188\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5586 - accuracy: 0.7014 - val_loss: 0.5669 - val_accuracy: 0.7240\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.7014 - val_loss: 0.5665 - val_accuracy: 0.7240\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7014 - val_loss: 0.5661 - val_accuracy: 0.7240\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.7031 - val_loss: 0.5656 - val_accuracy: 0.7240\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.7031 - val_loss: 0.5652 - val_accuracy: 0.7240\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7014 - val_loss: 0.5648 - val_accuracy: 0.7240\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.7031 - val_loss: 0.5644 - val_accuracy: 0.7240\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.7031 - val_loss: 0.5639 - val_accuracy: 0.7240\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7049 - val_loss: 0.5635 - val_accuracy: 0.7240\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7049 - val_loss: 0.5631 - val_accuracy: 0.7240\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.7049 - val_loss: 0.5627 - val_accuracy: 0.7240\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.7049 - val_loss: 0.5623 - val_accuracy: 0.7240\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5534 - accuracy: 0.7066 - val_loss: 0.5619 - val_accuracy: 0.7240\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5530 - accuracy: 0.7066 - val_loss: 0.5615 - val_accuracy: 0.7240\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5526 - accuracy: 0.7066 - val_loss: 0.5610 - val_accuracy: 0.7240\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.7083 - val_loss: 0.5606 - val_accuracy: 0.7240\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7101 - val_loss: 0.5602 - val_accuracy: 0.7240\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.7101 - val_loss: 0.5598 - val_accuracy: 0.7292\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7101 - val_loss: 0.5594 - val_accuracy: 0.7292\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7101 - val_loss: 0.5590 - val_accuracy: 0.7292\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.7118 - val_loss: 0.5586 - val_accuracy: 0.7292\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7118 - val_loss: 0.5582 - val_accuracy: 0.7292\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7118 - val_loss: 0.5578 - val_accuracy: 0.7292\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7118 - val_loss: 0.5574 - val_accuracy: 0.7292\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.7135 - val_loss: 0.5571 - val_accuracy: 0.7292\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.7135 - val_loss: 0.5567 - val_accuracy: 0.7344\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7153 - val_loss: 0.5563 - val_accuracy: 0.7344\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7170 - val_loss: 0.5559 - val_accuracy: 0.7344\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5469 - accuracy: 0.7170 - val_loss: 0.5555 - val_accuracy: 0.7396\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7188 - val_loss: 0.5551 - val_accuracy: 0.7396\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7205 - val_loss: 0.5548 - val_accuracy: 0.7448\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7205 - val_loss: 0.5544 - val_accuracy: 0.7500\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7205 - val_loss: 0.5540 - val_accuracy: 0.7500\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7222 - val_loss: 0.5536 - val_accuracy: 0.7500\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.7222 - val_loss: 0.5532 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)\n",
    "y_pred_class_nn_1 = (y_pred_prob_nn_1>0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4441683 ],\n",
       "       [0.55444354],\n",
       "       [0.33428407],\n",
       "       [0.3048895 ],\n",
       "       [0.285208  ],\n",
       "       [0.45386174],\n",
       "       [0.21710032],\n",
       "       [0.3900144 ],\n",
       "       [0.58346474],\n",
       "       [0.29577732]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.750\n",
      "roc-auc is 0.811\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x22f86cfd790>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7240 - val_loss: 0.5529 - val_accuracy: 0.7500\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7240 - val_loss: 0.5525 - val_accuracy: 0.7552\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7257 - val_loss: 0.5521 - val_accuracy: 0.7552\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5431 - accuracy: 0.7257 - val_loss: 0.5518 - val_accuracy: 0.7500\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7274 - val_loss: 0.5514 - val_accuracy: 0.7500\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7257 - val_loss: 0.5511 - val_accuracy: 0.7500\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7240 - val_loss: 0.5507 - val_accuracy: 0.7500\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7240 - val_loss: 0.5503 - val_accuracy: 0.7500\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5412 - accuracy: 0.7240 - val_loss: 0.5500 - val_accuracy: 0.7500\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7257 - val_loss: 0.5496 - val_accuracy: 0.7500\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7257 - val_loss: 0.5493 - val_accuracy: 0.7500\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7257 - val_loss: 0.5489 - val_accuracy: 0.7448\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.7274 - val_loss: 0.5486 - val_accuracy: 0.7448\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7326 - val_loss: 0.5482 - val_accuracy: 0.7448\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7326 - val_loss: 0.5479 - val_accuracy: 0.7448\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7344 - val_loss: 0.5475 - val_accuracy: 0.7448\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.7361 - val_loss: 0.5472 - val_accuracy: 0.7448\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7326 - val_loss: 0.5468 - val_accuracy: 0.7448\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7344 - val_loss: 0.5465 - val_accuracy: 0.7448\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7361 - val_loss: 0.5462 - val_accuracy: 0.7448\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7361 - val_loss: 0.5458 - val_accuracy: 0.7448\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7361 - val_loss: 0.5455 - val_accuracy: 0.7448\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7344 - val_loss: 0.5452 - val_accuracy: 0.7448\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7344 - val_loss: 0.5448 - val_accuracy: 0.7448\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7344 - val_loss: 0.5445 - val_accuracy: 0.7448\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7361 - val_loss: 0.5442 - val_accuracy: 0.7448\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7361 - val_loss: 0.5438 - val_accuracy: 0.7396\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7361 - val_loss: 0.5435 - val_accuracy: 0.7396\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7378 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.7378 - val_loss: 0.5429 - val_accuracy: 0.7448\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7378 - val_loss: 0.5426 - val_accuracy: 0.7448\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.7378 - val_loss: 0.5422 - val_accuracy: 0.7448\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.7378 - val_loss: 0.5419 - val_accuracy: 0.7448\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7344 - val_loss: 0.5416 - val_accuracy: 0.7448\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.7361 - val_loss: 0.5413 - val_accuracy: 0.7500\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7344 - val_loss: 0.5410 - val_accuracy: 0.7500\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7326 - val_loss: 0.5407 - val_accuracy: 0.7500\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7344 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7344 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7361 - val_loss: 0.5397 - val_accuracy: 0.7552\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7378 - val_loss: 0.5394 - val_accuracy: 0.7552\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7361 - val_loss: 0.5391 - val_accuracy: 0.7552\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7378 - val_loss: 0.5388 - val_accuracy: 0.7552\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7413 - val_loss: 0.5385 - val_accuracy: 0.7552\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7396 - val_loss: 0.5382 - val_accuracy: 0.7604\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7413 - val_loss: 0.5379 - val_accuracy: 0.7604\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7413 - val_loss: 0.5376 - val_accuracy: 0.7552\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7413 - val_loss: 0.5373 - val_accuracy: 0.7552\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7413 - val_loss: 0.5371 - val_accuracy: 0.7552\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7448 - val_loss: 0.5368 - val_accuracy: 0.7552\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7431 - val_loss: 0.5365 - val_accuracy: 0.7552\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7448 - val_loss: 0.5362 - val_accuracy: 0.7552\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7448 - val_loss: 0.5359 - val_accuracy: 0.7552\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.7448 - val_loss: 0.5356 - val_accuracy: 0.7552\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7465 - val_loss: 0.5353 - val_accuracy: 0.7552\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7500 - val_loss: 0.5351 - val_accuracy: 0.7552\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7483 - val_loss: 0.5348 - val_accuracy: 0.7500\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7500 - val_loss: 0.5345 - val_accuracy: 0.7500\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.7500 - val_loss: 0.5342 - val_accuracy: 0.7500\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7500 - val_loss: 0.5339 - val_accuracy: 0.7500\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7500 - val_loss: 0.5337 - val_accuracy: 0.7500\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7500 - val_loss: 0.5334 - val_accuracy: 0.7500\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7500 - val_loss: 0.5331 - val_accuracy: 0.7500\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7483 - val_loss: 0.5328 - val_accuracy: 0.7500\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.7483 - val_loss: 0.5326 - val_accuracy: 0.7448\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7465 - val_loss: 0.5323 - val_accuracy: 0.7448\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7465 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7465 - val_loss: 0.5318 - val_accuracy: 0.7448\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7465 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7448 - val_loss: 0.5313 - val_accuracy: 0.7500\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7465 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7431 - val_loss: 0.5307 - val_accuracy: 0.7500\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7448 - val_loss: 0.5305 - val_accuracy: 0.7552\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7465 - val_loss: 0.5302 - val_accuracy: 0.7552\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7448 - val_loss: 0.5300 - val_accuracy: 0.7552\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7465 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7465 - val_loss: 0.5295 - val_accuracy: 0.7500\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7465 - val_loss: 0.5292 - val_accuracy: 0.7500\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7465 - val_loss: 0.5290 - val_accuracy: 0.7500\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7465 - val_loss: 0.5287 - val_accuracy: 0.7500\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7465 - val_loss: 0.5285 - val_accuracy: 0.7500\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7483 - val_loss: 0.5282 - val_accuracy: 0.7500\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7465 - val_loss: 0.5280 - val_accuracy: 0.7500\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7500 - val_loss: 0.5277 - val_accuracy: 0.7552\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7500 - val_loss: 0.5275 - val_accuracy: 0.7500\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7500 - val_loss: 0.5272 - val_accuracy: 0.7552\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7500 - val_loss: 0.5270 - val_accuracy: 0.7552\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7535 - val_loss: 0.5268 - val_accuracy: 0.7552\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7483 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7500 - val_loss: 0.5263 - val_accuracy: 0.7552\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7483 - val_loss: 0.5261 - val_accuracy: 0.7552\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7500 - val_loss: 0.5258 - val_accuracy: 0.7552\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7500 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7517 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7517 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7517 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7500 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7517 - val_loss: 0.5245 - val_accuracy: 0.7552\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7517 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7517 - val_loss: 0.5240 - val_accuracy: 0.7604\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7517 - val_loss: 0.5238 - val_accuracy: 0.7604\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7517 - val_loss: 0.5236 - val_accuracy: 0.7604\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7517 - val_loss: 0.5233 - val_accuracy: 0.7604\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7535 - val_loss: 0.5231 - val_accuracy: 0.7604\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7535 - val_loss: 0.5229 - val_accuracy: 0.7604\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7535 - val_loss: 0.5227 - val_accuracy: 0.7604\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7552 - val_loss: 0.5225 - val_accuracy: 0.7604\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7552 - val_loss: 0.5223 - val_accuracy: 0.7604\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7552 - val_loss: 0.5220 - val_accuracy: 0.7604\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7552 - val_loss: 0.5218 - val_accuracy: 0.7604\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7535 - val_loss: 0.5216 - val_accuracy: 0.7604\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7569 - val_loss: 0.5214 - val_accuracy: 0.7604\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7569 - val_loss: 0.5212 - val_accuracy: 0.7604\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7569 - val_loss: 0.5210 - val_accuracy: 0.7604\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7569 - val_loss: 0.5208 - val_accuracy: 0.7604\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7569 - val_loss: 0.5206 - val_accuracy: 0.7604\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7569 - val_loss: 0.5204 - val_accuracy: 0.7604\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7569 - val_loss: 0.5202 - val_accuracy: 0.7656\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7569 - val_loss: 0.5200 - val_accuracy: 0.7656\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7569 - val_loss: 0.5198 - val_accuracy: 0.7656\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7569 - val_loss: 0.5196 - val_accuracy: 0.7656\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7569 - val_loss: 0.5194 - val_accuracy: 0.7656\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7569 - val_loss: 0.5192 - val_accuracy: 0.7656\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7569 - val_loss: 0.5190 - val_accuracy: 0.7656\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7569 - val_loss: 0.5188 - val_accuracy: 0.7656\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7569 - val_loss: 0.5186 - val_accuracy: 0.7656\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7569 - val_loss: 0.5184 - val_accuracy: 0.7656\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7569 - val_loss: 0.5182 - val_accuracy: 0.7656\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7569 - val_loss: 0.5180 - val_accuracy: 0.7656\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7569 - val_loss: 0.5178 - val_accuracy: 0.7656\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7569 - val_loss: 0.5176 - val_accuracy: 0.7656\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7569 - val_loss: 0.5175 - val_accuracy: 0.7708\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7569 - val_loss: 0.5173 - val_accuracy: 0.7708\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7569 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7587 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7587 - val_loss: 0.5167 - val_accuracy: 0.7708\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7587 - val_loss: 0.5165 - val_accuracy: 0.7708\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7587 - val_loss: 0.5164 - val_accuracy: 0.7708\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7587 - val_loss: 0.5162 - val_accuracy: 0.7708\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7587 - val_loss: 0.5160 - val_accuracy: 0.7708\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7587 - val_loss: 0.5158 - val_accuracy: 0.7708\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7587 - val_loss: 0.5156 - val_accuracy: 0.7708\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7622 - val_loss: 0.5155 - val_accuracy: 0.7708\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7622 - val_loss: 0.5153 - val_accuracy: 0.7708\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7639 - val_loss: 0.5151 - val_accuracy: 0.7708\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7639 - val_loss: 0.5149 - val_accuracy: 0.7708\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7639 - val_loss: 0.5148 - val_accuracy: 0.7708\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7639 - val_loss: 0.5146 - val_accuracy: 0.7708\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7656 - val_loss: 0.5144 - val_accuracy: 0.7708\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7656 - val_loss: 0.5143 - val_accuracy: 0.7708\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7656 - val_loss: 0.5141 - val_accuracy: 0.7708\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7656 - val_loss: 0.5139 - val_accuracy: 0.7708\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7656 - val_loss: 0.5137 - val_accuracy: 0.7708\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7656 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7639 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7656 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7656 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7639 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7656 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.7639 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7639 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7656 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7656 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7656 - val_loss: 0.5120 - val_accuracy: 0.7656\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7656 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.7656 - val_loss: 0.5116 - val_accuracy: 0.7656\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7656 - val_loss: 0.5115 - val_accuracy: 0.7656\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7656 - val_loss: 0.5113 - val_accuracy: 0.7656\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4997 - accuracy: 0.7656 - val_loss: 0.5112 - val_accuracy: 0.7656\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7656 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7656 - val_loss: 0.5109 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.7639 - val_loss: 0.5107 - val_accuracy: 0.7656\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7639 - val_loss: 0.5106 - val_accuracy: 0.7656\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.7639 - val_loss: 0.5104 - val_accuracy: 0.7656\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.7639 - val_loss: 0.5103 - val_accuracy: 0.7656\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7639 - val_loss: 0.5101 - val_accuracy: 0.7656\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7656 - val_loss: 0.5100 - val_accuracy: 0.7656\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7656 - val_loss: 0.5098 - val_accuracy: 0.7656\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.7656 - val_loss: 0.5097 - val_accuracy: 0.7656\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.7656 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7656 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.7656 - val_loss: 0.5093 - val_accuracy: 0.7708\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7656 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7639 - val_loss: 0.5090 - val_accuracy: 0.7708\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.7656 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.7674 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7656 - val_loss: 0.5086 - val_accuracy: 0.7708\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.7674 - val_loss: 0.5084 - val_accuracy: 0.7708\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.7691 - val_loss: 0.5083 - val_accuracy: 0.7708\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.7674 - val_loss: 0.5082 - val_accuracy: 0.7708\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7674 - val_loss: 0.5080 - val_accuracy: 0.7708\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7691 - val_loss: 0.5079 - val_accuracy: 0.7708\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.7691 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.7674 - val_loss: 0.5076 - val_accuracy: 0.7708\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.7674 - val_loss: 0.5075 - val_accuracy: 0.7708\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7691 - val_loss: 0.5074 - val_accuracy: 0.7708\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.7691 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7691 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.7691 - val_loss: 0.5070 - val_accuracy: 0.7708\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7691 - val_loss: 0.5068 - val_accuracy: 0.7656\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7674 - val_loss: 0.5067 - val_accuracy: 0.7656\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.7674 - val_loss: 0.5066 - val_accuracy: 0.7656\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7691 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7656 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7691 - val_loss: 0.5062 - val_accuracy: 0.7656\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.7656 - val_loss: 0.5061 - val_accuracy: 0.7656\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.7656 - val_loss: 0.5059 - val_accuracy: 0.7708\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.7656 - val_loss: 0.5058 - val_accuracy: 0.7708\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7656 - val_loss: 0.5057 - val_accuracy: 0.7708\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7656 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4932 - accuracy: 0.7656 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7656 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7656 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7674 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7656 - val_loss: 0.5050 - val_accuracy: 0.7708\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7639 - val_loss: 0.5049 - val_accuracy: 0.7708\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7639 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7639 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7639 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.7639 - val_loss: 0.5044 - val_accuracy: 0.7708\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.7639 - val_loss: 0.5043 - val_accuracy: 0.7708\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7639 - val_loss: 0.5042 - val_accuracy: 0.7708\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.7639 - val_loss: 0.5040 - val_accuracy: 0.7708\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7656 - val_loss: 0.5039 - val_accuracy: 0.7708\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7639 - val_loss: 0.5038 - val_accuracy: 0.7708\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7639 - val_loss: 0.5037 - val_accuracy: 0.7708\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7639 - val_loss: 0.5036 - val_accuracy: 0.7708\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7639 - val_loss: 0.5035 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.7639 - val_loss: 0.5034 - val_accuracy: 0.7708\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.7656 - val_loss: 0.5033 - val_accuracy: 0.7708\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.7656 - val_loss: 0.5032 - val_accuracy: 0.7708\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7656 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7656 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.7656 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7656 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7656 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.7656 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7656 - val_loss: 0.5024 - val_accuracy: 0.7708\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7656 - val_loss: 0.5023 - val_accuracy: 0.7708\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7656 - val_loss: 0.5022 - val_accuracy: 0.7708\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7656 - val_loss: 0.5021 - val_accuracy: 0.7708\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7656 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7656 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7674 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.7674 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7674 - val_loss: 0.5016 - val_accuracy: 0.7708\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7674 - val_loss: 0.5015 - val_accuracy: 0.7708\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.7656 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7656 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.7656 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.7656 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.7656 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7674 - val_loss: 0.5009 - val_accuracy: 0.7708\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7639 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7656 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.7674 - val_loss: 0.5006 - val_accuracy: 0.7708\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7656 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.7656 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7674 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7674 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7674 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7656 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7656 - val_loss: 0.5000 - val_accuracy: 0.7708\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7674 - val_loss: 0.4999 - val_accuracy: 0.7708\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7674 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7656 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7656 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.7656 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.7656 - val_loss: 0.4994 - val_accuracy: 0.7708\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7656 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7674 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7674 - val_loss: 0.4992 - val_accuracy: 0.7708\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7656 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7674 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7656 - val_loss: 0.4989 - val_accuracy: 0.7708\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.7656 - val_loss: 0.4988 - val_accuracy: 0.7708\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7656 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7656 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7656 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7656 - val_loss: 0.4985 - val_accuracy: 0.7708\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7656 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7656 - val_loss: 0.4983 - val_accuracy: 0.7708\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7639 - val_loss: 0.4982 - val_accuracy: 0.7708\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7656 - val_loss: 0.4982 - val_accuracy: 0.7708\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7656 - val_loss: 0.4981 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7656 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7639 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7639 - val_loss: 0.4978 - val_accuracy: 0.7708\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7639 - val_loss: 0.4978 - val_accuracy: 0.7708\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7656 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7674 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7656 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7691 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7674 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7674 - val_loss: 0.4973 - val_accuracy: 0.7708\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7674 - val_loss: 0.4972 - val_accuracy: 0.7708\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.7656 - val_loss: 0.4971 - val_accuracy: 0.7708\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7656 - val_loss: 0.4971 - val_accuracy: 0.7708\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7656 - val_loss: 0.4970 - val_accuracy: 0.7708\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7691 - val_loss: 0.4969 - val_accuracy: 0.7708\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7656 - val_loss: 0.4968 - val_accuracy: 0.7708\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7674 - val_loss: 0.4968 - val_accuracy: 0.7708\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7656 - val_loss: 0.4967 - val_accuracy: 0.7708\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7656 - val_loss: 0.4966 - val_accuracy: 0.7708\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7656 - val_loss: 0.4965 - val_accuracy: 0.7708\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7656 - val_loss: 0.4965 - val_accuracy: 0.7708\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7674 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7656 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4821 - accuracy: 0.7656 - val_loss: 0.4962 - val_accuracy: 0.7708\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7656 - val_loss: 0.4962 - val_accuracy: 0.7708\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7656 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7656 - val_loss: 0.4960 - val_accuracy: 0.7708\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7656 - val_loss: 0.4960 - val_accuracy: 0.7708\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7674 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7656 - val_loss: 0.4958 - val_accuracy: 0.7708\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7656 - val_loss: 0.4958 - val_accuracy: 0.7708\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7674 - val_loss: 0.4957 - val_accuracy: 0.7708\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7656 - val_loss: 0.4956 - val_accuracy: 0.7708\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7656 - val_loss: 0.4956 - val_accuracy: 0.7708\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7656 - val_loss: 0.4955 - val_accuracy: 0.7708\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7674 - val_loss: 0.4954 - val_accuracy: 0.7708\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7656 - val_loss: 0.4954 - val_accuracy: 0.7708\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7656 - val_loss: 0.4953 - val_accuracy: 0.7708\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7656 - val_loss: 0.4952 - val_accuracy: 0.7708\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7674 - val_loss: 0.4952 - val_accuracy: 0.7656\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7639 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7656 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7656 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7674 - val_loss: 0.4949 - val_accuracy: 0.7656\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7674 - val_loss: 0.4948 - val_accuracy: 0.7656\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7674 - val_loss: 0.4948 - val_accuracy: 0.7656\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7656 - val_loss: 0.4947 - val_accuracy: 0.7656\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7674 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7674 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7656 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7656 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7691 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7674 - val_loss: 0.4943 - val_accuracy: 0.7656\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7726 - val_loss: 0.4943 - val_accuracy: 0.7656\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7691 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7691 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7708 - val_loss: 0.4941 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7708 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7708 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7674 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7691 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7726 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7726 - val_loss: 0.4937 - val_accuracy: 0.7604\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7726 - val_loss: 0.4937 - val_accuracy: 0.7604\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7708 - val_loss: 0.4936 - val_accuracy: 0.7604\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7691 - val_loss: 0.4936 - val_accuracy: 0.7604\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7726 - val_loss: 0.4935 - val_accuracy: 0.7604\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7708 - val_loss: 0.4935 - val_accuracy: 0.7604\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7708 - val_loss: 0.4934 - val_accuracy: 0.7604\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7726 - val_loss: 0.4933 - val_accuracy: 0.7604\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7743 - val_loss: 0.4933 - val_accuracy: 0.7604\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7743 - val_loss: 0.4932 - val_accuracy: 0.7604\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7743 - val_loss: 0.4932 - val_accuracy: 0.7604\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7726 - val_loss: 0.4931 - val_accuracy: 0.7604\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7760 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7778 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7778 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7760 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7760 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7778 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7743 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7760 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7760 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7778 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7760 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.7778 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7760 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7760 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7778 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7778 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7760 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7778 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7795 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7795 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7795 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7778 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7778 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7760 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7778 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7795 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7795 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7778 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7778 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7778 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7795 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7778 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7778 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7778 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7778 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7778 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7778 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7795 - val_loss: 0.4912 - val_accuracy: 0.7552\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7778 - val_loss: 0.4912 - val_accuracy: 0.7552\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7778 - val_loss: 0.4911 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7778 - val_loss: 0.4911 - val_accuracy: 0.7552\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7778 - val_loss: 0.4911 - val_accuracy: 0.7552\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7778 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7778 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7778 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7778 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7778 - val_loss: 0.4908 - val_accuracy: 0.7552\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7778 - val_loss: 0.4908 - val_accuracy: 0.7552\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7778 - val_loss: 0.4907 - val_accuracy: 0.7552\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7778 - val_loss: 0.4907 - val_accuracy: 0.7552\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7778 - val_loss: 0.4907 - val_accuracy: 0.7552\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7778 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7778 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7552\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7552\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7552\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.7778 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7778 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7778 - val_loss: 0.4903 - val_accuracy: 0.7552\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7778 - val_loss: 0.4903 - val_accuracy: 0.7552\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7778 - val_loss: 0.4903 - val_accuracy: 0.7552\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7778 - val_loss: 0.4902 - val_accuracy: 0.7552\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7778 - val_loss: 0.4902 - val_accuracy: 0.7552\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7778 - val_loss: 0.4901 - val_accuracy: 0.7552\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7778 - val_loss: 0.4901 - val_accuracy: 0.7552\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7778 - val_loss: 0.4901 - val_accuracy: 0.7552\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7795 - val_loss: 0.4899 - val_accuracy: 0.7552\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7795 - val_loss: 0.4899 - val_accuracy: 0.7552\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7795 - val_loss: 0.4899 - val_accuracy: 0.7552\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7552\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7552\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7552\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7552\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7552\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7552\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7552\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7552\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7795 - val_loss: 0.4895 - val_accuracy: 0.7552\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7795 - val_loss: 0.4895 - val_accuracy: 0.7552\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7795 - val_loss: 0.4895 - val_accuracy: 0.7552\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7795 - val_loss: 0.4894 - val_accuracy: 0.7552\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7795 - val_loss: 0.4894 - val_accuracy: 0.7552\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7795 - val_loss: 0.4894 - val_accuracy: 0.7552\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7552\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7552\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7795 - val_loss: 0.4892 - val_accuracy: 0.7552\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7795 - val_loss: 0.4892 - val_accuracy: 0.7552\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7795 - val_loss: 0.4892 - val_accuracy: 0.7552\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7795 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7795 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7795 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7795 - val_loss: 0.4890 - val_accuracy: 0.7552\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7795 - val_loss: 0.4890 - val_accuracy: 0.7552\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7778 - val_loss: 0.4890 - val_accuracy: 0.7552\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7778 - val_loss: 0.4889 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7778 - val_loss: 0.4889 - val_accuracy: 0.7552\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7778 - val_loss: 0.4889 - val_accuracy: 0.7552\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7778 - val_loss: 0.4888 - val_accuracy: 0.7552\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7778 - val_loss: 0.4888 - val_accuracy: 0.7552\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7778 - val_loss: 0.4888 - val_accuracy: 0.7552\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7778 - val_loss: 0.4887 - val_accuracy: 0.7552\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7778 - val_loss: 0.4887 - val_accuracy: 0.7552\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7778 - val_loss: 0.4887 - val_accuracy: 0.7552\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7778 - val_loss: 0.4886 - val_accuracy: 0.7552\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7778 - val_loss: 0.4886 - val_accuracy: 0.7552\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7778 - val_loss: 0.4886 - val_accuracy: 0.7552\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7778 - val_loss: 0.4886 - val_accuracy: 0.7552\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7778 - val_loss: 0.4885 - val_accuracy: 0.7552\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7778 - val_loss: 0.4885 - val_accuracy: 0.7552\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7778 - val_loss: 0.4885 - val_accuracy: 0.7552\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7812 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7795 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.7795 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7795 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7795 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7795 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7795 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7795 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7795 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7812 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7812 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7812 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7812 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7812 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7795 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7812 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7812 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7812 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7812 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7812 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7812 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7812 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7812 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7812 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7812 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7812 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7830 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7830 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7830 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7812 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7812 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7847 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7812 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7812 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7812 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7795 - val_loss: 0.4867 - val_accuracy: 0.7552\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7552\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7552\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7812 - val_loss: 0.4867 - val_accuracy: 0.7552\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7552\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7552\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7552\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7552\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7552\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7552\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7552\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7552\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7604\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7604\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7830 - val_loss: 0.4862 - val_accuracy: 0.7604\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7830 - val_loss: 0.4862 - val_accuracy: 0.7604\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7830 - val_loss: 0.4862 - val_accuracy: 0.7604\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7604\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7604\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7812 - val_loss: 0.4861 - val_accuracy: 0.7604\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7604\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7604\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7604\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7812 - val_loss: 0.4861 - val_accuracy: 0.7604\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7604\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7812 - val_loss: 0.4860 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7812 - val_loss: 0.4860 - val_accuracy: 0.7604\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7812 - val_loss: 0.4860 - val_accuracy: 0.7604\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7604\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7812 - val_loss: 0.4860 - val_accuracy: 0.7604\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7812 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7812 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7830 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7812 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7812 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7812 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7812 - val_loss: 0.4858 - val_accuracy: 0.7656\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7812 - val_loss: 0.4858 - val_accuracy: 0.7656\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7812 - val_loss: 0.4857 - val_accuracy: 0.7656\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7812 - val_loss: 0.4857 - val_accuracy: 0.7656\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7830 - val_loss: 0.4857 - val_accuracy: 0.7656\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7812 - val_loss: 0.4857 - val_accuracy: 0.7656\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7812 - val_loss: 0.4857 - val_accuracy: 0.7656\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7812 - val_loss: 0.4856 - val_accuracy: 0.7656\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7812 - val_loss: 0.4856 - val_accuracy: 0.7656\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7812 - val_loss: 0.4856 - val_accuracy: 0.7656\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7812 - val_loss: 0.4856 - val_accuracy: 0.7656\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7812 - val_loss: 0.4856 - val_accuracy: 0.7656\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7812 - val_loss: 0.4856 - val_accuracy: 0.7656\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7812 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.7812 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7812 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7656\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7656\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7656\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7656\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7656\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7656\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7656\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7812 - val_loss: 0.4853 - val_accuracy: 0.7656\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7812 - val_loss: 0.4853 - val_accuracy: 0.7656\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7812 - val_loss: 0.4853 - val_accuracy: 0.7656\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7812 - val_loss: 0.4853 - val_accuracy: 0.7656\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7812 - val_loss: 0.4853 - val_accuracy: 0.7656\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7830 - val_loss: 0.4853 - val_accuracy: 0.7656\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7830 - val_loss: 0.4852 - val_accuracy: 0.7656\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7830 - val_loss: 0.4852 - val_accuracy: 0.7656\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7830 - val_loss: 0.4852 - val_accuracy: 0.7656\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7812 - val_loss: 0.4852 - val_accuracy: 0.7656\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7830 - val_loss: 0.4852 - val_accuracy: 0.7656\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7812 - val_loss: 0.4852 - val_accuracy: 0.7656\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7812 - val_loss: 0.4852 - val_accuracy: 0.7656\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7830 - val_loss: 0.4851 - val_accuracy: 0.7656\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7830 - val_loss: 0.4851 - val_accuracy: 0.7656\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7812 - val_loss: 0.4851 - val_accuracy: 0.7656\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7812 - val_loss: 0.4851 - val_accuracy: 0.7656\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7812 - val_loss: 0.4851 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7812 - val_loss: 0.4851 - val_accuracy: 0.7656\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7812 - val_loss: 0.4851 - val_accuracy: 0.7656\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7830 - val_loss: 0.4850 - val_accuracy: 0.7656\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7812 - val_loss: 0.4850 - val_accuracy: 0.7656\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7812 - val_loss: 0.4850 - val_accuracy: 0.7656\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7830 - val_loss: 0.4850 - val_accuracy: 0.7656\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7830 - val_loss: 0.4850 - val_accuracy: 0.7656\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7812 - val_loss: 0.4850 - val_accuracy: 0.7656\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7830 - val_loss: 0.4850 - val_accuracy: 0.7656\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7812 - val_loss: 0.4849 - val_accuracy: 0.7656\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7812 - val_loss: 0.4849 - val_accuracy: 0.7656\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7656\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7812 - val_loss: 0.4849 - val_accuracy: 0.7656\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7656\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7812 - val_loss: 0.4849 - val_accuracy: 0.7708\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.4849 - val_accuracy: 0.7708\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7708\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.4848 - val_accuracy: 0.7708\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7708\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.4848 - val_accuracy: 0.7708\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7708\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.4848 - val_accuracy: 0.7708\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7708\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7708\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.4847 - val_accuracy: 0.7708\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7708\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7708\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7708\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7708\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.4847 - val_accuracy: 0.7708\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.4847 - val_accuracy: 0.7708\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.4847 - val_accuracy: 0.7708\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.4846 - val_accuracy: 0.7708\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7708\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.4846 - val_accuracy: 0.7708\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7708\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.4846 - val_accuracy: 0.7708\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.4846 - val_accuracy: 0.7708\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7708\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.4846 - val_accuracy: 0.7708\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.4845 - val_accuracy: 0.7708\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7812 - val_loss: 0.4845 - val_accuracy: 0.7708\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.4845 - val_accuracy: 0.7708\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.4845 - val_accuracy: 0.7656\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7812 - val_loss: 0.4845 - val_accuracy: 0.7656\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7812 - val_loss: 0.4845 - val_accuracy: 0.7656\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.4845 - val_accuracy: 0.7656\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7812 - val_loss: 0.4845 - val_accuracy: 0.7656\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7812 - val_loss: 0.4844 - val_accuracy: 0.7708\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.4844 - val_accuracy: 0.7708\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.4844 - val_accuracy: 0.7708\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7812 - val_loss: 0.4844 - val_accuracy: 0.7708\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.4844 - val_accuracy: 0.7708\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.4844 - val_accuracy: 0.7708\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.4844 - val_accuracy: 0.7708\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.4844 - val_accuracy: 0.7708\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.4844 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.4843 - val_accuracy: 0.7708\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.4843 - val_accuracy: 0.7708\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.4843 - val_accuracy: 0.7708\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.4843 - val_accuracy: 0.7708\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.4843 - val_accuracy: 0.7708\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7830 - val_loss: 0.4843 - val_accuracy: 0.7708\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7830 - val_loss: 0.4843 - val_accuracy: 0.7708\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7830 - val_loss: 0.4843 - val_accuracy: 0.7708\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7830 - val_loss: 0.4843 - val_accuracy: 0.7708\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7830 - val_loss: 0.4842 - val_accuracy: 0.7708\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7812 - val_loss: 0.4842 - val_accuracy: 0.7708\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7830 - val_loss: 0.4842 - val_accuracy: 0.7708\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7830 - val_loss: 0.4842 - val_accuracy: 0.7708\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7830 - val_loss: 0.4842 - val_accuracy: 0.7708\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7830 - val_loss: 0.4842 - val_accuracy: 0.7708\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7830 - val_loss: 0.4842 - val_accuracy: 0.7708\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7830 - val_loss: 0.4842 - val_accuracy: 0.7708\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7830 - val_loss: 0.4842 - val_accuracy: 0.7708\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7830 - val_loss: 0.4842 - val_accuracy: 0.7708\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7830 - val_loss: 0.4841 - val_accuracy: 0.7708\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7812 - val_loss: 0.4841 - val_accuracy: 0.7708\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7812 - val_loss: 0.4841 - val_accuracy: 0.7708\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7812 - val_loss: 0.4841 - val_accuracy: 0.7708\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7812 - val_loss: 0.4841 - val_accuracy: 0.7708\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7812 - val_loss: 0.4841 - val_accuracy: 0.7708\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7812 - val_loss: 0.4841 - val_accuracy: 0.7708\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7812 - val_loss: 0.4841 - val_accuracy: 0.7708\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7812 - val_loss: 0.4841 - val_accuracy: 0.7708\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7812 - val_loss: 0.4841 - val_accuracy: 0.7708\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7812 - val_loss: 0.4840 - val_accuracy: 0.7708\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7812 - val_loss: 0.4840 - val_accuracy: 0.7708\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7812 - val_loss: 0.4840 - val_accuracy: 0.7708\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7812 - val_loss: 0.4840 - val_accuracy: 0.7708\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.7812 - val_loss: 0.4840 - val_accuracy: 0.7708\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7812 - val_loss: 0.4840 - val_accuracy: 0.7708\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7812 - val_loss: 0.4840 - val_accuracy: 0.7708\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7812 - val_loss: 0.4840 - val_accuracy: 0.7708\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7812 - val_loss: 0.4840 - val_accuracy: 0.7708\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7812 - val_loss: 0.4840 - val_accuracy: 0.7708\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7812 - val_loss: 0.4839 - val_accuracy: 0.7708\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7812 - val_loss: 0.4839 - val_accuracy: 0.7708\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7812 - val_loss: 0.4839 - val_accuracy: 0.7708\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7812 - val_loss: 0.4839 - val_accuracy: 0.7708\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7812 - val_loss: 0.4839 - val_accuracy: 0.7708\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7812 - val_loss: 0.4839 - val_accuracy: 0.7708\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7812 - val_loss: 0.4839 - val_accuracy: 0.7708\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7812 - val_loss: 0.4839 - val_accuracy: 0.7708\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7812 - val_loss: 0.4839 - val_accuracy: 0.7708\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7812 - val_loss: 0.4839 - val_accuracy: 0.7708\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7812 - val_loss: 0.4839 - val_accuracy: 0.7708\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7812 - val_loss: 0.4839 - val_accuracy: 0.7708\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7812 - val_loss: 0.4838 - val_accuracy: 0.7708\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7812 - val_loss: 0.4838 - val_accuracy: 0.7708\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7812 - val_loss: 0.4838 - val_accuracy: 0.7708\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7812 - val_loss: 0.4838 - val_accuracy: 0.7708\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7812 - val_loss: 0.4838 - val_accuracy: 0.7708\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7812 - val_loss: 0.4838 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7812 - val_loss: 0.4838 - val_accuracy: 0.7708\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7812 - val_loss: 0.4838 - val_accuracy: 0.7708\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7812 - val_loss: 0.4838 - val_accuracy: 0.7708\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7812 - val_loss: 0.4838 - val_accuracy: 0.7708\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7812 - val_loss: 0.4838 - val_accuracy: 0.7708\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7812 - val_loss: 0.4837 - val_accuracy: 0.7708\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7812 - val_loss: 0.4837 - val_accuracy: 0.7708\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7812 - val_loss: 0.4837 - val_accuracy: 0.7708\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7812 - val_loss: 0.4837 - val_accuracy: 0.7708\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7812 - val_loss: 0.4837 - val_accuracy: 0.7708\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7812 - val_loss: 0.4837 - val_accuracy: 0.7708\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7812 - val_loss: 0.4837 - val_accuracy: 0.7656\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7812 - val_loss: 0.4837 - val_accuracy: 0.7656\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7812 - val_loss: 0.4837 - val_accuracy: 0.7656\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7812 - val_loss: 0.4837 - val_accuracy: 0.7656\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7812 - val_loss: 0.4837 - val_accuracy: 0.7656\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7812 - val_loss: 0.4837 - val_accuracy: 0.7656\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7812 - val_loss: 0.4837 - val_accuracy: 0.7656\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7812 - val_loss: 0.4836 - val_accuracy: 0.7656\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7812 - val_loss: 0.4836 - val_accuracy: 0.7656\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7812 - val_loss: 0.4836 - val_accuracy: 0.7656\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7812 - val_loss: 0.4836 - val_accuracy: 0.7656\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7812 - val_loss: 0.4836 - val_accuracy: 0.7656\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7812 - val_loss: 0.4836 - val_accuracy: 0.7656\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7812 - val_loss: 0.4836 - val_accuracy: 0.7656\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7812 - val_loss: 0.4836 - val_accuracy: 0.7656\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7812 - val_loss: 0.4836 - val_accuracy: 0.7656\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7812 - val_loss: 0.4836 - val_accuracy: 0.7656\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7812 - val_loss: 0.4836 - val_accuracy: 0.7656\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7812 - val_loss: 0.4836 - val_accuracy: 0.7656\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7812 - val_loss: 0.4836 - val_accuracy: 0.7656\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7812 - val_loss: 0.4835 - val_accuracy: 0.7656\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7812 - val_loss: 0.4835 - val_accuracy: 0.7656\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7812 - val_loss: 0.4835 - val_accuracy: 0.7656\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7812 - val_loss: 0.4835 - val_accuracy: 0.7656\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7812 - val_loss: 0.4835 - val_accuracy: 0.7656\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7812 - val_loss: 0.4835 - val_accuracy: 0.7656\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7812 - val_loss: 0.4835 - val_accuracy: 0.7656\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7812 - val_loss: 0.4835 - val_accuracy: 0.7656\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7812 - val_loss: 0.4835 - val_accuracy: 0.7656\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7812 - val_loss: 0.4835 - val_accuracy: 0.7656\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7812 - val_loss: 0.4835 - val_accuracy: 0.7656\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7812 - val_loss: 0.4835 - val_accuracy: 0.7656\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7812 - val_loss: 0.4835 - val_accuracy: 0.7656\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7812 - val_loss: 0.4835 - val_accuracy: 0.7656\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7812 - val_loss: 0.4834 - val_accuracy: 0.7656\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7812 - val_loss: 0.4834 - val_accuracy: 0.7656\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7812 - val_loss: 0.4834 - val_accuracy: 0.7656\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7812 - val_loss: 0.4834 - val_accuracy: 0.7656\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7812 - val_loss: 0.4834 - val_accuracy: 0.7656\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7812 - val_loss: 0.4834 - val_accuracy: 0.7656\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7812 - val_loss: 0.4834 - val_accuracy: 0.7656\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7812 - val_loss: 0.4834 - val_accuracy: 0.7656\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7830 - val_loss: 0.4834 - val_accuracy: 0.7656\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7812 - val_loss: 0.4834 - val_accuracy: 0.7656\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7812 - val_loss: 0.4834 - val_accuracy: 0.7656\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7847 - val_loss: 0.4834 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7847 - val_loss: 0.4834 - val_accuracy: 0.7656\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7847 - val_loss: 0.4834 - val_accuracy: 0.7656\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7830 - val_loss: 0.4834 - val_accuracy: 0.7656\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7830 - val_loss: 0.4833 - val_accuracy: 0.7656\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7847 - val_loss: 0.4833 - val_accuracy: 0.7656\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7830 - val_loss: 0.4833 - val_accuracy: 0.7656\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7847 - val_loss: 0.4833 - val_accuracy: 0.7656\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7830 - val_loss: 0.4833 - val_accuracy: 0.7656\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7847 - val_loss: 0.4833 - val_accuracy: 0.7656\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7830 - val_loss: 0.4833 - val_accuracy: 0.7656\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7847 - val_loss: 0.4833 - val_accuracy: 0.7656\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7847 - val_loss: 0.4833 - val_accuracy: 0.7656\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7847 - val_loss: 0.4833 - val_accuracy: 0.7656\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7847 - val_loss: 0.4833 - val_accuracy: 0.7656\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7847 - val_loss: 0.4833 - val_accuracy: 0.7656\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7847 - val_loss: 0.4833 - val_accuracy: 0.7656\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7847 - val_loss: 0.4833 - val_accuracy: 0.7656\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7847 - val_loss: 0.4833 - val_accuracy: 0.7656\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7847 - val_loss: 0.4833 - val_accuracy: 0.7656\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7847 - val_loss: 0.4832 - val_accuracy: 0.7656\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7847 - val_loss: 0.4832 - val_accuracy: 0.7656\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7847 - val_loss: 0.4832 - val_accuracy: 0.7656\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7847 - val_loss: 0.4832 - val_accuracy: 0.7656\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7847 - val_loss: 0.4832 - val_accuracy: 0.7656\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7847 - val_loss: 0.4832 - val_accuracy: 0.7656\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7847 - val_loss: 0.4832 - val_accuracy: 0.7656\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7847 - val_loss: 0.4832 - val_accuracy: 0.7656\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7847 - val_loss: 0.4832 - val_accuracy: 0.7656\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7847 - val_loss: 0.4832 - val_accuracy: 0.7656\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7847 - val_loss: 0.4832 - val_accuracy: 0.7656\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7847 - val_loss: 0.4832 - val_accuracy: 0.7656\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7847 - val_loss: 0.4832 - val_accuracy: 0.7656\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7847 - val_loss: 0.4832 - val_accuracy: 0.7656\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7847 - val_loss: 0.4832 - val_accuracy: 0.7708\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7847 - val_loss: 0.4832 - val_accuracy: 0.7708\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7847 - val_loss: 0.4832 - val_accuracy: 0.7708\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7847 - val_loss: 0.4832 - val_accuracy: 0.7708\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7847 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7847 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7847 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7847 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7847 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7847 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7847 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7847 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7847 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7847 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7847 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7847 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7847 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7847 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7847 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7847 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7847 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7847 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7847 - val_loss: 0.4831 - val_accuracy: 0.7708\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7847 - val_loss: 0.4830 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7847 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7847 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7847 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7847 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7847 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7847 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7847 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7847 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7847 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7847 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7847 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7847 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7847 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7847 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7847 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7847 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7847 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7847 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7847 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7847 - val_loss: 0.4830 - val_accuracy: 0.7708\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7847 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7847 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7847 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7847 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7847 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7847 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7847 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7847 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7847 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7847 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7847 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7847 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7847 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7847 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7847 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7847 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7847 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7847 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7847 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7847 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7847 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7847 - val_loss: 0.4829 - val_accuracy: 0.7708\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7847 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7847 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7847 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7847 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7847 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7847 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7847 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7847 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7847 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7847 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7847 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7847 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7847 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7847 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7847 - val_loss: 0.4828 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7847 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7847 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7847 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7847 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7847 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7847 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7847 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7847 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7847 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7847 - val_loss: 0.4828 - val_accuracy: 0.7708\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7847 - val_loss: 0.4827 - val_accuracy: 0.7708\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7847 - val_loss: 0.4827 - val_accuracy: 0.7708\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7847 - val_loss: 0.4827 - val_accuracy: 0.7708\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7847 - val_loss: 0.4827 - val_accuracy: 0.7708\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7847 - val_loss: 0.4827 - val_accuracy: 0.7708\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7847 - val_loss: 0.4827 - val_accuracy: 0.7708\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7847 - val_loss: 0.4827 - val_accuracy: 0.7708\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7847 - val_loss: 0.4827 - val_accuracy: 0.7708\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7847 - val_loss: 0.4827 - val_accuracy: 0.7708\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7847 - val_loss: 0.4827 - val_accuracy: 0.7708\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7847 - val_loss: 0.4827 - val_accuracy: 0.7708\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7847 - val_loss: 0.4827 - val_accuracy: 0.7708\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7847 - val_loss: 0.4827 - val_accuracy: 0.7708\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7847 - val_loss: 0.4827 - val_accuracy: 0.7708\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7847 - val_loss: 0.4827 - val_accuracy: 0.7708\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7847 - val_loss: 0.4827 - val_accuracy: 0.7708\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7847 - val_loss: 0.4827 - val_accuracy: 0.7708\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7847 - val_loss: 0.4827 - val_accuracy: 0.7708\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7847 - val_loss: 0.4827 - val_accuracy: 0.7708\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7847 - val_loss: 0.4827 - val_accuracy: 0.7708\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7847 - val_loss: 0.4827 - val_accuracy: 0.7708\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7847 - val_loss: 0.4827 - val_accuracy: 0.7708\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7847 - val_loss: 0.4827 - val_accuracy: 0.7708\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7847 - val_loss: 0.4827 - val_accuracy: 0.7708\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7847 - val_loss: 0.4827 - val_accuracy: 0.7708\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7847 - val_loss: 0.4827 - val_accuracy: 0.7708\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7847 - val_loss: 0.4827 - val_accuracy: 0.7708\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7847 - val_loss: 0.4827 - val_accuracy: 0.7708\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7847 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7847 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7847 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7865 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7865 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7847 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7865 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7865 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7865 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7865 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7865 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7865 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7865 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7865 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7865 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7865 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7865 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7865 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7865 - val_loss: 0.4826 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7865 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7865 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7865 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7865 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7865 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7865 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7865 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7865 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7865 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7882 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7865 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7865 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7882 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7865 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7865 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7882 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7882 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7882 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7882 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7882 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7882 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7882 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7882 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7882 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7882 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7882 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7882 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7882 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7882 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7882 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7882 - val_loss: 0.4825 - val_accuracy: 0.7708\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x22f87e38070>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs? About 400 epochs, which is where the validation loss begins to stabilize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "For this exercise, do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8859 - accuracy: 0.3559 - val_loss: 0.8225 - val_accuracy: 0.3750\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8637 - accuracy: 0.3646 - val_loss: 0.8050 - val_accuracy: 0.3802\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8441 - accuracy: 0.3646 - val_loss: 0.7894 - val_accuracy: 0.3854\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8266 - accuracy: 0.3681 - val_loss: 0.7757 - val_accuracy: 0.3750\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8111 - accuracy: 0.3715 - val_loss: 0.7634 - val_accuracy: 0.3906\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7973 - accuracy: 0.3750 - val_loss: 0.7525 - val_accuracy: 0.3802\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7848 - accuracy: 0.3785 - val_loss: 0.7428 - val_accuracy: 0.4010\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7736 - accuracy: 0.3837 - val_loss: 0.7339 - val_accuracy: 0.4010\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7636 - accuracy: 0.3924 - val_loss: 0.7260 - val_accuracy: 0.4010\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7544 - accuracy: 0.4010 - val_loss: 0.7188 - val_accuracy: 0.4323\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7462 - accuracy: 0.4062 - val_loss: 0.7123 - val_accuracy: 0.4375\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7386 - accuracy: 0.4149 - val_loss: 0.7063 - val_accuracy: 0.4479\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7316 - accuracy: 0.4167 - val_loss: 0.7009 - val_accuracy: 0.4792\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7253 - accuracy: 0.4271 - val_loss: 0.6960 - val_accuracy: 0.4844\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7195 - accuracy: 0.4392 - val_loss: 0.6914 - val_accuracy: 0.5000\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7141 - accuracy: 0.4531 - val_loss: 0.6872 - val_accuracy: 0.5052\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7091 - accuracy: 0.4757 - val_loss: 0.6833 - val_accuracy: 0.5000\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7045 - accuracy: 0.4948 - val_loss: 0.6798 - val_accuracy: 0.5469\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7002 - accuracy: 0.5295 - val_loss: 0.6765 - val_accuracy: 0.5365\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6962 - accuracy: 0.5538 - val_loss: 0.6734 - val_accuracy: 0.5781\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5712 - val_loss: 0.6705 - val_accuracy: 0.6042\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5833 - val_loss: 0.6679 - val_accuracy: 0.6198\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6859 - accuracy: 0.6042 - val_loss: 0.6654 - val_accuracy: 0.6198\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.6198 - val_loss: 0.6631 - val_accuracy: 0.6354\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6800 - accuracy: 0.6302 - val_loss: 0.6609 - val_accuracy: 0.6406\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6774 - accuracy: 0.6424 - val_loss: 0.6588 - val_accuracy: 0.6458\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.6424 - val_loss: 0.6569 - val_accuracy: 0.6562\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6725 - accuracy: 0.6424 - val_loss: 0.6551 - val_accuracy: 0.6771\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6703 - accuracy: 0.6580 - val_loss: 0.6534 - val_accuracy: 0.6823\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6682 - accuracy: 0.6719 - val_loss: 0.6518 - val_accuracy: 0.6875\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6662 - accuracy: 0.6823 - val_loss: 0.6503 - val_accuracy: 0.6927\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6643 - accuracy: 0.6910 - val_loss: 0.6488 - val_accuracy: 0.6927\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6625 - accuracy: 0.6962 - val_loss: 0.6474 - val_accuracy: 0.6979\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6608 - accuracy: 0.7049 - val_loss: 0.6461 - val_accuracy: 0.6927\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6592 - accuracy: 0.7049 - val_loss: 0.6449 - val_accuracy: 0.6979\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6576 - accuracy: 0.7101 - val_loss: 0.6437 - val_accuracy: 0.7083\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.7083 - val_loss: 0.6425 - val_accuracy: 0.7083\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6547 - accuracy: 0.7066 - val_loss: 0.6414 - val_accuracy: 0.6979\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.7101 - val_loss: 0.6404 - val_accuracy: 0.6979\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6521 - accuracy: 0.7066 - val_loss: 0.6394 - val_accuracy: 0.7083\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6509 - accuracy: 0.7083 - val_loss: 0.6384 - val_accuracy: 0.7083\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6497 - accuracy: 0.7031 - val_loss: 0.6375 - val_accuracy: 0.7083\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.6997 - val_loss: 0.6366 - val_accuracy: 0.7135\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.7031 - val_loss: 0.6358 - val_accuracy: 0.7135\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6464 - accuracy: 0.7049 - val_loss: 0.6349 - val_accuracy: 0.7083\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6454 - accuracy: 0.7014 - val_loss: 0.6341 - val_accuracy: 0.7135\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6445 - accuracy: 0.6997 - val_loss: 0.6334 - val_accuracy: 0.7135\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6435 - accuracy: 0.6997 - val_loss: 0.6326 - val_accuracy: 0.7135\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6426 - accuracy: 0.6997 - val_loss: 0.6319 - val_accuracy: 0.7135\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6418 - accuracy: 0.6997 - val_loss: 0.6311 - val_accuracy: 0.7135\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6409 - accuracy: 0.6997 - val_loss: 0.6304 - val_accuracy: 0.7083\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6401 - accuracy: 0.7014 - val_loss: 0.6298 - val_accuracy: 0.7083\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6393 - accuracy: 0.7014 - val_loss: 0.6291 - val_accuracy: 0.7083\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6385 - accuracy: 0.7014 - val_loss: 0.6284 - val_accuracy: 0.7083\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6378 - accuracy: 0.6997 - val_loss: 0.6278 - val_accuracy: 0.7083\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6370 - accuracy: 0.6962 - val_loss: 0.6272 - val_accuracy: 0.7083\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.6944 - val_loss: 0.6265 - val_accuracy: 0.7083\n",
      "Epoch 58/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6356 - accuracy: 0.6944 - val_loss: 0.6259 - val_accuracy: 0.7135\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6349 - accuracy: 0.6927 - val_loss: 0.6253 - val_accuracy: 0.7188\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6342 - accuracy: 0.6910 - val_loss: 0.6247 - val_accuracy: 0.7188\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6336 - accuracy: 0.6892 - val_loss: 0.6241 - val_accuracy: 0.7188\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.6875 - val_loss: 0.6236 - val_accuracy: 0.7188\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6323 - accuracy: 0.6875 - val_loss: 0.6230 - val_accuracy: 0.7188\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6317 - accuracy: 0.6892 - val_loss: 0.6224 - val_accuracy: 0.7188\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6311 - accuracy: 0.6892 - val_loss: 0.6219 - val_accuracy: 0.7188\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6305 - accuracy: 0.6875 - val_loss: 0.6213 - val_accuracy: 0.7188\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6300 - accuracy: 0.6858 - val_loss: 0.6208 - val_accuracy: 0.7188\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6294 - accuracy: 0.6858 - val_loss: 0.6203 - val_accuracy: 0.7188\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6289 - accuracy: 0.6858 - val_loss: 0.6198 - val_accuracy: 0.7188\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6283 - accuracy: 0.6858 - val_loss: 0.6193 - val_accuracy: 0.7188\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6278 - accuracy: 0.6858 - val_loss: 0.6188 - val_accuracy: 0.7188\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.6858 - val_loss: 0.6182 - val_accuracy: 0.7188\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6268 - accuracy: 0.6858 - val_loss: 0.6177 - val_accuracy: 0.7188\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6263 - accuracy: 0.6858 - val_loss: 0.6172 - val_accuracy: 0.7188\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6259 - accuracy: 0.6858 - val_loss: 0.6167 - val_accuracy: 0.7188\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6253 - accuracy: 0.6858 - val_loss: 0.6162 - val_accuracy: 0.7188\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6249 - accuracy: 0.6858 - val_loss: 0.6157 - val_accuracy: 0.7188\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6244 - accuracy: 0.6858 - val_loss: 0.6153 - val_accuracy: 0.7188\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6240 - accuracy: 0.6858 - val_loss: 0.6148 - val_accuracy: 0.7188\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.6858 - val_loss: 0.6143 - val_accuracy: 0.7188\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6231 - accuracy: 0.6858 - val_loss: 0.6138 - val_accuracy: 0.7240\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.6875 - val_loss: 0.6133 - val_accuracy: 0.7240\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6222 - accuracy: 0.6875 - val_loss: 0.6129 - val_accuracy: 0.7240\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6218 - accuracy: 0.6875 - val_loss: 0.6124 - val_accuracy: 0.7240\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6214 - accuracy: 0.6858 - val_loss: 0.6119 - val_accuracy: 0.7240\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6209 - accuracy: 0.6875 - val_loss: 0.6115 - val_accuracy: 0.7240\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.6858 - val_loss: 0.6110 - val_accuracy: 0.7240\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6201 - accuracy: 0.6858 - val_loss: 0.6105 - val_accuracy: 0.7240\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6197 - accuracy: 0.6858 - val_loss: 0.6101 - val_accuracy: 0.7240\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6193 - accuracy: 0.6875 - val_loss: 0.6096 - val_accuracy: 0.7240\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6189 - accuracy: 0.6875 - val_loss: 0.6092 - val_accuracy: 0.7240\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6185 - accuracy: 0.6875 - val_loss: 0.6087 - val_accuracy: 0.7240\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6181 - accuracy: 0.6875 - val_loss: 0.6082 - val_accuracy: 0.7240\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6177 - accuracy: 0.6892 - val_loss: 0.6078 - val_accuracy: 0.7240\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6173 - accuracy: 0.6892 - val_loss: 0.6073 - val_accuracy: 0.7240\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.6892 - val_loss: 0.6069 - val_accuracy: 0.7240\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6165 - accuracy: 0.6892 - val_loss: 0.6064 - val_accuracy: 0.7240\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6161 - accuracy: 0.6892 - val_loss: 0.6059 - val_accuracy: 0.7240\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6157 - accuracy: 0.6910 - val_loss: 0.6055 - val_accuracy: 0.7240\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6153 - accuracy: 0.6892 - val_loss: 0.6050 - val_accuracy: 0.7240\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6149 - accuracy: 0.6892 - val_loss: 0.6046 - val_accuracy: 0.7240\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6146 - accuracy: 0.6892 - val_loss: 0.6041 - val_accuracy: 0.7240\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6142 - accuracy: 0.6892 - val_loss: 0.6037 - val_accuracy: 0.7240\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6138 - accuracy: 0.6892 - val_loss: 0.6033 - val_accuracy: 0.7240\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6134 - accuracy: 0.6892 - val_loss: 0.6028 - val_accuracy: 0.7240\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6131 - accuracy: 0.6892 - val_loss: 0.6024 - val_accuracy: 0.7240\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6127 - accuracy: 0.6892 - val_loss: 0.6019 - val_accuracy: 0.7240\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6123 - accuracy: 0.6892 - val_loss: 0.6015 - val_accuracy: 0.7240\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6119 - accuracy: 0.6892 - val_loss: 0.6010 - val_accuracy: 0.7240\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6116 - accuracy: 0.6892 - val_loss: 0.6006 - val_accuracy: 0.7240\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6112 - accuracy: 0.6910 - val_loss: 0.6002 - val_accuracy: 0.7240\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6109 - accuracy: 0.6910 - val_loss: 0.5997 - val_accuracy: 0.7240\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6105 - accuracy: 0.6910 - val_loss: 0.5992 - val_accuracy: 0.7240\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6102 - accuracy: 0.6910 - val_loss: 0.5988 - val_accuracy: 0.7240\n",
      "Epoch 115/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6098 - accuracy: 0.6927 - val_loss: 0.5983 - val_accuracy: 0.7240\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6094 - accuracy: 0.6927 - val_loss: 0.5979 - val_accuracy: 0.7188\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6091 - accuracy: 0.6927 - val_loss: 0.5974 - val_accuracy: 0.7188\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6087 - accuracy: 0.6927 - val_loss: 0.5970 - val_accuracy: 0.7188\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6084 - accuracy: 0.6927 - val_loss: 0.5965 - val_accuracy: 0.7188\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6080 - accuracy: 0.6927 - val_loss: 0.5961 - val_accuracy: 0.7188\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6077 - accuracy: 0.6944 - val_loss: 0.5956 - val_accuracy: 0.7188\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6073 - accuracy: 0.6944 - val_loss: 0.5951 - val_accuracy: 0.7188\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.6944 - val_loss: 0.5947 - val_accuracy: 0.7188\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6066 - accuracy: 0.6944 - val_loss: 0.5942 - val_accuracy: 0.7188\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6062 - accuracy: 0.6979 - val_loss: 0.5938 - val_accuracy: 0.7188\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.6979 - val_loss: 0.5933 - val_accuracy: 0.7188\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6055 - accuracy: 0.6979 - val_loss: 0.5929 - val_accuracy: 0.7240\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.6962 - val_loss: 0.5924 - val_accuracy: 0.7240\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6048 - accuracy: 0.6979 - val_loss: 0.5920 - val_accuracy: 0.7240\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6044 - accuracy: 0.6979 - val_loss: 0.5916 - val_accuracy: 0.7240\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6041 - accuracy: 0.6997 - val_loss: 0.5911 - val_accuracy: 0.7240\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6037 - accuracy: 0.7014 - val_loss: 0.5907 - val_accuracy: 0.7240\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6033 - accuracy: 0.7014 - val_loss: 0.5902 - val_accuracy: 0.7240\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6030 - accuracy: 0.7014 - val_loss: 0.5898 - val_accuracy: 0.7240\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6027 - accuracy: 0.7014 - val_loss: 0.5893 - val_accuracy: 0.7240\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6023 - accuracy: 0.7014 - val_loss: 0.5889 - val_accuracy: 0.7240\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6020 - accuracy: 0.7014 - val_loss: 0.5884 - val_accuracy: 0.7240\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6016 - accuracy: 0.7014 - val_loss: 0.5880 - val_accuracy: 0.7240\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6012 - accuracy: 0.7014 - val_loss: 0.5876 - val_accuracy: 0.7240\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6009 - accuracy: 0.7014 - val_loss: 0.5871 - val_accuracy: 0.7240\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6005 - accuracy: 0.7014 - val_loss: 0.5867 - val_accuracy: 0.7240\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6002 - accuracy: 0.7031 - val_loss: 0.5863 - val_accuracy: 0.7240\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5998 - accuracy: 0.7031 - val_loss: 0.5858 - val_accuracy: 0.7240\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5995 - accuracy: 0.7049 - val_loss: 0.5854 - val_accuracy: 0.7240\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5991 - accuracy: 0.7049 - val_loss: 0.5849 - val_accuracy: 0.7292\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5987 - accuracy: 0.7049 - val_loss: 0.5845 - val_accuracy: 0.7292\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5984 - accuracy: 0.7066 - val_loss: 0.5841 - val_accuracy: 0.7292\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5981 - accuracy: 0.7066 - val_loss: 0.5837 - val_accuracy: 0.7292\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5977 - accuracy: 0.7083 - val_loss: 0.5833 - val_accuracy: 0.7292\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5974 - accuracy: 0.7083 - val_loss: 0.5828 - val_accuracy: 0.7292\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.7083 - val_loss: 0.5824 - val_accuracy: 0.7292\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5967 - accuracy: 0.7066 - val_loss: 0.5820 - val_accuracy: 0.7292\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5964 - accuracy: 0.7066 - val_loss: 0.5815 - val_accuracy: 0.7292\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5960 - accuracy: 0.7066 - val_loss: 0.5811 - val_accuracy: 0.7292\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5957 - accuracy: 0.7083 - val_loss: 0.5807 - val_accuracy: 0.7292\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.7066 - val_loss: 0.5802 - val_accuracy: 0.7292\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5950 - accuracy: 0.7066 - val_loss: 0.5798 - val_accuracy: 0.7292\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5946 - accuracy: 0.7066 - val_loss: 0.5794 - val_accuracy: 0.7292\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5943 - accuracy: 0.7049 - val_loss: 0.5790 - val_accuracy: 0.7292\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5939 - accuracy: 0.7066 - val_loss: 0.5785 - val_accuracy: 0.7292\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5936 - accuracy: 0.7066 - val_loss: 0.5781 - val_accuracy: 0.7292\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5932 - accuracy: 0.7066 - val_loss: 0.5777 - val_accuracy: 0.7292\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5929 - accuracy: 0.7066 - val_loss: 0.5773 - val_accuracy: 0.7292\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5925 - accuracy: 0.7066 - val_loss: 0.5768 - val_accuracy: 0.7292\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5922 - accuracy: 0.7049 - val_loss: 0.5764 - val_accuracy: 0.7292\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5919 - accuracy: 0.7031 - val_loss: 0.5760 - val_accuracy: 0.7292\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5915 - accuracy: 0.7049 - val_loss: 0.5756 - val_accuracy: 0.7292\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5911 - accuracy: 0.7049 - val_loss: 0.5752 - val_accuracy: 0.7292\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5908 - accuracy: 0.7049 - val_loss: 0.5747 - val_accuracy: 0.7292\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5904 - accuracy: 0.7049 - val_loss: 0.5743 - val_accuracy: 0.7292\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5900 - accuracy: 0.7049 - val_loss: 0.5739 - val_accuracy: 0.7292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5897 - accuracy: 0.7049 - val_loss: 0.5735 - val_accuracy: 0.7292\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.7049 - val_loss: 0.5730 - val_accuracy: 0.7292\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5890 - accuracy: 0.7049 - val_loss: 0.5726 - val_accuracy: 0.7292\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5886 - accuracy: 0.7066 - val_loss: 0.5722 - val_accuracy: 0.7292\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5883 - accuracy: 0.7066 - val_loss: 0.5718 - val_accuracy: 0.7240\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5879 - accuracy: 0.7083 - val_loss: 0.5714 - val_accuracy: 0.7240\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5876 - accuracy: 0.7083 - val_loss: 0.5710 - val_accuracy: 0.7240\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.7101 - val_loss: 0.5706 - val_accuracy: 0.7240\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5869 - accuracy: 0.7101 - val_loss: 0.5701 - val_accuracy: 0.7240\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5866 - accuracy: 0.7101 - val_loss: 0.5697 - val_accuracy: 0.7240\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5862 - accuracy: 0.7101 - val_loss: 0.5693 - val_accuracy: 0.7240\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5859 - accuracy: 0.7083 - val_loss: 0.5689 - val_accuracy: 0.7240\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.7118 - val_loss: 0.5685 - val_accuracy: 0.7240\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.7101 - val_loss: 0.5681 - val_accuracy: 0.7240\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.7101 - val_loss: 0.5677 - val_accuracy: 0.7240\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5846 - accuracy: 0.7118 - val_loss: 0.5673 - val_accuracy: 0.7240\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.7118 - val_loss: 0.5669 - val_accuracy: 0.7240\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5839 - accuracy: 0.7118 - val_loss: 0.5664 - val_accuracy: 0.7292\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5836 - accuracy: 0.7118 - val_loss: 0.5660 - val_accuracy: 0.7292\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5833 - accuracy: 0.7135 - val_loss: 0.5656 - val_accuracy: 0.7292\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.7135 - val_loss: 0.5652 - val_accuracy: 0.7292\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.7135 - val_loss: 0.5648 - val_accuracy: 0.7292\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.7135 - val_loss: 0.5644 - val_accuracy: 0.7292\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5820 - accuracy: 0.7135 - val_loss: 0.5640 - val_accuracy: 0.7292\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.7135 - val_loss: 0.5636 - val_accuracy: 0.7292\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.7135 - val_loss: 0.5633 - val_accuracy: 0.7292\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.7135 - val_loss: 0.5629 - val_accuracy: 0.7292\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.7153 - val_loss: 0.5625 - val_accuracy: 0.7292\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.7153 - val_loss: 0.5621 - val_accuracy: 0.7292\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.7153 - val_loss: 0.5617 - val_accuracy: 0.7292\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.7153 - val_loss: 0.5614 - val_accuracy: 0.7292\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.7153 - val_loss: 0.5610 - val_accuracy: 0.7292\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.7170 - val_loss: 0.5606 - val_accuracy: 0.7292\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.7170 - val_loss: 0.5603 - val_accuracy: 0.7292\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.7170 - val_loss: 0.5599 - val_accuracy: 0.7292\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.7170 - val_loss: 0.5596 - val_accuracy: 0.7292\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.7170 - val_loss: 0.5592 - val_accuracy: 0.7292\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5778 - accuracy: 0.7170 - val_loss: 0.5588 - val_accuracy: 0.7292\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5775 - accuracy: 0.7170 - val_loss: 0.5585 - val_accuracy: 0.7292\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5772 - accuracy: 0.7170 - val_loss: 0.5581 - val_accuracy: 0.7292\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.7170 - val_loss: 0.5578 - val_accuracy: 0.7292\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5765 - accuracy: 0.7188 - val_loss: 0.5574 - val_accuracy: 0.7292\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5763 - accuracy: 0.7188 - val_loss: 0.5571 - val_accuracy: 0.7344\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5759 - accuracy: 0.7188 - val_loss: 0.5567 - val_accuracy: 0.7344\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5756 - accuracy: 0.7170 - val_loss: 0.5564 - val_accuracy: 0.7344\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5754 - accuracy: 0.7170 - val_loss: 0.5560 - val_accuracy: 0.7344\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5751 - accuracy: 0.7153 - val_loss: 0.5557 - val_accuracy: 0.7344\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5748 - accuracy: 0.7170 - val_loss: 0.5553 - val_accuracy: 0.7344\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5745 - accuracy: 0.7153 - val_loss: 0.5550 - val_accuracy: 0.7344\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5742 - accuracy: 0.7188 - val_loss: 0.5546 - val_accuracy: 0.7344\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.7188 - val_loss: 0.5543 - val_accuracy: 0.7344\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.7170 - val_loss: 0.5540 - val_accuracy: 0.7344\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 0.7170 - val_loss: 0.5536 - val_accuracy: 0.7344\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.7170 - val_loss: 0.5533 - val_accuracy: 0.7344\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.7170 - val_loss: 0.5529 - val_accuracy: 0.7396\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.7170 - val_loss: 0.5526 - val_accuracy: 0.7396\n",
      "Epoch 228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5721 - accuracy: 0.7188 - val_loss: 0.5523 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5718 - accuracy: 0.7188 - val_loss: 0.5519 - val_accuracy: 0.7448\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.7170 - val_loss: 0.5516 - val_accuracy: 0.7448\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.7188 - val_loss: 0.5513 - val_accuracy: 0.7448\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.7188 - val_loss: 0.5510 - val_accuracy: 0.7448\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5707 - accuracy: 0.7170 - val_loss: 0.5506 - val_accuracy: 0.7448\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5704 - accuracy: 0.7170 - val_loss: 0.5503 - val_accuracy: 0.7448\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.7170 - val_loss: 0.5500 - val_accuracy: 0.7448\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.7170 - val_loss: 0.5497 - val_accuracy: 0.7448\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5696 - accuracy: 0.7170 - val_loss: 0.5494 - val_accuracy: 0.7448\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.7170 - val_loss: 0.5491 - val_accuracy: 0.7396\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5691 - accuracy: 0.7170 - val_loss: 0.5488 - val_accuracy: 0.7396\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5688 - accuracy: 0.7170 - val_loss: 0.5485 - val_accuracy: 0.7396\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.7170 - val_loss: 0.5482 - val_accuracy: 0.7396\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5683 - accuracy: 0.7170 - val_loss: 0.5479 - val_accuracy: 0.7396\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7153 - val_loss: 0.5476 - val_accuracy: 0.7396\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5678 - accuracy: 0.7153 - val_loss: 0.5473 - val_accuracy: 0.7396\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.7170 - val_loss: 0.5470 - val_accuracy: 0.7396\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.7170 - val_loss: 0.5467 - val_accuracy: 0.7448\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.7170 - val_loss: 0.5464 - val_accuracy: 0.7448\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7170 - val_loss: 0.5461 - val_accuracy: 0.7448\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.7188 - val_loss: 0.5458 - val_accuracy: 0.7448\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.7188 - val_loss: 0.5455 - val_accuracy: 0.7448\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.7205 - val_loss: 0.5452 - val_accuracy: 0.7448\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.7188 - val_loss: 0.5450 - val_accuracy: 0.7448\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7205 - val_loss: 0.5447 - val_accuracy: 0.7448\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.7205 - val_loss: 0.5444 - val_accuracy: 0.7448\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.7188 - val_loss: 0.5441 - val_accuracy: 0.7448\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7205 - val_loss: 0.5438 - val_accuracy: 0.7448\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.7188 - val_loss: 0.5435 - val_accuracy: 0.7448\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.7205 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7205 - val_loss: 0.5429 - val_accuracy: 0.7448\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.7222 - val_loss: 0.5426 - val_accuracy: 0.7448\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7205 - val_loss: 0.5422 - val_accuracy: 0.7448\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.7222 - val_loss: 0.5419 - val_accuracy: 0.7448\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.7222 - val_loss: 0.5416 - val_accuracy: 0.7448\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5624 - accuracy: 0.7222 - val_loss: 0.5413 - val_accuracy: 0.7448\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7240 - val_loss: 0.5410 - val_accuracy: 0.7448\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.7240 - val_loss: 0.5406 - val_accuracy: 0.7448\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.7240 - val_loss: 0.5403 - val_accuracy: 0.7448\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.7240 - val_loss: 0.5400 - val_accuracy: 0.7448\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.7240 - val_loss: 0.5397 - val_accuracy: 0.7448\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7240 - val_loss: 0.5394 - val_accuracy: 0.7448\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7240 - val_loss: 0.5391 - val_accuracy: 0.7448\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.7222 - val_loss: 0.5388 - val_accuracy: 0.7448\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.7222 - val_loss: 0.5384 - val_accuracy: 0.7448\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7222 - val_loss: 0.5381 - val_accuracy: 0.7448\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7222 - val_loss: 0.5378 - val_accuracy: 0.7448\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.7240 - val_loss: 0.5375 - val_accuracy: 0.7396\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5589 - accuracy: 0.7257 - val_loss: 0.5372 - val_accuracy: 0.7448\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.7257 - val_loss: 0.5369 - val_accuracy: 0.7500\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7274 - val_loss: 0.5366 - val_accuracy: 0.7500\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7292 - val_loss: 0.5363 - val_accuracy: 0.7500\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.7274 - val_loss: 0.5360 - val_accuracy: 0.7552\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7292 - val_loss: 0.5357 - val_accuracy: 0.7552\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.7274 - val_loss: 0.5354 - val_accuracy: 0.7552\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.7292 - val_loss: 0.5350 - val_accuracy: 0.7552\n",
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.7292 - val_loss: 0.5347 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.7274 - val_loss: 0.5344 - val_accuracy: 0.7552\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.7274 - val_loss: 0.5341 - val_accuracy: 0.7500\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.7274 - val_loss: 0.5338 - val_accuracy: 0.7500\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5554 - accuracy: 0.7274 - val_loss: 0.5335 - val_accuracy: 0.7500\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7292 - val_loss: 0.5332 - val_accuracy: 0.7448\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7344 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7344 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.7326 - val_loss: 0.5322 - val_accuracy: 0.7396\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7361 - val_loss: 0.5319 - val_accuracy: 0.7448\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.7344 - val_loss: 0.5316 - val_accuracy: 0.7448\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5534 - accuracy: 0.7361 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5532 - accuracy: 0.7361 - val_loss: 0.5310 - val_accuracy: 0.7448\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.7396 - val_loss: 0.5307 - val_accuracy: 0.7448\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5526 - accuracy: 0.7413 - val_loss: 0.5304 - val_accuracy: 0.7448\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.7413 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7413 - val_loss: 0.5299 - val_accuracy: 0.7448\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7431 - val_loss: 0.5296 - val_accuracy: 0.7448\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5515 - accuracy: 0.7431 - val_loss: 0.5293 - val_accuracy: 0.7448\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7431 - val_loss: 0.5290 - val_accuracy: 0.7448\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7431 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7431 - val_loss: 0.5284 - val_accuracy: 0.7448\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7431 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7431 - val_loss: 0.5279 - val_accuracy: 0.7448\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.7431 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7448 - val_loss: 0.5273 - val_accuracy: 0.7448\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7448 - val_loss: 0.5271 - val_accuracy: 0.7448\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7465 - val_loss: 0.5268 - val_accuracy: 0.7448\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7465 - val_loss: 0.5265 - val_accuracy: 0.7448\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7483 - val_loss: 0.5262 - val_accuracy: 0.7448\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7465 - val_loss: 0.5260 - val_accuracy: 0.7448\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.7483 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.7483 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.7483 - val_loss: 0.5252 - val_accuracy: 0.7396\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7500 - val_loss: 0.5249 - val_accuracy: 0.7396\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7500 - val_loss: 0.5247 - val_accuracy: 0.7396\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7483 - val_loss: 0.5244 - val_accuracy: 0.7396\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5466 - accuracy: 0.7483 - val_loss: 0.5241 - val_accuracy: 0.7396\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 0.7500 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7500 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.7500 - val_loss: 0.5234 - val_accuracy: 0.7396\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7500 - val_loss: 0.5231 - val_accuracy: 0.7396\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7500 - val_loss: 0.5228 - val_accuracy: 0.7396\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7500 - val_loss: 0.5225 - val_accuracy: 0.7396\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7483 - val_loss: 0.5223 - val_accuracy: 0.7396\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7483 - val_loss: 0.5220 - val_accuracy: 0.7396\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.7500 - val_loss: 0.5218 - val_accuracy: 0.7396\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7517 - val_loss: 0.5215 - val_accuracy: 0.7396\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7535 - val_loss: 0.5212 - val_accuracy: 0.7396\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7517 - val_loss: 0.5210 - val_accuracy: 0.7396\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7517 - val_loss: 0.5207 - val_accuracy: 0.7396\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7517 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7517 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7517 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7517 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7517 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7517 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7517 - val_loss: 0.5189 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7535 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.7535 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7535 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7535 - val_loss: 0.5179 - val_accuracy: 0.7552\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7535 - val_loss: 0.5177 - val_accuracy: 0.7552\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7535 - val_loss: 0.5174 - val_accuracy: 0.7552\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7535 - val_loss: 0.5172 - val_accuracy: 0.7552\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5396 - accuracy: 0.7535 - val_loss: 0.5169 - val_accuracy: 0.7552\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7535 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5391 - accuracy: 0.7535 - val_loss: 0.5165 - val_accuracy: 0.7552\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.7535 - val_loss: 0.5162 - val_accuracy: 0.7552\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.7569 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.7552 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5382 - accuracy: 0.7552 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7569 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.7587 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.7587 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7587 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7587 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.7587 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5364 - accuracy: 0.7604 - val_loss: 0.5138 - val_accuracy: 0.7552\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7604 - val_loss: 0.5136 - val_accuracy: 0.7552\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.7622 - val_loss: 0.5134 - val_accuracy: 0.7552\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7622 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7622 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7622 - val_loss: 0.5126 - val_accuracy: 0.7552\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7622 - val_loss: 0.5124 - val_accuracy: 0.7552\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7622 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.7639 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.7639 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7639 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7639 - val_loss: 0.5112 - val_accuracy: 0.7552\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7639 - val_loss: 0.5110 - val_accuracy: 0.7552\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.7639 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7639 - val_loss: 0.5105 - val_accuracy: 0.7552\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7639 - val_loss: 0.5102 - val_accuracy: 0.7552\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7639 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5322 - accuracy: 0.7639 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7639 - val_loss: 0.5095 - val_accuracy: 0.7604\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7639 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.7639 - val_loss: 0.5091 - val_accuracy: 0.7604\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7656 - val_loss: 0.5088 - val_accuracy: 0.7604\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7639 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7622 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7622 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7604 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7604 - val_loss: 0.5077 - val_accuracy: 0.7604\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7604 - val_loss: 0.5075 - val_accuracy: 0.7604\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7604 - val_loss: 0.5073 - val_accuracy: 0.7656\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7604 - val_loss: 0.5071 - val_accuracy: 0.7656\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.7604 - val_loss: 0.5069 - val_accuracy: 0.7656\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7622 - val_loss: 0.5067 - val_accuracy: 0.7656\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7639 - val_loss: 0.5065 - val_accuracy: 0.7656\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7639 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7622 - val_loss: 0.5061 - val_accuracy: 0.7656\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7622 - val_loss: 0.5059 - val_accuracy: 0.7708\n",
      "Epoch 399/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7639 - val_loss: 0.5057 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7622 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.7622 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.7656 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7656 - val_loss: 0.5049 - val_accuracy: 0.7708\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.7622 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7622 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7604 - val_loss: 0.5043 - val_accuracy: 0.7708\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.7639 - val_loss: 0.5042 - val_accuracy: 0.7708\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7622 - val_loss: 0.5040 - val_accuracy: 0.7708\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7639 - val_loss: 0.5038 - val_accuracy: 0.7708\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7622 - val_loss: 0.5036 - val_accuracy: 0.7708\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7639 - val_loss: 0.5034 - val_accuracy: 0.7760\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7622 - val_loss: 0.5033 - val_accuracy: 0.7760\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7639 - val_loss: 0.5031 - val_accuracy: 0.7760\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7622 - val_loss: 0.5029 - val_accuracy: 0.7760\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7639 - val_loss: 0.5027 - val_accuracy: 0.7812\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7639 - val_loss: 0.5026 - val_accuracy: 0.7812\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7639 - val_loss: 0.5024 - val_accuracy: 0.7812\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.7656 - val_loss: 0.5022 - val_accuracy: 0.7812\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7656 - val_loss: 0.5021 - val_accuracy: 0.7812\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7656 - val_loss: 0.5019 - val_accuracy: 0.7812\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7656 - val_loss: 0.5017 - val_accuracy: 0.7812\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7639 - val_loss: 0.5015 - val_accuracy: 0.7812\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.7656 - val_loss: 0.5014 - val_accuracy: 0.7812\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7656 - val_loss: 0.5012 - val_accuracy: 0.7812\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7656 - val_loss: 0.5010 - val_accuracy: 0.7812\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7656 - val_loss: 0.5009 - val_accuracy: 0.7812\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7656 - val_loss: 0.5007 - val_accuracy: 0.7812\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7674 - val_loss: 0.5005 - val_accuracy: 0.7812\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7674 - val_loss: 0.5004 - val_accuracy: 0.7812\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7674 - val_loss: 0.5002 - val_accuracy: 0.7812\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7674 - val_loss: 0.5000 - val_accuracy: 0.7812\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7674 - val_loss: 0.4999 - val_accuracy: 0.7812\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7674 - val_loss: 0.4997 - val_accuracy: 0.7812\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7656 - val_loss: 0.4996 - val_accuracy: 0.7812\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7656 - val_loss: 0.4994 - val_accuracy: 0.7812\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7656 - val_loss: 0.4992 - val_accuracy: 0.7865\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7656 - val_loss: 0.4991 - val_accuracy: 0.7865\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7656 - val_loss: 0.4989 - val_accuracy: 0.7865\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7656 - val_loss: 0.4988 - val_accuracy: 0.7865\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7656 - val_loss: 0.4986 - val_accuracy: 0.7865\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7674 - val_loss: 0.4984 - val_accuracy: 0.7865\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7674 - val_loss: 0.4983 - val_accuracy: 0.7865\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7674 - val_loss: 0.4981 - val_accuracy: 0.7865\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7656 - val_loss: 0.4980 - val_accuracy: 0.7865\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7656 - val_loss: 0.4978 - val_accuracy: 0.7865\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7656 - val_loss: 0.4977 - val_accuracy: 0.7865\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7656 - val_loss: 0.4975 - val_accuracy: 0.7865\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7656 - val_loss: 0.4974 - val_accuracy: 0.7865\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7656 - val_loss: 0.4972 - val_accuracy: 0.7865\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7656 - val_loss: 0.4971 - val_accuracy: 0.7865\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7656 - val_loss: 0.4969 - val_accuracy: 0.7812\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7656 - val_loss: 0.4968 - val_accuracy: 0.7812\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7656 - val_loss: 0.4966 - val_accuracy: 0.7812\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7674 - val_loss: 0.4965 - val_accuracy: 0.7812\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7674 - val_loss: 0.4963 - val_accuracy: 0.7760\n",
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7674 - val_loss: 0.4962 - val_accuracy: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7674 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7674 - val_loss: 0.4959 - val_accuracy: 0.7760\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7674 - val_loss: 0.4957 - val_accuracy: 0.7760\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7674 - val_loss: 0.4956 - val_accuracy: 0.7760\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7674 - val_loss: 0.4955 - val_accuracy: 0.7760\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7674 - val_loss: 0.4953 - val_accuracy: 0.7760\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7656 - val_loss: 0.4952 - val_accuracy: 0.7760\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7674 - val_loss: 0.4951 - val_accuracy: 0.7760\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7656 - val_loss: 0.4949 - val_accuracy: 0.7760\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7674 - val_loss: 0.4948 - val_accuracy: 0.7760\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7656 - val_loss: 0.4947 - val_accuracy: 0.7760\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7674 - val_loss: 0.4946 - val_accuracy: 0.7760\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7656 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7656 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7674 - val_loss: 0.4942 - val_accuracy: 0.7812\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7656 - val_loss: 0.4941 - val_accuracy: 0.7812\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7639 - val_loss: 0.4940 - val_accuracy: 0.7812\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7656 - val_loss: 0.4938 - val_accuracy: 0.7812\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7639 - val_loss: 0.4937 - val_accuracy: 0.7812\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7656 - val_loss: 0.4936 - val_accuracy: 0.7812\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7656 - val_loss: 0.4935 - val_accuracy: 0.7812\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7639 - val_loss: 0.4934 - val_accuracy: 0.7812\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7639 - val_loss: 0.4932 - val_accuracy: 0.7812\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7674 - val_loss: 0.4931 - val_accuracy: 0.7812\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7674 - val_loss: 0.4930 - val_accuracy: 0.7812\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7674 - val_loss: 0.4929 - val_accuracy: 0.7812\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7674 - val_loss: 0.4928 - val_accuracy: 0.7812\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7674 - val_loss: 0.4927 - val_accuracy: 0.7812\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7674 - val_loss: 0.4926 - val_accuracy: 0.7865\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7674 - val_loss: 0.4924 - val_accuracy: 0.7865\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7674 - val_loss: 0.4923 - val_accuracy: 0.7865\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7656 - val_loss: 0.4922 - val_accuracy: 0.7865\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7639 - val_loss: 0.4921 - val_accuracy: 0.7865\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7639 - val_loss: 0.4920 - val_accuracy: 0.7865\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7639 - val_loss: 0.4919 - val_accuracy: 0.7865\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7639 - val_loss: 0.4918 - val_accuracy: 0.7917\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7639 - val_loss: 0.4917 - val_accuracy: 0.7917\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7656 - val_loss: 0.4916 - val_accuracy: 0.7917\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7656 - val_loss: 0.4915 - val_accuracy: 0.7917\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7656 - val_loss: 0.4915 - val_accuracy: 0.7917\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7656 - val_loss: 0.4914 - val_accuracy: 0.7917\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7656 - val_loss: 0.4913 - val_accuracy: 0.7917\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7656 - val_loss: 0.4912 - val_accuracy: 0.7969\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7656 - val_loss: 0.4910 - val_accuracy: 0.7969\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7656 - val_loss: 0.4909 - val_accuracy: 0.7969\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7674 - val_loss: 0.4908 - val_accuracy: 0.7969\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7656 - val_loss: 0.4907 - val_accuracy: 0.7969\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7656 - val_loss: 0.4907 - val_accuracy: 0.7969\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7674 - val_loss: 0.4906 - val_accuracy: 0.7969\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7674 - val_loss: 0.4905 - val_accuracy: 0.7917\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7656 - val_loss: 0.4904 - val_accuracy: 0.7917\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.7674 - val_loss: 0.4903 - val_accuracy: 0.7917\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7656 - val_loss: 0.4902 - val_accuracy: 0.7917\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7674 - val_loss: 0.4901 - val_accuracy: 0.7917\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7656 - val_loss: 0.4900 - val_accuracy: 0.7917\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7656 - val_loss: 0.4899 - val_accuracy: 0.7917\n",
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.7656 - val_loss: 0.4898 - val_accuracy: 0.7917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7656 - val_loss: 0.4898 - val_accuracy: 0.7917\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7674 - val_loss: 0.4897 - val_accuracy: 0.7917\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.7656 - val_loss: 0.4896 - val_accuracy: 0.7917\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7656 - val_loss: 0.4895 - val_accuracy: 0.7917\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.7656 - val_loss: 0.4895 - val_accuracy: 0.7917\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.7656 - val_loss: 0.4894 - val_accuracy: 0.7917\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7656 - val_loss: 0.4893 - val_accuracy: 0.7917\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7656 - val_loss: 0.4892 - val_accuracy: 0.7865\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.7656 - val_loss: 0.4891 - val_accuracy: 0.7865\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7656 - val_loss: 0.4891 - val_accuracy: 0.7865\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7674 - val_loss: 0.4890 - val_accuracy: 0.7812\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7708 - val_loss: 0.4889 - val_accuracy: 0.7812\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.7691 - val_loss: 0.4888 - val_accuracy: 0.7812\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7691 - val_loss: 0.4887 - val_accuracy: 0.7812\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7691 - val_loss: 0.4886 - val_accuracy: 0.7812\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.7691 - val_loss: 0.4885 - val_accuracy: 0.7812\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.7691 - val_loss: 0.4884 - val_accuracy: 0.7812\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.7691 - val_loss: 0.4883 - val_accuracy: 0.7812\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7691 - val_loss: 0.4882 - val_accuracy: 0.7812\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7691 - val_loss: 0.4882 - val_accuracy: 0.7812\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.7726 - val_loss: 0.4881 - val_accuracy: 0.7812\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7708 - val_loss: 0.4880 - val_accuracy: 0.7812\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7708 - val_loss: 0.4880 - val_accuracy: 0.7812\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.7691 - val_loss: 0.4879 - val_accuracy: 0.7812\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7726 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7691 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.7708 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.7691 - val_loss: 0.4876 - val_accuracy: 0.7812\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7691 - val_loss: 0.4876 - val_accuracy: 0.7812\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7691 - val_loss: 0.4875 - val_accuracy: 0.7812\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.7691 - val_loss: 0.4875 - val_accuracy: 0.7812\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4962 - accuracy: 0.7708 - val_loss: 0.4874 - val_accuracy: 0.7812\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7708 - val_loss: 0.4873 - val_accuracy: 0.7812\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7726 - val_loss: 0.4873 - val_accuracy: 0.7812\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.7708 - val_loss: 0.4872 - val_accuracy: 0.7812\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.7708 - val_loss: 0.4872 - val_accuracy: 0.7812\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.7743 - val_loss: 0.4871 - val_accuracy: 0.7812\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7726 - val_loss: 0.4871 - val_accuracy: 0.7812\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7726 - val_loss: 0.4870 - val_accuracy: 0.7812\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.7726 - val_loss: 0.4870 - val_accuracy: 0.7812\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.7726 - val_loss: 0.4869 - val_accuracy: 0.7812\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7743 - val_loss: 0.4868 - val_accuracy: 0.7812\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7743 - val_loss: 0.4868 - val_accuracy: 0.7812\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.7726 - val_loss: 0.4867 - val_accuracy: 0.7812\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7743 - val_loss: 0.4866 - val_accuracy: 0.7812\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7726 - val_loss: 0.4866 - val_accuracy: 0.7812\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7726 - val_loss: 0.4865 - val_accuracy: 0.7812\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.7743 - val_loss: 0.4865 - val_accuracy: 0.7812\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.7726 - val_loss: 0.4864 - val_accuracy: 0.7812\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.7726 - val_loss: 0.4864 - val_accuracy: 0.7812\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.7726 - val_loss: 0.4863 - val_accuracy: 0.7812\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7743 - val_loss: 0.4863 - val_accuracy: 0.7812\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.7743 - val_loss: 0.4862 - val_accuracy: 0.7812\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.7743 - val_loss: 0.4862 - val_accuracy: 0.7812\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7743 - val_loss: 0.4861 - val_accuracy: 0.7812\n",
      "Epoch 569/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.7743 - val_loss: 0.4861 - val_accuracy: 0.7812\n",
      "Epoch 570/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7760 - val_loss: 0.4861 - val_accuracy: 0.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7760 - val_loss: 0.4860 - val_accuracy: 0.7760\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7743 - val_loss: 0.4860 - val_accuracy: 0.7760\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.7760 - val_loss: 0.4859 - val_accuracy: 0.7760\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7760 - val_loss: 0.4859 - val_accuracy: 0.7760\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7743 - val_loss: 0.4859 - val_accuracy: 0.7760\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.7743 - val_loss: 0.4858 - val_accuracy: 0.7760\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7743 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7760 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7743 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7743 - val_loss: 0.4856 - val_accuracy: 0.7708\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7726 - val_loss: 0.4856 - val_accuracy: 0.7708\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7743 - val_loss: 0.4855 - val_accuracy: 0.7708\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7743 - val_loss: 0.4855 - val_accuracy: 0.7708\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.7743 - val_loss: 0.4854 - val_accuracy: 0.7708\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.7743 - val_loss: 0.4854 - val_accuracy: 0.7708\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.7743 - val_loss: 0.4854 - val_accuracy: 0.7708\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7743 - val_loss: 0.4853 - val_accuracy: 0.7708\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7743 - val_loss: 0.4853 - val_accuracy: 0.7708\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7726 - val_loss: 0.4852 - val_accuracy: 0.7708\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.7743 - val_loss: 0.4852 - val_accuracy: 0.7708\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7743 - val_loss: 0.4852 - val_accuracy: 0.7708\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7743 - val_loss: 0.4851 - val_accuracy: 0.7708\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.7743 - val_loss: 0.4851 - val_accuracy: 0.7708\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7743 - val_loss: 0.4851 - val_accuracy: 0.7708\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7743 - val_loss: 0.4850 - val_accuracy: 0.7708\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7743 - val_loss: 0.4850 - val_accuracy: 0.7708\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7743 - val_loss: 0.4850 - val_accuracy: 0.7708\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7743 - val_loss: 0.4849 - val_accuracy: 0.7708\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7743 - val_loss: 0.4849 - val_accuracy: 0.7708\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7743 - val_loss: 0.4849 - val_accuracy: 0.7708\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7743 - val_loss: 0.4849 - val_accuracy: 0.7708\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7743 - val_loss: 0.4848 - val_accuracy: 0.7708\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7743 - val_loss: 0.4848 - val_accuracy: 0.7708\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7743 - val_loss: 0.4848 - val_accuracy: 0.7708\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7743 - val_loss: 0.4847 - val_accuracy: 0.7708\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7743 - val_loss: 0.4847 - val_accuracy: 0.7708\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.7743 - val_loss: 0.4847 - val_accuracy: 0.7708\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7726 - val_loss: 0.4847 - val_accuracy: 0.7708\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7743 - val_loss: 0.4846 - val_accuracy: 0.7656\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.7726 - val_loss: 0.4846 - val_accuracy: 0.7708\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.7726 - val_loss: 0.4846 - val_accuracy: 0.7708\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7743 - val_loss: 0.4846 - val_accuracy: 0.7708\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7743 - val_loss: 0.4845 - val_accuracy: 0.7708\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7726 - val_loss: 0.4845 - val_accuracy: 0.7708\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.7726 - val_loss: 0.4845 - val_accuracy: 0.7708\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.7743 - val_loss: 0.4845 - val_accuracy: 0.7708\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7726 - val_loss: 0.4844 - val_accuracy: 0.7708\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.7726 - val_loss: 0.4844 - val_accuracy: 0.7708\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7726 - val_loss: 0.4844 - val_accuracy: 0.7708\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7726 - val_loss: 0.4844 - val_accuracy: 0.7708\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7726 - val_loss: 0.4844 - val_accuracy: 0.7708\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7726 - val_loss: 0.4843 - val_accuracy: 0.7708\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7726 - val_loss: 0.4843 - val_accuracy: 0.7708\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7743 - val_loss: 0.4843 - val_accuracy: 0.7708\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7743 - val_loss: 0.4843 - val_accuracy: 0.7708\n",
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7743 - val_loss: 0.4842 - val_accuracy: 0.7656\n",
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7726 - val_loss: 0.4842 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7743 - val_loss: 0.4842 - val_accuracy: 0.7656\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7743 - val_loss: 0.4842 - val_accuracy: 0.7656\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7743 - val_loss: 0.4842 - val_accuracy: 0.7656\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7743 - val_loss: 0.4841 - val_accuracy: 0.7656\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.7743 - val_loss: 0.4841 - val_accuracy: 0.7656\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7743 - val_loss: 0.4841 - val_accuracy: 0.7708\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7743 - val_loss: 0.4841 - val_accuracy: 0.7708\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7743 - val_loss: 0.4841 - val_accuracy: 0.7708\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7743 - val_loss: 0.4840 - val_accuracy: 0.7708\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7743 - val_loss: 0.4840 - val_accuracy: 0.7708\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7743 - val_loss: 0.4840 - val_accuracy: 0.7708\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.7743 - val_loss: 0.4840 - val_accuracy: 0.7708\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7743 - val_loss: 0.4839 - val_accuracy: 0.7708\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7743 - val_loss: 0.4839 - val_accuracy: 0.7708\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7743 - val_loss: 0.4839 - val_accuracy: 0.7708\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7743 - val_loss: 0.4839 - val_accuracy: 0.7708\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7743 - val_loss: 0.4839 - val_accuracy: 0.7708\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7743 - val_loss: 0.4838 - val_accuracy: 0.7708\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7743 - val_loss: 0.4838 - val_accuracy: 0.7708\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7743 - val_loss: 0.4838 - val_accuracy: 0.7708\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7743 - val_loss: 0.4838 - val_accuracy: 0.7708\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7743 - val_loss: 0.4838 - val_accuracy: 0.7708\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7743 - val_loss: 0.4837 - val_accuracy: 0.7708\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7743 - val_loss: 0.4837 - val_accuracy: 0.7708\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7743 - val_loss: 0.4837 - val_accuracy: 0.7708\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7743 - val_loss: 0.4837 - val_accuracy: 0.7708\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7743 - val_loss: 0.4837 - val_accuracy: 0.7708\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7726 - val_loss: 0.4836 - val_accuracy: 0.7708\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7760 - val_loss: 0.4836 - val_accuracy: 0.7708\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7760 - val_loss: 0.4836 - val_accuracy: 0.7708\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7743 - val_loss: 0.4836 - val_accuracy: 0.7708\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7760 - val_loss: 0.4835 - val_accuracy: 0.7708\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7760 - val_loss: 0.4835 - val_accuracy: 0.7708\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7760 - val_loss: 0.4835 - val_accuracy: 0.7708\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7760 - val_loss: 0.4835 - val_accuracy: 0.7708\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7760 - val_loss: 0.4834 - val_accuracy: 0.7760\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7743 - val_loss: 0.4834 - val_accuracy: 0.7760\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.7778 - val_loss: 0.4834 - val_accuracy: 0.7760\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7778 - val_loss: 0.4834 - val_accuracy: 0.7760\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7760 - val_loss: 0.4833 - val_accuracy: 0.7760\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7760 - val_loss: 0.4833 - val_accuracy: 0.7760\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7760 - val_loss: 0.4833 - val_accuracy: 0.7760\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7760 - val_loss: 0.4832 - val_accuracy: 0.7760\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7760 - val_loss: 0.4832 - val_accuracy: 0.7760\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7760 - val_loss: 0.4832 - val_accuracy: 0.7760\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7760 - val_loss: 0.4832 - val_accuracy: 0.7760\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7760 - val_loss: 0.4832 - val_accuracy: 0.7760\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7760 - val_loss: 0.4831 - val_accuracy: 0.7760\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7760 - val_loss: 0.4831 - val_accuracy: 0.7760\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7760 - val_loss: 0.4831 - val_accuracy: 0.7760\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7760 - val_loss: 0.4831 - val_accuracy: 0.7760\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7760 - val_loss: 0.4831 - val_accuracy: 0.7760\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7760 - val_loss: 0.4830 - val_accuracy: 0.7760\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7760 - val_loss: 0.4830 - val_accuracy: 0.7760\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7760 - val_loss: 0.4830 - val_accuracy: 0.7760\n",
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7760 - val_loss: 0.4830 - val_accuracy: 0.7760\n",
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7743 - val_loss: 0.4830 - val_accuracy: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7743 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7743 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7743 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7743 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7743 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.7743 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7760 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7743 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7743 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7743 - val_loss: 0.4827 - val_accuracy: 0.7760\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7743 - val_loss: 0.4827 - val_accuracy: 0.7760\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7743 - val_loss: 0.4827 - val_accuracy: 0.7760\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7743 - val_loss: 0.4827 - val_accuracy: 0.7760\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7743 - val_loss: 0.4827 - val_accuracy: 0.7760\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7743 - val_loss: 0.4826 - val_accuracy: 0.7760\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7743 - val_loss: 0.4826 - val_accuracy: 0.7760\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7743 - val_loss: 0.4826 - val_accuracy: 0.7760\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7743 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7743 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7743 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7743 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7743 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7760 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7760 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7760 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7760 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7760 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7760 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7708\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7708\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7708\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7708\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7708\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7708\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7760 - val_loss: 0.4823 - val_accuracy: 0.7708\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7760 - val_loss: 0.4823 - val_accuracy: 0.7708\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7760 - val_loss: 0.4823 - val_accuracy: 0.7708\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7760 - val_loss: 0.4823 - val_accuracy: 0.7708\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7760 - val_loss: 0.4823 - val_accuracy: 0.7708\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7760 - val_loss: 0.4822 - val_accuracy: 0.7708\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7760 - val_loss: 0.4822 - val_accuracy: 0.7708\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7760 - val_loss: 0.4822 - val_accuracy: 0.7708\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7760 - val_loss: 0.4822 - val_accuracy: 0.7708\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7760 - val_loss: 0.4822 - val_accuracy: 0.7708\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7760 - val_loss: 0.4821 - val_accuracy: 0.7708\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7760 - val_loss: 0.4821 - val_accuracy: 0.7708\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7760 - val_loss: 0.4821 - val_accuracy: 0.7708\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7760 - val_loss: 0.4821 - val_accuracy: 0.7708\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7760 - val_loss: 0.4821 - val_accuracy: 0.7708\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7760 - val_loss: 0.4820 - val_accuracy: 0.7708\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7708\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7708\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7760 - val_loss: 0.4820 - val_accuracy: 0.7708\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7760 - val_loss: 0.4820 - val_accuracy: 0.7708\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7760 - val_loss: 0.4819 - val_accuracy: 0.7708\n",
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7760 - val_loss: 0.4819 - val_accuracy: 0.7708\n",
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7778 - val_loss: 0.4819 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7760 - val_loss: 0.4819 - val_accuracy: 0.7708\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7778 - val_loss: 0.4819 - val_accuracy: 0.7708\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7760 - val_loss: 0.4818 - val_accuracy: 0.7708\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7778 - val_loss: 0.4818 - val_accuracy: 0.7708\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.7778 - val_loss: 0.4818 - val_accuracy: 0.7708\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7778 - val_loss: 0.4818 - val_accuracy: 0.7708\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7760 - val_loss: 0.4818 - val_accuracy: 0.7708\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7778 - val_loss: 0.4817 - val_accuracy: 0.7708\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7778 - val_loss: 0.4817 - val_accuracy: 0.7708\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7778 - val_loss: 0.4817 - val_accuracy: 0.7708\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7778 - val_loss: 0.4817 - val_accuracy: 0.7708\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7778 - val_loss: 0.4817 - val_accuracy: 0.7708\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7778 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7812 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7778 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7778 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7778 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7795 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7812 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7795 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7778 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7795 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7795 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7795 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7812 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7812 - val_loss: 0.4814 - val_accuracy: 0.7708\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7812 - val_loss: 0.4814 - val_accuracy: 0.7708\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7812 - val_loss: 0.4814 - val_accuracy: 0.7708\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7795 - val_loss: 0.4814 - val_accuracy: 0.7708\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7812 - val_loss: 0.4814 - val_accuracy: 0.7708\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7830 - val_loss: 0.4813 - val_accuracy: 0.7708\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7830 - val_loss: 0.4813 - val_accuracy: 0.7708\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7812 - val_loss: 0.4813 - val_accuracy: 0.7708\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7812 - val_loss: 0.4813 - val_accuracy: 0.7708\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7830 - val_loss: 0.4813 - val_accuracy: 0.7708\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7812 - val_loss: 0.4813 - val_accuracy: 0.7708\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7812 - val_loss: 0.4812 - val_accuracy: 0.7708\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7830 - val_loss: 0.4812 - val_accuracy: 0.7708\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7830 - val_loss: 0.4812 - val_accuracy: 0.7708\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7830 - val_loss: 0.4812 - val_accuracy: 0.7708\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7830 - val_loss: 0.4812 - val_accuracy: 0.7708\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7830 - val_loss: 0.4811 - val_accuracy: 0.7708\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7830 - val_loss: 0.4811 - val_accuracy: 0.7708\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7830 - val_loss: 0.4811 - val_accuracy: 0.7708\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7847 - val_loss: 0.4811 - val_accuracy: 0.7708\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7830 - val_loss: 0.4811 - val_accuracy: 0.7708\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7830 - val_loss: 0.4810 - val_accuracy: 0.7708\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7830 - val_loss: 0.4810 - val_accuracy: 0.7708\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7847 - val_loss: 0.4810 - val_accuracy: 0.7708\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7830 - val_loss: 0.4810 - val_accuracy: 0.7708\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.7847 - val_loss: 0.4810 - val_accuracy: 0.7708\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7830 - val_loss: 0.4810 - val_accuracy: 0.7708\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7812 - val_loss: 0.4810 - val_accuracy: 0.7708\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7830 - val_loss: 0.4809 - val_accuracy: 0.7708\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7847 - val_loss: 0.4809 - val_accuracy: 0.7708\n",
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7830 - val_loss: 0.4809 - val_accuracy: 0.7708\n",
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7847 - val_loss: 0.4809 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7830 - val_loss: 0.4809 - val_accuracy: 0.7708\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7830 - val_loss: 0.4809 - val_accuracy: 0.7708\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7847 - val_loss: 0.4809 - val_accuracy: 0.7708\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7830 - val_loss: 0.4808 - val_accuracy: 0.7708\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7847 - val_loss: 0.4808 - val_accuracy: 0.7708\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7847 - val_loss: 0.4808 - val_accuracy: 0.7708\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7847 - val_loss: 0.4808 - val_accuracy: 0.7708\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7830 - val_loss: 0.4808 - val_accuracy: 0.7708\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7847 - val_loss: 0.4808 - val_accuracy: 0.7708\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7830 - val_loss: 0.4807 - val_accuracy: 0.7708\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7830 - val_loss: 0.4807 - val_accuracy: 0.7708\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7830 - val_loss: 0.4807 - val_accuracy: 0.7708\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7830 - val_loss: 0.4807 - val_accuracy: 0.7708\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7847 - val_loss: 0.4807 - val_accuracy: 0.7708\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7847 - val_loss: 0.4807 - val_accuracy: 0.7708\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7847 - val_loss: 0.4806 - val_accuracy: 0.7708\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7847 - val_loss: 0.4806 - val_accuracy: 0.7708\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7847 - val_loss: 0.4806 - val_accuracy: 0.7708\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7847 - val_loss: 0.4806 - val_accuracy: 0.7708\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7847 - val_loss: 0.4806 - val_accuracy: 0.7708\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7847 - val_loss: 0.4806 - val_accuracy: 0.7708\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7847 - val_loss: 0.4805 - val_accuracy: 0.7708\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7847 - val_loss: 0.4805 - val_accuracy: 0.7708\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7847 - val_loss: 0.4805 - val_accuracy: 0.7708\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7847 - val_loss: 0.4805 - val_accuracy: 0.7708\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7847 - val_loss: 0.4805 - val_accuracy: 0.7708\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7847 - val_loss: 0.4805 - val_accuracy: 0.7708\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7847 - val_loss: 0.4804 - val_accuracy: 0.7708\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7847 - val_loss: 0.4804 - val_accuracy: 0.7708\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7830 - val_loss: 0.4804 - val_accuracy: 0.7708\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7847 - val_loss: 0.4804 - val_accuracy: 0.7708\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7847 - val_loss: 0.4804 - val_accuracy: 0.7708\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7847 - val_loss: 0.4804 - val_accuracy: 0.7708\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7830 - val_loss: 0.4804 - val_accuracy: 0.7708\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7847 - val_loss: 0.4804 - val_accuracy: 0.7708\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7847 - val_loss: 0.4804 - val_accuracy: 0.7708\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7847 - val_loss: 0.4803 - val_accuracy: 0.7708\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7830 - val_loss: 0.4803 - val_accuracy: 0.7708\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7847 - val_loss: 0.4803 - val_accuracy: 0.7708\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7830 - val_loss: 0.4803 - val_accuracy: 0.7708\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7847 - val_loss: 0.4803 - val_accuracy: 0.7708\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7830 - val_loss: 0.4803 - val_accuracy: 0.7708\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7830 - val_loss: 0.4803 - val_accuracy: 0.7708\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7830 - val_loss: 0.4803 - val_accuracy: 0.7708\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7847 - val_loss: 0.4803 - val_accuracy: 0.7708\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7830 - val_loss: 0.4802 - val_accuracy: 0.7708\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7847 - val_loss: 0.4802 - val_accuracy: 0.7708\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7847 - val_loss: 0.4802 - val_accuracy: 0.7708\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7830 - val_loss: 0.4802 - val_accuracy: 0.7708\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7830 - val_loss: 0.4802 - val_accuracy: 0.7708\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7830 - val_loss: 0.4802 - val_accuracy: 0.7708\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7830 - val_loss: 0.4802 - val_accuracy: 0.7708\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7830 - val_loss: 0.4802 - val_accuracy: 0.7708\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7830 - val_loss: 0.4801 - val_accuracy: 0.7708\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7830 - val_loss: 0.4801 - val_accuracy: 0.7708\n",
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7830 - val_loss: 0.4801 - val_accuracy: 0.7708\n",
      "Epoch 855/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7830 - val_loss: 0.4801 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7830 - val_loss: 0.4801 - val_accuracy: 0.7708\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7830 - val_loss: 0.4801 - val_accuracy: 0.7708\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7830 - val_loss: 0.4801 - val_accuracy: 0.7708\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7830 - val_loss: 0.4801 - val_accuracy: 0.7708\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7830 - val_loss: 0.4801 - val_accuracy: 0.7708\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7830 - val_loss: 0.4800 - val_accuracy: 0.7708\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.7830 - val_loss: 0.4800 - val_accuracy: 0.7708\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7847 - val_loss: 0.4800 - val_accuracy: 0.7708\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7830 - val_loss: 0.4800 - val_accuracy: 0.7708\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7830 - val_loss: 0.4800 - val_accuracy: 0.7708\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7830 - val_loss: 0.4800 - val_accuracy: 0.7708\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7830 - val_loss: 0.4800 - val_accuracy: 0.7708\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7830 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7830 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7830 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7830 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7830 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7830 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7830 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7830 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7830 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7830 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7847 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7830 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7830 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7830 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7830 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7830 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7847 - val_loss: 0.4798 - val_accuracy: 0.7708\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7830 - val_loss: 0.4798 - val_accuracy: 0.7708\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7830 - val_loss: 0.4798 - val_accuracy: 0.7708\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7830 - val_loss: 0.4798 - val_accuracy: 0.7708\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7830 - val_loss: 0.4798 - val_accuracy: 0.7708\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7830 - val_loss: 0.4798 - val_accuracy: 0.7708\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7830 - val_loss: 0.4798 - val_accuracy: 0.7708\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7830 - val_loss: 0.4798 - val_accuracy: 0.7708\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7847 - val_loss: 0.4798 - val_accuracy: 0.7708\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7847 - val_loss: 0.4798 - val_accuracy: 0.7708\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7830 - val_loss: 0.4798 - val_accuracy: 0.7708\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7830 - val_loss: 0.4798 - val_accuracy: 0.7708\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7830 - val_loss: 0.4797 - val_accuracy: 0.7708\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7830 - val_loss: 0.4797 - val_accuracy: 0.7708\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7830 - val_loss: 0.4797 - val_accuracy: 0.7708\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7865 - val_loss: 0.4797 - val_accuracy: 0.7708\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7847 - val_loss: 0.4797 - val_accuracy: 0.7708\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7847 - val_loss: 0.4797 - val_accuracy: 0.7708\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7830 - val_loss: 0.4797 - val_accuracy: 0.7708\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7830 - val_loss: 0.4797 - val_accuracy: 0.7708\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7830 - val_loss: 0.4797 - val_accuracy: 0.7708\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7847 - val_loss: 0.4797 - val_accuracy: 0.7708\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7865 - val_loss: 0.4797 - val_accuracy: 0.7708\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7830 - val_loss: 0.4797 - val_accuracy: 0.7708\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7830 - val_loss: 0.4797 - val_accuracy: 0.7708\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7847 - val_loss: 0.4796 - val_accuracy: 0.7708\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7865 - val_loss: 0.4796 - val_accuracy: 0.7708\n",
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7865 - val_loss: 0.4796 - val_accuracy: 0.7708\n",
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7847 - val_loss: 0.4796 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7865 - val_loss: 0.4796 - val_accuracy: 0.7708\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7865 - val_loss: 0.4796 - val_accuracy: 0.7708\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7865 - val_loss: 0.4796 - val_accuracy: 0.7708\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7847 - val_loss: 0.4796 - val_accuracy: 0.7708\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7865 - val_loss: 0.4796 - val_accuracy: 0.7708\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7865 - val_loss: 0.4796 - val_accuracy: 0.7708\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7865 - val_loss: 0.4795 - val_accuracy: 0.7708\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7847 - val_loss: 0.4795 - val_accuracy: 0.7708\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7865 - val_loss: 0.4795 - val_accuracy: 0.7708\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7865 - val_loss: 0.4795 - val_accuracy: 0.7708\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7865 - val_loss: 0.4795 - val_accuracy: 0.7708\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7865 - val_loss: 0.4795 - val_accuracy: 0.7708\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7865 - val_loss: 0.4795 - val_accuracy: 0.7708\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7865 - val_loss: 0.4795 - val_accuracy: 0.7708\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7865 - val_loss: 0.4795 - val_accuracy: 0.7708\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7865 - val_loss: 0.4795 - val_accuracy: 0.7708\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7865 - val_loss: 0.4794 - val_accuracy: 0.7708\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7865 - val_loss: 0.4794 - val_accuracy: 0.7708\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7865 - val_loss: 0.4794 - val_accuracy: 0.7708\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7865 - val_loss: 0.4794 - val_accuracy: 0.7708\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7865 - val_loss: 0.4794 - val_accuracy: 0.7708\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7847 - val_loss: 0.4794 - val_accuracy: 0.7708\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7865 - val_loss: 0.4793 - val_accuracy: 0.7708\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7865 - val_loss: 0.4793 - val_accuracy: 0.7708\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7865 - val_loss: 0.4793 - val_accuracy: 0.7708\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7865 - val_loss: 0.4793 - val_accuracy: 0.7708\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7865 - val_loss: 0.4793 - val_accuracy: 0.7708\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7865 - val_loss: 0.4793 - val_accuracy: 0.7708\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7847 - val_loss: 0.4793 - val_accuracy: 0.7708\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7847 - val_loss: 0.4792 - val_accuracy: 0.7708\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7847 - val_loss: 0.4792 - val_accuracy: 0.7708\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7865 - val_loss: 0.4792 - val_accuracy: 0.7708\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7847 - val_loss: 0.4792 - val_accuracy: 0.7708\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7847 - val_loss: 0.4792 - val_accuracy: 0.7708\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7865 - val_loss: 0.4792 - val_accuracy: 0.7708\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7865 - val_loss: 0.4791 - val_accuracy: 0.7708\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7847 - val_loss: 0.4791 - val_accuracy: 0.7708\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7865 - val_loss: 0.4791 - val_accuracy: 0.7708\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7865 - val_loss: 0.4791 - val_accuracy: 0.7708\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7865 - val_loss: 0.4791 - val_accuracy: 0.7708\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7847 - val_loss: 0.4791 - val_accuracy: 0.7708\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7847 - val_loss: 0.4790 - val_accuracy: 0.7708\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7847 - val_loss: 0.4790 - val_accuracy: 0.7708\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7847 - val_loss: 0.4790 - val_accuracy: 0.7708\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.4790 - val_accuracy: 0.7708\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7847 - val_loss: 0.4790 - val_accuracy: 0.7708\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7847 - val_loss: 0.4790 - val_accuracy: 0.7708\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7847 - val_loss: 0.4790 - val_accuracy: 0.7708\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.4790 - val_accuracy: 0.7708\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.4789 - val_accuracy: 0.7708\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.4789 - val_accuracy: 0.7708\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7847 - val_loss: 0.4789 - val_accuracy: 0.7708\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.4789 - val_accuracy: 0.7708\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7847 - val_loss: 0.4789 - val_accuracy: 0.7708\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7847 - val_loss: 0.4789 - val_accuracy: 0.7708\n",
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7847 - val_loss: 0.4789 - val_accuracy: 0.7708\n",
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7847 - val_loss: 0.4789 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.4789 - val_accuracy: 0.7708\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7847 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7847 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7847 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7847 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7847 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7812 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7847 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7847 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7847 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7847 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7847 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7847 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7847 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7847 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7847 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7847 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7847 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7812 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7847 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7847 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7847 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7847 - val_loss: 0.4788 - val_accuracy: 0.7708\n",
      "Epoch 1024/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7847 - val_loss: 0.4788 - val_accuracy: 0.7760\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7760\n",
      "Epoch 1026/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7847 - val_loss: 0.4788 - val_accuracy: 0.7760\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7847 - val_loss: 0.4788 - val_accuracy: 0.7760\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7847 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7847 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7830 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7847 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7847 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7847 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7847 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7847 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7882 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7830 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7847 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7865 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7847 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7847 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7830 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7847 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7865 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7847 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7830 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7865 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7865 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7865 - val_loss: 0.4788 - val_accuracy: 0.7760\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7865 - val_loss: 0.4788 - val_accuracy: 0.7760\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7865 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7865 - val_loss: 0.4788 - val_accuracy: 0.7760\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7847 - val_loss: 0.4788 - val_accuracy: 0.7760\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7865 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7865 - val_loss: 0.4788 - val_accuracy: 0.7760\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7865 - val_loss: 0.4788 - val_accuracy: 0.7760\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7865 - val_loss: 0.4788 - val_accuracy: 0.7760\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7865 - val_loss: 0.4788 - val_accuracy: 0.7760\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7847 - val_loss: 0.4788 - val_accuracy: 0.7760\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7865 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7865 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7865 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7847 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7865 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7865 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7865 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7865 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7847 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7847 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7847 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7847 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7847 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7865 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7865 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7865 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7847 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7865 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7865 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1080/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7865 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1082/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7865 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1083/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7847 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7865 - val_loss: 0.4786 - val_accuracy: 0.7760\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7847 - val_loss: 0.4786 - val_accuracy: 0.7760\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7847 - val_loss: 0.4786 - val_accuracy: 0.7760\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7847 - val_loss: 0.4786 - val_accuracy: 0.7760\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.4786 - val_accuracy: 0.7760\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7865 - val_loss: 0.4786 - val_accuracy: 0.7760\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7865 - val_loss: 0.4786 - val_accuracy: 0.7760\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7847 - val_loss: 0.4786 - val_accuracy: 0.7760\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4786 - val_accuracy: 0.7760\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7847 - val_loss: 0.4786 - val_accuracy: 0.7760\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7865 - val_loss: 0.4786 - val_accuracy: 0.7760\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7847 - val_loss: 0.4786 - val_accuracy: 0.7812\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7865 - val_loss: 0.4785 - val_accuracy: 0.7812\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7847 - val_loss: 0.4785 - val_accuracy: 0.7812\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7830 - val_loss: 0.4785 - val_accuracy: 0.7812\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7830 - val_loss: 0.4785 - val_accuracy: 0.7812\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4785 - val_accuracy: 0.7812\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7865 - val_loss: 0.4785 - val_accuracy: 0.7812\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7847 - val_loss: 0.4785 - val_accuracy: 0.7812\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7847 - val_loss: 0.4785 - val_accuracy: 0.7812\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4785 - val_accuracy: 0.7812\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.4785 - val_accuracy: 0.7812\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7847 - val_loss: 0.4785 - val_accuracy: 0.7812\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7847 - val_loss: 0.4784 - val_accuracy: 0.7812\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.4784 - val_accuracy: 0.7812\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7865 - val_loss: 0.4784 - val_accuracy: 0.7812\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7830 - val_loss: 0.4784 - val_accuracy: 0.7812\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7830 - val_loss: 0.4784 - val_accuracy: 0.7812\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7847 - val_loss: 0.4784 - val_accuracy: 0.7812\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7847 - val_loss: 0.4784 - val_accuracy: 0.7812\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7847 - val_loss: 0.4784 - val_accuracy: 0.7812\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7830 - val_loss: 0.4783 - val_accuracy: 0.7812\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7847 - val_loss: 0.4783 - val_accuracy: 0.7812\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7847 - val_loss: 0.4783 - val_accuracy: 0.7812\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7865 - val_loss: 0.4783 - val_accuracy: 0.7812\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7882 - val_loss: 0.4783 - val_accuracy: 0.7812\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7865 - val_loss: 0.4783 - val_accuracy: 0.7812\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7847 - val_loss: 0.4783 - val_accuracy: 0.7812\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7847 - val_loss: 0.4783 - val_accuracy: 0.7812\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7865 - val_loss: 0.4783 - val_accuracy: 0.7812\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7847 - val_loss: 0.4783 - val_accuracy: 0.7812\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7847 - val_loss: 0.4783 - val_accuracy: 0.7812\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7847 - val_loss: 0.4782 - val_accuracy: 0.7812\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7865 - val_loss: 0.4783 - val_accuracy: 0.7812\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7865 - val_loss: 0.4783 - val_accuracy: 0.7812\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7865 - val_loss: 0.4782 - val_accuracy: 0.7812\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7865 - val_loss: 0.4782 - val_accuracy: 0.7812\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7847 - val_loss: 0.4782 - val_accuracy: 0.7812\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7865 - val_loss: 0.4782 - val_accuracy: 0.7812\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7865 - val_loss: 0.4782 - val_accuracy: 0.7812\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7865 - val_loss: 0.4782 - val_accuracy: 0.7812\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7865 - val_loss: 0.4782 - val_accuracy: 0.7812\n",
      "Epoch 1136/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7865 - val_loss: 0.4782 - val_accuracy: 0.7812\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7865 - val_loss: 0.4782 - val_accuracy: 0.7812\n",
      "Epoch 1138/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7865 - val_loss: 0.4782 - val_accuracy: 0.7812\n",
      "Epoch 1139/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7865 - val_loss: 0.4782 - val_accuracy: 0.7812\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7865 - val_loss: 0.4782 - val_accuracy: 0.7812\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7847 - val_loss: 0.4782 - val_accuracy: 0.7812\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7865 - val_loss: 0.4782 - val_accuracy: 0.7812\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7865 - val_loss: 0.4782 - val_accuracy: 0.7812\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7865 - val_loss: 0.4782 - val_accuracy: 0.7812\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7865 - val_loss: 0.4782 - val_accuracy: 0.7812\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7847 - val_loss: 0.4782 - val_accuracy: 0.7812\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7865 - val_loss: 0.4782 - val_accuracy: 0.7812\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7865 - val_loss: 0.4782 - val_accuracy: 0.7812\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7882 - val_loss: 0.4782 - val_accuracy: 0.7812\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7865 - val_loss: 0.4782 - val_accuracy: 0.7812\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7865 - val_loss: 0.4782 - val_accuracy: 0.7812\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7865 - val_loss: 0.4782 - val_accuracy: 0.7812\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7882 - val_loss: 0.4782 - val_accuracy: 0.7812\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7865 - val_loss: 0.4782 - val_accuracy: 0.7812\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7847 - val_loss: 0.4782 - val_accuracy: 0.7812\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7865 - val_loss: 0.4781 - val_accuracy: 0.7812\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7865 - val_loss: 0.4781 - val_accuracy: 0.7812\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7865 - val_loss: 0.4781 - val_accuracy: 0.7812\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7865 - val_loss: 0.4781 - val_accuracy: 0.7812\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7865 - val_loss: 0.4781 - val_accuracy: 0.7812\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7865 - val_loss: 0.4781 - val_accuracy: 0.7812\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7847 - val_loss: 0.4781 - val_accuracy: 0.7812\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7865 - val_loss: 0.4781 - val_accuracy: 0.7812\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7882 - val_loss: 0.4781 - val_accuracy: 0.7812\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7865 - val_loss: 0.4781 - val_accuracy: 0.7812\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7865 - val_loss: 0.4781 - val_accuracy: 0.7812\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7865 - val_loss: 0.4781 - val_accuracy: 0.7812\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7847 - val_loss: 0.4781 - val_accuracy: 0.7812\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7865 - val_loss: 0.4781 - val_accuracy: 0.7812\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7865 - val_loss: 0.4781 - val_accuracy: 0.7812\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7865 - val_loss: 0.4781 - val_accuracy: 0.7812\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7865 - val_loss: 0.4781 - val_accuracy: 0.7812\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7865 - val_loss: 0.4781 - val_accuracy: 0.7812\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7847 - val_loss: 0.4781 - val_accuracy: 0.7812\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7865 - val_loss: 0.4780 - val_accuracy: 0.7812\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7847 - val_loss: 0.4780 - val_accuracy: 0.7812\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7865 - val_loss: 0.4780 - val_accuracy: 0.7812\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7865 - val_loss: 0.4780 - val_accuracy: 0.7812\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7865 - val_loss: 0.4780 - val_accuracy: 0.7812\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7847 - val_loss: 0.4780 - val_accuracy: 0.7812\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7847 - val_loss: 0.4780 - val_accuracy: 0.7812\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7865 - val_loss: 0.4780 - val_accuracy: 0.7812\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7830 - val_loss: 0.4780 - val_accuracy: 0.7760\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7847 - val_loss: 0.4779 - val_accuracy: 0.7760\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7865 - val_loss: 0.4779 - val_accuracy: 0.7760\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7847 - val_loss: 0.4779 - val_accuracy: 0.7760\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7847 - val_loss: 0.4779 - val_accuracy: 0.7760\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7865 - val_loss: 0.4779 - val_accuracy: 0.7760\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7865 - val_loss: 0.4779 - val_accuracy: 0.7760\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7847 - val_loss: 0.4779 - val_accuracy: 0.7760\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7865 - val_loss: 0.4779 - val_accuracy: 0.7760\n",
      "Epoch 1192/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7865 - val_loss: 0.4779 - val_accuracy: 0.7760\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7865 - val_loss: 0.4779 - val_accuracy: 0.7760\n",
      "Epoch 1194/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7865 - val_loss: 0.4778 - val_accuracy: 0.7760\n",
      "Epoch 1195/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7882 - val_loss: 0.4778 - val_accuracy: 0.7760\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7882 - val_loss: 0.4778 - val_accuracy: 0.7760\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7847 - val_loss: 0.4778 - val_accuracy: 0.7760\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7865 - val_loss: 0.4778 - val_accuracy: 0.7760\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7865 - val_loss: 0.4778 - val_accuracy: 0.7760\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7865 - val_loss: 0.4778 - val_accuracy: 0.7760\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7865 - val_loss: 0.4778 - val_accuracy: 0.7760\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7865 - val_loss: 0.4778 - val_accuracy: 0.7760\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7865 - val_loss: 0.4778 - val_accuracy: 0.7760\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7847 - val_loss: 0.4778 - val_accuracy: 0.7760\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7865 - val_loss: 0.4777 - val_accuracy: 0.7760\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7865 - val_loss: 0.4777 - val_accuracy: 0.7760\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7865 - val_loss: 0.4777 - val_accuracy: 0.7760\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7865 - val_loss: 0.4777 - val_accuracy: 0.7760\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7865 - val_loss: 0.4777 - val_accuracy: 0.7760\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7865 - val_loss: 0.4777 - val_accuracy: 0.7760\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7865 - val_loss: 0.4777 - val_accuracy: 0.7760\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7847 - val_loss: 0.4777 - val_accuracy: 0.7760\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7847 - val_loss: 0.4776 - val_accuracy: 0.7760\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7847 - val_loss: 0.4776 - val_accuracy: 0.7760\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7865 - val_loss: 0.4776 - val_accuracy: 0.7760\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7847 - val_loss: 0.4776 - val_accuracy: 0.7760\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7847 - val_loss: 0.4776 - val_accuracy: 0.7760\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7847 - val_loss: 0.4776 - val_accuracy: 0.7760\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7865 - val_loss: 0.4776 - val_accuracy: 0.7760\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7865 - val_loss: 0.4776 - val_accuracy: 0.7760\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7865 - val_loss: 0.4776 - val_accuracy: 0.7760\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7847 - val_loss: 0.4776 - val_accuracy: 0.7760\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7847 - val_loss: 0.4776 - val_accuracy: 0.7760\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7865 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7865 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7865 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7847 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7865 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7847 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7865 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7865 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7865 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7865 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7847 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7865 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7865 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7865 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7865 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7865 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7865 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7865 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7865 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7865 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7865 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7865 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7865 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7865 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1248/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7865 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7865 - val_loss: 0.4773 - val_accuracy: 0.7760\n",
      "Epoch 1250/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7865 - val_loss: 0.4773 - val_accuracy: 0.7760\n",
      "Epoch 1251/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7865 - val_loss: 0.4773 - val_accuracy: 0.7760\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7882 - val_loss: 0.4773 - val_accuracy: 0.7812\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7865 - val_loss: 0.4773 - val_accuracy: 0.7865\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7865 - val_loss: 0.4773 - val_accuracy: 0.7865\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7865 - val_loss: 0.4773 - val_accuracy: 0.7865\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7865 - val_loss: 0.4773 - val_accuracy: 0.7812\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7865 - val_loss: 0.4773 - val_accuracy: 0.7812\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7865 - val_loss: 0.4773 - val_accuracy: 0.7812\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7865 - val_loss: 0.4773 - val_accuracy: 0.7812\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7882 - val_loss: 0.4773 - val_accuracy: 0.7865\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7865 - val_loss: 0.4773 - val_accuracy: 0.7865\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7865 - val_loss: 0.4773 - val_accuracy: 0.7812\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7882 - val_loss: 0.4773 - val_accuracy: 0.7865\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7865 - val_loss: 0.4772 - val_accuracy: 0.7812\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7882 - val_loss: 0.4772 - val_accuracy: 0.7812\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7882 - val_loss: 0.4772 - val_accuracy: 0.7865\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7882 - val_loss: 0.4772 - val_accuracy: 0.7865\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7882 - val_loss: 0.4772 - val_accuracy: 0.7865\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7899 - val_loss: 0.4772 - val_accuracy: 0.7865\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7865 - val_loss: 0.4772 - val_accuracy: 0.7865\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7899 - val_loss: 0.4772 - val_accuracy: 0.7865\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7899 - val_loss: 0.4772 - val_accuracy: 0.7865\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7882 - val_loss: 0.4772 - val_accuracy: 0.7865\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7899 - val_loss: 0.4772 - val_accuracy: 0.7865\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7882 - val_loss: 0.4771 - val_accuracy: 0.7865\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7882 - val_loss: 0.4771 - val_accuracy: 0.7865\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7882 - val_loss: 0.4771 - val_accuracy: 0.7865\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7882 - val_loss: 0.4771 - val_accuracy: 0.7865\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7882 - val_loss: 0.4771 - val_accuracy: 0.7865\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7882 - val_loss: 0.4771 - val_accuracy: 0.7865\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7882 - val_loss: 0.4771 - val_accuracy: 0.7812\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7899 - val_loss: 0.4771 - val_accuracy: 0.7812\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7899 - val_loss: 0.4770 - val_accuracy: 0.7812\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7882 - val_loss: 0.4770 - val_accuracy: 0.7812\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7899 - val_loss: 0.4770 - val_accuracy: 0.7812\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7899 - val_loss: 0.4770 - val_accuracy: 0.7865\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7882 - val_loss: 0.4770 - val_accuracy: 0.7812\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7917 - val_loss: 0.4770 - val_accuracy: 0.7865\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7882 - val_loss: 0.4770 - val_accuracy: 0.7812\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7882 - val_loss: 0.4769 - val_accuracy: 0.7812\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7917 - val_loss: 0.4769 - val_accuracy: 0.7812\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7899 - val_loss: 0.4769 - val_accuracy: 0.7812\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7917 - val_loss: 0.4769 - val_accuracy: 0.7812\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7899 - val_loss: 0.4769 - val_accuracy: 0.7812\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7899 - val_loss: 0.4769 - val_accuracy: 0.7812\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7882 - val_loss: 0.4769 - val_accuracy: 0.7812\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7917 - val_loss: 0.4769 - val_accuracy: 0.7812\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7882 - val_loss: 0.4768 - val_accuracy: 0.7812\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7917 - val_loss: 0.4768 - val_accuracy: 0.7812\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7917 - val_loss: 0.4768 - val_accuracy: 0.7812\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7917 - val_loss: 0.4768 - val_accuracy: 0.7812\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7917 - val_loss: 0.4768 - val_accuracy: 0.7812\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7917 - val_loss: 0.4768 - val_accuracy: 0.7812\n",
      "Epoch 1304/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7917 - val_loss: 0.4768 - val_accuracy: 0.7812\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7917 - val_loss: 0.4768 - val_accuracy: 0.7760\n",
      "Epoch 1306/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7917 - val_loss: 0.4768 - val_accuracy: 0.7812\n",
      "Epoch 1307/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7917 - val_loss: 0.4768 - val_accuracy: 0.7760\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7917 - val_loss: 0.4768 - val_accuracy: 0.7760\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7917 - val_loss: 0.4767 - val_accuracy: 0.7760\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7917 - val_loss: 0.4767 - val_accuracy: 0.7760\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7917 - val_loss: 0.4767 - val_accuracy: 0.7760\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7917 - val_loss: 0.4767 - val_accuracy: 0.7760\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7917 - val_loss: 0.4767 - val_accuracy: 0.7760\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7917 - val_loss: 0.4767 - val_accuracy: 0.7812\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7917 - val_loss: 0.4767 - val_accuracy: 0.7812\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7882 - val_loss: 0.4767 - val_accuracy: 0.7760\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7917 - val_loss: 0.4767 - val_accuracy: 0.7760\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7917 - val_loss: 0.4766 - val_accuracy: 0.7760\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7917 - val_loss: 0.4766 - val_accuracy: 0.7760\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7917 - val_loss: 0.4766 - val_accuracy: 0.7760\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7917 - val_loss: 0.4766 - val_accuracy: 0.7760\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7917 - val_loss: 0.4766 - val_accuracy: 0.7760\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7917 - val_loss: 0.4766 - val_accuracy: 0.7760\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7917 - val_loss: 0.4766 - val_accuracy: 0.7760\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7917 - val_loss: 0.4765 - val_accuracy: 0.7760\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7917 - val_loss: 0.4765 - val_accuracy: 0.7760\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7917 - val_loss: 0.4765 - val_accuracy: 0.7760\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7917 - val_loss: 0.4765 - val_accuracy: 0.7760\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7917 - val_loss: 0.4765 - val_accuracy: 0.7760\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7917 - val_loss: 0.4765 - val_accuracy: 0.7812\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7917 - val_loss: 0.4765 - val_accuracy: 0.7760\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7917 - val_loss: 0.4764 - val_accuracy: 0.7760\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7917 - val_loss: 0.4764 - val_accuracy: 0.7760\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7917 - val_loss: 0.4764 - val_accuracy: 0.7760\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7917 - val_loss: 0.4764 - val_accuracy: 0.7760\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7917 - val_loss: 0.4764 - val_accuracy: 0.7760\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7917 - val_loss: 0.4764 - val_accuracy: 0.7760\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7917 - val_loss: 0.4764 - val_accuracy: 0.7760\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7917 - val_loss: 0.4764 - val_accuracy: 0.7760\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7917 - val_loss: 0.4764 - val_accuracy: 0.7760\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7917 - val_loss: 0.4763 - val_accuracy: 0.7760\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7917 - val_loss: 0.4763 - val_accuracy: 0.7760\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7917 - val_loss: 0.4763 - val_accuracy: 0.7760\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7917 - val_loss: 0.4763 - val_accuracy: 0.7760\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7917 - val_loss: 0.4763 - val_accuracy: 0.7760\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7917 - val_loss: 0.4763 - val_accuracy: 0.7760\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7917 - val_loss: 0.4763 - val_accuracy: 0.7760\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7917 - val_loss: 0.4763 - val_accuracy: 0.7760\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7917 - val_loss: 0.4763 - val_accuracy: 0.7760\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7917 - val_loss: 0.4763 - val_accuracy: 0.7760\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7917 - val_loss: 0.4763 - val_accuracy: 0.7760\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7917 - val_loss: 0.4763 - val_accuracy: 0.7760\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7917 - val_loss: 0.4762 - val_accuracy: 0.7760\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7917 - val_loss: 0.4762 - val_accuracy: 0.7760\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7917 - val_loss: 0.4762 - val_accuracy: 0.7760\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7934 - val_loss: 0.4762 - val_accuracy: 0.7760\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7934 - val_loss: 0.4762 - val_accuracy: 0.7760\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7917 - val_loss: 0.4762 - val_accuracy: 0.7760\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7917 - val_loss: 0.4762 - val_accuracy: 0.7760\n",
      "Epoch 1360/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7934 - val_loss: 0.4762 - val_accuracy: 0.7760\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7917 - val_loss: 0.4762 - val_accuracy: 0.7760\n",
      "Epoch 1362/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7934 - val_loss: 0.4762 - val_accuracy: 0.7760\n",
      "Epoch 1363/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7934 - val_loss: 0.4762 - val_accuracy: 0.7760\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7951 - val_loss: 0.4762 - val_accuracy: 0.7760\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7917 - val_loss: 0.4762 - val_accuracy: 0.7760\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7934 - val_loss: 0.4762 - val_accuracy: 0.7760\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7917 - val_loss: 0.4762 - val_accuracy: 0.7760\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7951 - val_loss: 0.4762 - val_accuracy: 0.7760\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7934 - val_loss: 0.4762 - val_accuracy: 0.7760\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7934 - val_loss: 0.4761 - val_accuracy: 0.7760\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7951 - val_loss: 0.4761 - val_accuracy: 0.7760\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7934 - val_loss: 0.4761 - val_accuracy: 0.7760\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7934 - val_loss: 0.4761 - val_accuracy: 0.7760\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7951 - val_loss: 0.4761 - val_accuracy: 0.7760\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7934 - val_loss: 0.4761 - val_accuracy: 0.7760\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7934 - val_loss: 0.4761 - val_accuracy: 0.7760\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7934 - val_loss: 0.4761 - val_accuracy: 0.7760\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7934 - val_loss: 0.4761 - val_accuracy: 0.7760\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7934 - val_loss: 0.4761 - val_accuracy: 0.7760\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7934 - val_loss: 0.4761 - val_accuracy: 0.7760\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7951 - val_loss: 0.4761 - val_accuracy: 0.7760\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7934 - val_loss: 0.4761 - val_accuracy: 0.7760\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7934 - val_loss: 0.4761 - val_accuracy: 0.7760\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7934 - val_loss: 0.4761 - val_accuracy: 0.7760\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7951 - val_loss: 0.4760 - val_accuracy: 0.7760\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7934 - val_loss: 0.4760 - val_accuracy: 0.7760\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7934 - val_loss: 0.4760 - val_accuracy: 0.7760\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7951 - val_loss: 0.4760 - val_accuracy: 0.7760\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7951 - val_loss: 0.4760 - val_accuracy: 0.7760\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7934 - val_loss: 0.4760 - val_accuracy: 0.7760\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7951 - val_loss: 0.4760 - val_accuracy: 0.7760\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7951 - val_loss: 0.4760 - val_accuracy: 0.7760\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7951 - val_loss: 0.4760 - val_accuracy: 0.7760\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7951 - val_loss: 0.4760 - val_accuracy: 0.7760\n",
      "Epoch 1395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7951 - val_loss: 0.4760 - val_accuracy: 0.7760\n",
      "Epoch 1396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7934 - val_loss: 0.4760 - val_accuracy: 0.7760\n",
      "Epoch 1397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7951 - val_loss: 0.4760 - val_accuracy: 0.7760\n",
      "Epoch 1398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7951 - val_loss: 0.4759 - val_accuracy: 0.7760\n",
      "Epoch 1399/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7951 - val_loss: 0.4759 - val_accuracy: 0.7760\n",
      "Epoch 1400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7951 - val_loss: 0.4759 - val_accuracy: 0.7760\n",
      "Epoch 1401/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7951 - val_loss: 0.4759 - val_accuracy: 0.7760\n",
      "Epoch 1402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7951 - val_loss: 0.4759 - val_accuracy: 0.7760\n",
      "Epoch 1403/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7951 - val_loss: 0.4759 - val_accuracy: 0.7760\n",
      "Epoch 1404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7951 - val_loss: 0.4759 - val_accuracy: 0.7760\n",
      "Epoch 1405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7951 - val_loss: 0.4759 - val_accuracy: 0.7708\n",
      "Epoch 1406/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7934 - val_loss: 0.4759 - val_accuracy: 0.7708\n",
      "Epoch 1407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7951 - val_loss: 0.4759 - val_accuracy: 0.7708\n",
      "Epoch 1408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7951 - val_loss: 0.4759 - val_accuracy: 0.7708\n",
      "Epoch 1409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7951 - val_loss: 0.4759 - val_accuracy: 0.7708\n",
      "Epoch 1410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7951 - val_loss: 0.4758 - val_accuracy: 0.7708\n",
      "Epoch 1411/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7934 - val_loss: 0.4758 - val_accuracy: 0.7708\n",
      "Epoch 1412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7951 - val_loss: 0.4758 - val_accuracy: 0.7708\n",
      "Epoch 1413/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7951 - val_loss: 0.4758 - val_accuracy: 0.7656\n",
      "Epoch 1414/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7951 - val_loss: 0.4758 - val_accuracy: 0.7656\n",
      "Epoch 1415/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7934 - val_loss: 0.4758 - val_accuracy: 0.7656\n",
      "Epoch 1416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7951 - val_loss: 0.4758 - val_accuracy: 0.7656\n",
      "Epoch 1417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7951 - val_loss: 0.4758 - val_accuracy: 0.7656\n",
      "Epoch 1418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7951 - val_loss: 0.4758 - val_accuracy: 0.7656\n",
      "Epoch 1419/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7934 - val_loss: 0.4758 - val_accuracy: 0.7656\n",
      "Epoch 1420/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7951 - val_loss: 0.4758 - val_accuracy: 0.7656\n",
      "Epoch 1421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7951 - val_loss: 0.4758 - val_accuracy: 0.7656\n",
      "Epoch 1422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7951 - val_loss: 0.4758 - val_accuracy: 0.7656\n",
      "Epoch 1423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7951 - val_loss: 0.4758 - val_accuracy: 0.7656\n",
      "Epoch 1424/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7951 - val_loss: 0.4757 - val_accuracy: 0.7656\n",
      "Epoch 1425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7951 - val_loss: 0.4757 - val_accuracy: 0.7656\n",
      "Epoch 1426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7934 - val_loss: 0.4757 - val_accuracy: 0.7656\n",
      "Epoch 1427/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7951 - val_loss: 0.4757 - val_accuracy: 0.7656\n",
      "Epoch 1428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7951 - val_loss: 0.4757 - val_accuracy: 0.7656\n",
      "Epoch 1429/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7951 - val_loss: 0.4757 - val_accuracy: 0.7656\n",
      "Epoch 1430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7934 - val_loss: 0.4757 - val_accuracy: 0.7656\n",
      "Epoch 1431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7951 - val_loss: 0.4757 - val_accuracy: 0.7656\n",
      "Epoch 1432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7917 - val_loss: 0.4757 - val_accuracy: 0.7656\n",
      "Epoch 1433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7951 - val_loss: 0.4757 - val_accuracy: 0.7656\n",
      "Epoch 1434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7934 - val_loss: 0.4757 - val_accuracy: 0.7656\n",
      "Epoch 1435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7969 - val_loss: 0.4756 - val_accuracy: 0.7656\n",
      "Epoch 1436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7951 - val_loss: 0.4756 - val_accuracy: 0.7656\n",
      "Epoch 1437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7951 - val_loss: 0.4756 - val_accuracy: 0.7656\n",
      "Epoch 1438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7917 - val_loss: 0.4756 - val_accuracy: 0.7656\n",
      "Epoch 1439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.4756 - val_accuracy: 0.7656\n",
      "Epoch 1440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7917 - val_loss: 0.4756 - val_accuracy: 0.7656\n",
      "Epoch 1441/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.4755 - val_accuracy: 0.7656\n",
      "Epoch 1442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7951 - val_loss: 0.4755 - val_accuracy: 0.7656\n",
      "Epoch 1443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7917 - val_loss: 0.4755 - val_accuracy: 0.7656\n",
      "Epoch 1444/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7934 - val_loss: 0.4755 - val_accuracy: 0.7656\n",
      "Epoch 1445/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7917 - val_loss: 0.4755 - val_accuracy: 0.7656\n",
      "Epoch 1446/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7934 - val_loss: 0.4755 - val_accuracy: 0.7656\n",
      "Epoch 1447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7917 - val_loss: 0.4755 - val_accuracy: 0.7656\n",
      "Epoch 1448/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7917 - val_loss: 0.4754 - val_accuracy: 0.7656\n",
      "Epoch 1449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7917 - val_loss: 0.4754 - val_accuracy: 0.7656\n",
      "Epoch 1450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7934 - val_loss: 0.4754 - val_accuracy: 0.7656\n",
      "Epoch 1451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7917 - val_loss: 0.4754 - val_accuracy: 0.7656\n",
      "Epoch 1452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7917 - val_loss: 0.4754 - val_accuracy: 0.7656\n",
      "Epoch 1453/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7917 - val_loss: 0.4754 - val_accuracy: 0.7656\n",
      "Epoch 1454/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7917 - val_loss: 0.4753 - val_accuracy: 0.7656\n",
      "Epoch 1455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7917 - val_loss: 0.4753 - val_accuracy: 0.7656\n",
      "Epoch 1456/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7934 - val_loss: 0.4753 - val_accuracy: 0.7656\n",
      "Epoch 1457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7951 - val_loss: 0.4753 - val_accuracy: 0.7656\n",
      "Epoch 1458/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7934 - val_loss: 0.4753 - val_accuracy: 0.7656\n",
      "Epoch 1459/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7917 - val_loss: 0.4753 - val_accuracy: 0.7656\n",
      "Epoch 1460/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7917 - val_loss: 0.4752 - val_accuracy: 0.7656\n",
      "Epoch 1461/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.4752 - val_accuracy: 0.7656\n",
      "Epoch 1462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7969 - val_loss: 0.4752 - val_accuracy: 0.7656\n",
      "Epoch 1463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7917 - val_loss: 0.4752 - val_accuracy: 0.7656\n",
      "Epoch 1464/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7934 - val_loss: 0.4752 - val_accuracy: 0.7656\n",
      "Epoch 1465/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7934 - val_loss: 0.4752 - val_accuracy: 0.7656\n",
      "Epoch 1466/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7934 - val_loss: 0.4751 - val_accuracy: 0.7656\n",
      "Epoch 1467/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7951 - val_loss: 0.4751 - val_accuracy: 0.7656\n",
      "Epoch 1468/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7934 - val_loss: 0.4751 - val_accuracy: 0.7656\n",
      "Epoch 1469/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7917 - val_loss: 0.4751 - val_accuracy: 0.7656\n",
      "Epoch 1470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7917 - val_loss: 0.4751 - val_accuracy: 0.7656\n",
      "Epoch 1471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7917 - val_loss: 0.4750 - val_accuracy: 0.7656\n",
      "Epoch 1472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7917 - val_loss: 0.4750 - val_accuracy: 0.7656\n",
      "Epoch 1473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7934 - val_loss: 0.4750 - val_accuracy: 0.7656\n",
      "Epoch 1474/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7917 - val_loss: 0.4750 - val_accuracy: 0.7656\n",
      "Epoch 1475/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7951 - val_loss: 0.4750 - val_accuracy: 0.7656\n",
      "Epoch 1476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7934 - val_loss: 0.4750 - val_accuracy: 0.7656\n",
      "Epoch 1477/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7934 - val_loss: 0.4749 - val_accuracy: 0.7656\n",
      "Epoch 1478/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7934 - val_loss: 0.4749 - val_accuracy: 0.7656\n",
      "Epoch 1479/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7934 - val_loss: 0.4749 - val_accuracy: 0.7656\n",
      "Epoch 1480/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7934 - val_loss: 0.4749 - val_accuracy: 0.7656\n",
      "Epoch 1481/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7934 - val_loss: 0.4749 - val_accuracy: 0.7656\n",
      "Epoch 1482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7934 - val_loss: 0.4749 - val_accuracy: 0.7656\n",
      "Epoch 1483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7917 - val_loss: 0.4748 - val_accuracy: 0.7656\n",
      "Epoch 1484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7934 - val_loss: 0.4748 - val_accuracy: 0.7656\n",
      "Epoch 1485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7934 - val_loss: 0.4748 - val_accuracy: 0.7656\n",
      "Epoch 1486/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7917 - val_loss: 0.4748 - val_accuracy: 0.7656\n",
      "Epoch 1487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7934 - val_loss: 0.4748 - val_accuracy: 0.7656\n",
      "Epoch 1488/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7934 - val_loss: 0.4748 - val_accuracy: 0.7656\n",
      "Epoch 1489/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7951 - val_loss: 0.4748 - val_accuracy: 0.7656\n",
      "Epoch 1490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7934 - val_loss: 0.4747 - val_accuracy: 0.7656\n",
      "Epoch 1491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7934 - val_loss: 0.4747 - val_accuracy: 0.7656\n",
      "Epoch 1492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7934 - val_loss: 0.4747 - val_accuracy: 0.7656\n",
      "Epoch 1493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7934 - val_loss: 0.4747 - val_accuracy: 0.7656\n",
      "Epoch 1494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7934 - val_loss: 0.4747 - val_accuracy: 0.7656\n",
      "Epoch 1495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7934 - val_loss: 0.4747 - val_accuracy: 0.7656\n",
      "Epoch 1496/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7934 - val_loss: 0.4747 - val_accuracy: 0.7656\n",
      "Epoch 1497/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7934 - val_loss: 0.4747 - val_accuracy: 0.7656\n",
      "Epoch 1498/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7917 - val_loss: 0.4746 - val_accuracy: 0.7656\n",
      "Epoch 1499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7951 - val_loss: 0.4746 - val_accuracy: 0.7656\n",
      "Epoch 1500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7917 - val_loss: 0.4746 - val_accuracy: 0.7656\n"
     ]
    }
   ],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Dense(6, input_shape=(8,), activation=\"relu\"))\n",
    "model_2.add(Dense(6,  activation=\"relu\"))\n",
    "model_2.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy over iterations')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsIAAAF1CAYAAADiNYyJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABh1klEQVR4nO3de3iU1bn38e+dI6CgglgtWPBcVOQggoMHxuKGqq0HqFWLgto2alsV+7YgdnvYUkWwb0vdupW8bXVTKG5blGqrwjY6YmUK4hEBUVRQPBWDCiqQ03r/WM8kk2QmmSSTzEzy+1zXc83Mc1yTwJo7a+7nXuacQ0RERESkq8nLdANERERERDJBgbCIiIiIdEkKhEVERESkS1IgLCIiIiJdkgJhEREREemSFAiLiIiISJekQFg6PTP73MwOzuD1TzKzDZm6vohIV2Bm95jZ9Rluw1ozC2eyDdIypjrCXYuZbQJ+4Jx7ItNtyQQzuw/Y4pz793a8hgMOc85tbK9riEhuMrMIMATY3zm3O8PN6bSCYHSBc65/O17jPtr580Tan0aEpdMws4LOcA0R6ZzMbCBwEuCAMzv42p2q72rv99PZfl6SnAJhAcDMis1srpm9Hyxzzaw42Lavmf3NzD41s21m9oyZ5QXbppvZe2a2w8w2mNnYJOffy8zmm9lWM9tsZv9uZnnBdT81s6Pj9u1rZjvNbL/g9bfM7KVgvxVmdkzcvpuCNrwCfJGo8zIzZ2aHmlkJMAmYFqRLPBJs/6qZLQ7a9raZXRV37E1m9hczW2Bm24GLzWykmUWD9nxgZneaWVGw//Lg0JeDa5xnZmEz2xJ3zkFmFgmOX2tmZ8Ztu8/M7jKzvwc/05VmdkiwzczsN2b2LzP7zMxeif+5iUjWmwz8E7gPmBK/wcwONLMHg36o3MzujNv2QzNbH/QJ68xseLDemdmhcfvdZ2a/DJ6HzWxL0D9+CNxrZvsEfflWM/skeN4/7vjeZnZv8BnwiZktCda/ambfjtuv0Mw+NrOhid5k0N6NwefFw2b21WD9PWb2qwb7/tXMfho8b1FfnOC695nZL81sD+Ax4KtBP/x5cO48M7vWzN4MfsYPmFnv4NiBwc/z+2b2DvBksP7PZvZh0OcuN7OjgvXJPk82mdmpwfOmPldjv5//E/TpH5jZJXHv5fTgd73D/GfszxL9rCUNnHNautACbAJOTbD+ZnwHvR/QF1gBzAy2zQLuAQqD5STAgCOAd4GvBvsNBA5Jct35wF+BnsF+rwPfD7b9Abglbt8fA48Hz4cD/wJGAfn4D49NQHHc+3kJOBDonuTaDjg0eH4f8Mu4bXnA88ANQBFwMPAWMD7YfhNQCZwd7NsdOBY4HigI3st6YGqi6wWvw/ivzwh+fhuB64LrfQPYARwR175twMjg/AuB+4Nt44O27h38/AcBB2T635QWLVpSW4L/+z8K+pBK4CvB+nzgZeA3wB5AN+DEYNu5wHvAccH/+0OBAcG2hn1Nbf8W9DtVwGygOOi7+gATgR5BX/xnYEnc8X8H/gfYJ+irxgTrpwH/E7ffWcCaJO/xG8DH+L67GPhPYHmw7WT8Z0YsLXMfYCfw1db0xQmu3fD9b2mwfSr+c65/0LZ5wKJg28Dg5zk/+B10D9ZfGvysioG5wEuJrhe3bhPBZyxNf67Gfj83Bz/r04EvgX2C7R8AJ8X9nIZn+t9vZ10y3gAtHfwLTx4IvwmcHvd6PLApeH4zPog9tMExh+KD1FOBwiaumQ/sBo6MW3cZEAmenwq8FbftWWBy8PzuWMcRt30DdR30JuDSZt5zU4HwKOCdBvvPAO4Nnt9E0Ik3cf6pwEOJrhe8ru2Q8X9EfAjkxW1fBNwU177fxW07HXgteP4N/B8Qx8cfr0WLluxfgBPxgdy+wevXgGuC5yFgK1CQ4LilwNVJztlcIFwBdGuiTUOBT4LnBwA1BIFYg/2+iv+DvVfw+i/AtCTn/D0wJ+71nsH7HogP5N8BTg62/RB4Mniejr644ftvGAivB8bGvT4gaFtsUMMBBzdx/r2DffZqeL24fTZRFwg39bkaxv8RUBC3/V/A8cHzd/Cfk70y/W+3sy9KjZCYrwKb415vDtYB3I4fyVhmZm+Z2bUAzt8MNhXfQf3LzO6PfQXWwL74v/Abnr9f8PxJoLuZjTKzAfjO+aFg2wDg/wRpBJ+a2af40d/467zb4ndbZwD+67P4818HfCXZ+c3s8OArxQ+Dr+huDd5jKr4KvOucq4lbF/+zAB8ox3yJ/yDBOfckcCdwF/CRmZWaWa8UrysimTUFWOac+zh4/Sfq0iMOBDY756oSHHcgPqBqja3OuV2xF2bWw8zmmU9P2w4sB/Y2s/zgOtucc580PIlz7n38AMVEM9sbOA3/bVUi9T5LnHOfA+VAP+cjvPuBC4LN34s7T4v74lYYADwUd/71QHWya5hZvpndFqRSbMcHudCy/j7Z5ypAeYPfeW1/jx+5Px3YbGZPm1koxWtKCykQlpj38Z1EzNeCdTjndjjn/o9z7mDg28BPLcgFds79yTl3YnCsw38N19DH+L+6G57/veAcNcAD+M7xe8DfnHM7gv3exadN7B239HDOLYo7V0tKnzTc913g7Qbn7+mcO72JY+7Gj+Yc5pzrhe+sLcXrvw8caEGOdaD2Z9Fs4527wzl3LHAUcDjw8xSvKyIZYmbdge8CY4I/oD8ErgGGmNkQfD/0NUt8g9a7wCFJTv0lPs0hZv8G2xv2Xf8Hn9I2Kui7To41MbhO7yDQTeS/gQvxqRpR51yyPqveZ0mQr9uHuj5uEfCdYNBjFLA4WN+avrgpifZ9FzitwTW6NXgv8cd9D58GciqwF37UGOr6++bak/RztdnGO/ecc+4sfFrFEvxnpLQDBcJdU6GZdYtbCvCd07+bv1FtX3ye1gKovVntUDMzYDv+L+hqMzvCzL4RJP/vwn/NU93wYs65avx/4lvMrGfQAf40dv7An4Dz8Dcf/Clu/f8DLg9Gi83M9jCzM8ysZyvf+0f43LOYVcB28zeUdA9GAI42s+OaOEdP/M/hczP7OnBFM9eItxL4An+DRaH5Ej/fxo+SNMnMjgt+DoXBOXaR4OctIlnnbPz/1SPx33gNxef4P4O/gW4VPif0tqCP62ZmJwTH/g74mZkdG/SBhwZ9KPj7I74X9FvfBMY0046e+H760+AmsRtjG5xzH+BvMPsv8zfVFZrZyXHHLsHn/V6Nz6NN5k/AJWY2NPhsuBVY6ZzbFFznRXwayO+Apc65T4PjWtMXN+UjoI+Z7RW37h7859AAqL0x+6wmztETn9ZXjv+D49YE12iqRn3Sz9WmmFmRmU0ys72cc5XUfe5KO1Ag3DU9iu8MY8tNwC+B1cArwBrghWAdwGHAE8DnQBT4L+dcBH/zwG34Ed8P8X+5Xpfkmlfig7e3gH/gO8s/xDY652IB4lfxnXFs/Wp8HtmdwCf4FI2LW/vG8flrRwZfjS0JgvRv4z+Y3g7ey+/wf/0n8zP8SMEOfKD+Pw223wT8d3CN78ZvcM5V4MsmnRZc67/w+dCvpdD2XsH1PsF/xVYO/KrJI0QkG0zB57q+45z7MLbg+7VJ+BHGb+Pvu3gH2IIfGMA592fgFnyfuQMfkPYOznt1cNynwXmWNNOOufib5j7G38T1eIPtF+G/vXsNn686NbbBObcTP3p7EPBgsgs458qA64N9P8CPZp/fYLdF+FHWP8Ud15q+OKmgT10EvBX0xV8Ffgs8jE/z24H/GYxq4jTz8X3te8C6YP949T5PEhzf1Odqcy4CNgUpGZfjR+OlHWhCDREREWmWmd0AHO6cU1AmnYYKRouIiEiTglSK7+NHKkU6DaVGiIiISFJm9kP8jWaPOeeWN7e/SC5RaoSIiIiIdEkaERYRERGRLkmBsIiIiIh0SRm7WW7fffd1AwcOzNTlRUTa5Pnnn//YOdc30+3oKOqzRSSXJeuzMxYIDxw4kNWrV2fq8iIibWJmm5vfq/NQny0iuSxZn51SaoSZfdPMNpjZRjO7NsH2fczsITN7xcxWmdnRbW2wiIiIiEh7ajYQNrN84C78TFhHAheY2ZENdrsOeMk5dwx+usjfpruhIiIiIiLplMqI8Ehgo3PurWB62PuBhnNzHwmUQe20hgPN7CtpbamIiIiISBqlkiPcD19IO2YLjefmfhmYAPzDzEYCA4D+wEfxO5lZCVAC8LWvfa2VTRbJTZWVlWzZsoVdu3ZluinSAt26daN///4UFhZmuikiIpJmqQTClmBdw1k4bgN+a2YvAWuAF4GqRgc5VwqUAowYMUIzeUiXsmXLFnr27MnAgQMxS/TfSrKNc47y8nK2bNnCQQcdlOnmiIhImqUSCG8BDox73R94P34H59x24BIA85/wbweLiAR27dqlIDjHmBl9+vRh69atmW6KiIi0g1RyhJ8DDjOzg8ysCDgfeDh+BzPbO9gG8ANgeRAci0gcBcG5R78zEZHOq9lA2DlXBfwEWAqsBx5wzq01s8vN7PJgt0HAWjN7DV9d4ur2arCItE55eTlDhw5l6NCh7L///vTr16/2dUVFRZPHrl69mquuuqpF1xs4cCAff/xxW5osrZRCycu9zOwRM3vZzNaa2SWZaKeISKalNKGGc+5R4NEG6+6Jex4FDktv00Qknfr06cNLL70EwE033cSee+7Jz372s9rtVVVVFBQk7hJGjBjBiBEjOqKZ0kZxJS//DZ/a9pyZPeycWxe324+Bdc65b5tZX2CDmS0MKgOJiHQZKU2oISIZEo3CrFn+sR1cfPHF/PSnP+WUU05h+vTprFq1itGjRzNs2DBGjx7Nhg0bAIhEInzrW98CfBB96aWXEg6HOfjgg7njjjtSvt7mzZsZO3YsxxxzDGPHjuWdd94B4M9//jNHH300Q4YM4eSTTwZg7dq1jBw5kqFDh3LMMcfwxhtvpPndd1qplLx0QM/gno49gW0kuMFZRKSzy9gUy60SjUIkAuEwhEKZbo1I+4pGYexYqKiAoiIoK2uXf/evv/46TzzxBPn5+Wzfvp3ly5dTUFDAE088wXXXXcfixYsbHfPaa6/x1FNPsWPHDo444giuuOKKlMqL/eQnP2Hy5MlMmTKFP/zhD1x11VUsWbKEm2++maVLl9KvXz8+/fRTAO655x6uvvpqJk2aREVFBdXV1el+651VKiUv78Tf6/E+0BM4zzlX0/BEKnmZW0pLYcYM2LEDTjkFli7NdItEmpEoruvgWC93AuEOCgpEskYk4v+9V1f7x0ikXf7Nn3vuueTn5wPw2WefMWXKFN544w3MjMrKyoTHnHHGGRQXF1NcXMx+++3HRx99RP/+/Zu9VjQa5cEHHwTgoosuYtq0aQCccMIJXHzxxXz3u99lwoQJAIRCIW655Ra2bNnChAkTOOwwZV+lKJWSl+OBl4BvAIcA/2tmzzS8yVklL3NHaSlcdlnd62XLYPx4BcOSxRLFddDhsV7upEYkCgpEOrNw2HcE+fn+MRxul8vssccetc+vv/56TjnlFF599VUeeeSRpJN/FBcX1z7Pz8+nqqp136rHKjLcc889/PKXv+Tdd99l6NChlJeX873vfY+HH36Y7t27M378eJ588slWXaMLarbkJb7c5YPO24gvd/n1DmqftIMEX9zwzDMd3w7pwqJROOccOPJIGDMGhg2DHj38Z5hZ3ZKX5x9Hj4adO31ct3MnzJ/vl1276tZNnerPG0sTLC1Ne7pg7owIx4KC2F8J7RQUiGSNUMj/NdyBXxF99tln9OvXD4D77rsv7ecfPXo0999/PxdddBELFy7kxBNPBODNN99k1KhRjBo1ikceeYR3332Xzz77jIMPPpirrrqKt956i1deeYVvfOMbaW9TJ1Rb8hJ4D1/y8nsN9nkHGAs8Y2ZfAY4A3urQVkpaTZzoR4HjnXRSZtoiXUw0Cj/6EQQ3YwOwfn3y/V2SL5fuuafxulWrfMDcUPfuaRstzp1AOANBgUjGhUId+m992rRpTJkyhV//+tdpCTqPOeYY8vL8F0/f/e53ueOOO7j00ku5/fbb6du3L/feey8AP//5z3njjTdwzjF27FiGDBnCbbfdxoIFCygsLGT//ffnhhtuaHN7ugLnXJWZxUpe5gN/iJW8DLbfA8wE7jOzNfhUiunOOdW6y2HLl/uBt/hU+mXLoLAQzjsPFizIXNskx5SWwty5sGULfPEF1DS6fSDzdu5MW7qguWSReTsbMWKEW716dUauLZIJ69evZ9CgQZluhrRCot+dmT3vnOsyNeXUZ2evCy+EhQub3mfSJAXDkkQ0CtdeC2+9BVVV8OGHmW5RaqZNg9mzU949WZ+dOyPCIiIi0shjj6VnH0mztlQ/SFZNYf58/3zYMCgvb3zu0lKfMD5xIpSUNH/+tWub/ysqW8WnYrSBAmEREZEsNWqUT5MEKChInOZQVNT8eTQfTpxYQLluHbz6Knz6aeOv/4uL/Q+2Tx9fk66poDLZNcJhf19TPDOfw1Jc7G8KKy6GXr2gWzcYOhROO83/1fLXvybPpW0odkN1rKAA+LyYyy7zuTGFhX5bTU3t+4xyPHP4Of/kIj6hlN0UESs4048tfJtHmcx8QvyzZe+74Xvt1g2OOAKOP94H7489Bhs2+Pf9yittS7uYOLH1x8ZRICwiIpKF4oNg8N9axwbvYsHw+PGNv8nu1s3HWPGeesrHZl3+9ppkAWpDu3f7ZceOurp0LQmG589PfA3n/C8yVmnnyy/9ArBpEyxZkvo1YmIVFhKprPRLnCjHczIRqkj8F9R7fI17uJx7uYSnOCX1YLioCL761ab/cIhfHxuVXrIEnn/eB8VmPnCP/XXXvbv/AwHqAt9URrxbQIGwiIhIFnrhhcTr49McEpVICyZnrFdForKy3UqRt69oFObMgRdf9EFpLKj78sv6dwYWFPigqXt3uPhiOPvsutQCqEspWLeu+SA4kcsu80t+Puyzj/9LIxZ87r8/HHecf3zrLf9XR5Ia7NkgQpgqCklccrxOBYVECBMqfN6XPKuqSm9t39jN4DNmtOy4NAXAMQqERUREstDw4fVHhGNOO63u+UknNS6bFhs4i19fWJhjVUenT4c77mg8tJ1MVZUPlHfs8IHznDnt067qavi4QYGV997zS44IE6GAyqQjwjFFVkX4rH1g2tN+RSet2qVAWEREJEuMHw//+7/J00O7d4d+/RLHib17+7kG4gfMZsyAbdv8AGWicqzgB/tOPTXDs9DF8nY//NAHXMFU611BKT9gBrewjd4kH6V1TW7LA05lGUs5o9nrhfgnd/ETfsZsdtAr7ryxR1/ycrcrZvSSaXRfGqtJHWJiHxhMJ4uJnXMZWY499lgn0pWsW7cuo9cfM2aMe/zxx+ut+81vfuOuuOKKJo957rnnnHPOnXbaae6TTz5ptM+NN97obr/99iav/dBDD7m1a9fWvr7++uvd//7v/7ag9Yk99dRT7owzzmjzeZqT6HcHrHYZ6j8zsajPbn/jxjnnQ+DWLSNH1j/fpEktO37cuMy8b7dihXNFRW178zm6zOMHDmrStozj781ec0X+iS7Pqlrd7MJC5/Lzneve3f/qckWyPjt3plgWkTa54IILuP/+++utu//++7ngggtSOv7RRx9l7733btW1lyxZwrp162pf33zzzZx66qmtOpdIZ9XWKZEb5hS3tGRam65fWuqHs0tLW3bMkUemdvNaezv5ZJg3D2691Rdd3msvnw+cTkOHwqBB0L+/r5oALCZW+cDSsMAzFvb50ZdfXvc+unf3XxcMHAhnn03khwuoca1/b5WVPkOkosKPDOe8RNFxRywaXZCupjUjwitWOHfrren5q/vjjz92++67r9u1a5dzzrm3337bHXjgga6mpsZdfvnl7thjj3VHHnmku+GGG2qPiR8RHjBggNu6datzzrlf/vKX7vDDD3djx451559/fu2IcGlpqRsxYoQ75phj3IQJE9wXX3zhnn32WbfPPvu4gQMHuiFDhriNGze6KVOmuD//+c/OOeeeeOIJN3ToUHf00Ue7Sy65pLZ9AwYMcDfccIMbNmyYO/roo9369esbvadkI8J/+tOf3NFHH+2OOuooN23aNOecc1VVVW7KlCnuqKOOckcffbT79a9/7Zxz7re//a0bNGiQGzx4sDvvvPMS/uw0Iqw+uyMMGNC6Ebq2jQjXjSb2Lvik5Z3NvHluRXHYHcZrDiodVAVLpYNqB9XOqHYje65t25uLX4qKnBs40Ll583x7zz7buf33d65HDz9U2dzxeXl+3549687TxPtzgwb5/QoKGp+rb19/vuD1NG513fi83vv3P4/qBE2JbWtqlLdlv8MsGORu8seesW8dnHPJ+uxWd4ptXVrVqaYzKhDpYC0NhFes8F89pfMrqNNPP90tWbLEOefcrFmz3M9+9jPnnHPl5eXOOR8sjhkzxr388svOucSB8OrVq93RRx/tvvjiC/fZZ5+5Qw45pDYQ/vjjj2uv9Ytf/MLdcccdzjlXL/CNf71z507Xv39/t2HDBueccxdddJH7zW9+U3u92PF33XWX+/73v9/o/SQKhN977z134IEHun/961+usrLSnXLKKe6hhx5yq1evdqeeemrtfrE0jwMOOKA2+E6U+uGcAmHX2j5bUjZtWuLgwcwHD80FtQ2D4JhJk+rFaQkCsYZfrT+aemczb55bwfHOqGwmmPPLSJ5tefQUH/Bm+vM/1oZ58xq3ZcUKN+3kZ9sQjMZ+TokC5vZdunXzf0usWOH/rSX/95KeJVPBcLI+O3dSI6JRGDsWrr/eP0ajmW6RSLuKROrqo6frK6j49Ij4tIgHHniA4cOHM2zYMNauXVsvjaGhZ555hnPOOYcePXrQq1cvzjzzzNptr776KieddBKDBw9m4cKFrF27tsn2bNiwgYMOOojDDz8cgClTprB8+fLa7RMmTADg2GOPZdOmTSm9x+eee45wOEzfvn0pKChg0qRJLF++nIMPPpi33nqLK6+8kscff5xevXoBcMwxxzBp0iQWLFhAQYHuH5bMePDBxutuvdWXVl26FFauTH7suHHJty9Y4PuQeqHIiiju5DHcmnc91N6EFXy1zkn+rjqzuqVXLz8ZQp8+/s662PrLLiNCOLhVq/mv7V/g2Jb9UObNg7ff9nf/xcpsZfLurFgbSkoatyUU4sH3R9NcSbLk/M/p0EPzWhRW3npr299W//7w0EP+7SxdWvfvZdy4tp87kbamAKVb7gTC7REViGSxcNiXbIxNGpSO0kdnn302ZWVlvPDCC+zcuZPhw4fz9ttv86tf/YqysjJeeeUVzjjjDHY1U7LILHFnf/HFF3PnnXeyZs0abrzxxmbP4/9IT644yKPLz8+nKlaAvhnJzrnPPvvw8ssvEw6Hueuuu/jBD34AwN///nd+/OMf8/zzz3PsscemfB2RdAr+5qtVUFD//3zD7fFSmmArlsN74YU+0F2+nHDNkxg1+GDY/785ieWNj92xw09nu22bj5DihIk0OEeyBYbzfPPtLCz0+borVqS9Xmx7a+p31F7nCIf93yTtcc00TdzWiK9AkT1yJxBuj6hAJIuFQr5u+cyZ6atfvueeexIOh7n00ktrR4O3b9/OHnvswV577cVHH33EY83cYXPyySfz0EMPsXPnTnbs2MEjjzxSu23Hjh0ccMABVFZWsjBu/vqePXuyY8eORuf6+te/zqZNm9i4cSMAf/zjHxkzZkyb3uOoUaN4+umn+fjjj6murmbRokWMGTOGjz/+mJqaGiZOnMjMmTN54YUXqKmp4d133+WUU05hzpw5fPrpp3z++edtur5IS40aVVf21gwOPRSWL6//f372bJg2zc8aF9Orlx80bTJejEbhnHP8ZBDLltVNTYcvo/UsJ3EYrwPVQDXLGI9RFbdU1i55VNGHjyhgV+260fwDhwE1DZbqRutWMbLBuRsu1VhlBbb8aWx0qN6gdC4sbSldXFzsf7+zZ7fsuFAInn0WDjss/dcsKfH/vnr2bPm5m7J6dcvuqWxvufM9YCwq6FTF60SaFpt4J50uuOACJkyYUJsiMWTIEIYNG8ZRRx3FwQcfzAknnNDk8cOHD+e8885j6NChDBgwgJPi/ryfOXMmo0aNYsCAAQwePLg2+D3//PP54Q9/yB133MFf/vKX2v27devGvffey7nnnktVVRXHHXccl19+eYveT1lZGf379699/ec//5lZs2Zxyimn4Jzj9NNP56yzzuLll1/mkksuoSaY237WrFlUV1dz4YUX8tlnn+Gc45prrml1ZQyR1mg4jbJzsHEjrFnT+P/+7NktDJSiUT+62sS3HCH+yUG8yRsc3uzpHLCNvk3uM47HWcrpta/H83eWcVqDvdo4hJkjWhPYtkYoBK+/3j7nLilp+8B8NAonnFD3ZcK2ba2btbq9WHNfTbaXESNGuNWrV2fk2iKZsH79egYNGpTpZkgrJPrdmdnzzrkRGWpSh1Of3T4KCxPHqeMGbmDpJ6N8OuABB/hpfQGef96vKyqC44/3M2o8/7x/feWVfp8//MHnVoCfoKIZPdjBTvYgtQA1llOceFv34hq+fGoVfPe7sGVLC8/duRx6KLzxRqZbkXmzZsF11zVeP25cx07ikqzPzp0RYRERkc4iGqV0zifUVI8DGtd0nbjpV8Bn/kWiaKqiwudPxOzc2brv5vfem5P2epdlm79OLJe3efHBcPwxxklj8v0Q5bvvAnDS+MZTQHcV6cgZ7gxiecwNx12XLWtdfnP37v5vvnSNtudOjrCIiEhnEI1SevIfuWzJaQ0mNnD05mPmUUIJv2v/dqxYAZ98wtJNgxg3ruWTN3j+dV6eJRzhW7rUj/y19YauXNK9e8elReSCWB7znnum53yxv/mmT0/P+TQiLCIi0lGCpODFxG5KrRtZ7c6XlLNf+107P9/fIXXYYXD33fWSkBsGsLNm+Wql1dX+MLPGKRypfrXdkV9/S3YKhXz2Tjo9+GB6/tjQiLBIB8pUTr60nn5nkhbRqA9CgzvjJrI42NBM6bJ0MfMFXL/4wpdCa+Yu3IaFmoYPb7xPe5XXks7ptIb3TLZRulJPFAiLdJBu3bpRXl6uwCqHOOcoLy+nW3zNKpGWikZ97d6KCv+S4/kVPyNWYsyoYRyPsZQzGh8bG44185NZ9O7t78JqTvzkMP37+++mW1CCpmH5xpUr/QhwQYFvQrNl20QaWLAAJk3y/6TbIt2pJ0qNEOkg/fv3Z8uWLWzdujXTTZEW6NatW73ybCItdsUVtU+jHM8JPIOLu0HOAX35uPFxeXl+FLdhANtcWbRJk3zU0UYNyzcqxUHaasGCtPzTTCsFwiIdpLCwkIMOOijTzRCRjjR9Orz8cu3L+lMSxzgea1Rrl0Z5vLVCIV8xYs4c2LAB+vaFDz6Ajz6Cb387+yINkSyWW4FwNKoJNUREJCOmT/cpAWY+LaC5r2anX7iFuQtvpIJbaFxpoX6K1GnEzeh48slw221Nf86FQvDQQy19CyLSQO4EwtEojB3rc6yKitI356yIiEgzpk+vX6Y39jxZMDx9OsxZ2K+JM/pg2Kjhe3s8zIJf74LyWzXQI9LBcicQjkR8EFxd7R8jEXUWIiLSIR58MPG6hIFwNMqD9xwM7EfTM6oZ+/TOZ0H5OelppIi0WO5UjWhYyyUcznSLRESki0hUqilh+abSUhg9mgnb/xCscAmWOukuKSUiLZM7gXDDWi4aDRYRkQ5y9tl+HgrwOcIjRzYYDS4thV694LLL/P48zGG8TqxEWt3iR4jz89NW3EFE2iB3UiOgcS0XERGRdtawWplzfl6M6dODYPjCC2Hhwrr9OZ6TiVBF3VRa8yihZNw7qkEmkmVyZ0RYREQkAyKRxCV7H3wQPxIcFwSDL5FWRSF+9NePAC/ufZmCYJEspEBYRES6tFhWgxnssQfst1/dZG5mcN11iY/buBHssu9jVGFUcRivEeV4wkQooJK6nGBj4qwRHfiORCRVCoRFRKTLKi31ab07dvjXX34JqU/+6PAfo37ZyOGcyD8AWE6Ys4duYuRI03TEIlkst3KERURE0mjx4rYc3bg0Wg15RPpfxIzrC3ioRDNJimQ7BcIiItJlTZwIy5a15kiXcG1enhF+4Eeg+7pFcoJSI0REpMsqKfFlzPJS+DSMlTwbN2gzjcui1QDV1NTA6NE+t7igwBeUEJHslXuBcDQKs2b5RxERkTaIFX2oqWm8bdw4XyptxQro3t2vu/9+WLb+a0A+kMc05jCJhfiP0/x6x1dX+3MrGBbJXrmVGhGNwtixforloiJNrCEiIm3SVI7wM8/4x0jEf+xUV8dvNcDxIBPZxj5x6xp77LG2t1NE2kdujQjH90YVFf61iIhIK4wf33R+8Ekn+cdw2I+95OdDfl4sGvY5whNYzGkDXiNZEAyaRlkkm+XUiHC0z7eI2E7CeU8SKnrB904iIiItlCwILiryaRLf+Ebd/BehkP8CMhKB8OO/YMnyvXiQiUxgMbO5Dr4yEk5cyaJF9VMs8vPh/PM1jbJINjPnEt/52t5GjBjhVq9enfL+tVkRux1F+VWU3fkaoZLB7dhCEZHkzOx551yXmSWhpX12tuvRA3bubLz+1lthxowmDhw1ys+vHO/ss+Ghh9LZPBFJs2R9ds6kRtRmRdQYFTWFRMoVBIuISOvE0h7i5eWl8EVjwx3y8mDatDS1SkQ6Ws4EwvE5WkVFyooQEZE6F17oy5XFT41s5uPU8eNh+nQoLq5b3zAton9/+Mc/mrn/urQU7r23/rqSEt20LZLDciZHuF6OVlj9joiIeBde6MuUJeKcD3qbuilu3Li6fOCkYnMxNzRsWMrtFJHskzOBMPjgVwGwiIjEa2t5sliZtCZdd13i9eXlbbu4iGRUzqRGiIhI1zF9up/EomGqg5lPkRs/3t+3ZgbbtrXtWonyhes1pLg4ecCrPD2RnJZTI8KALx+h/AgRkU5r+nSYMyf59pqaplMdUmUG//ZvTaRFNNeQceP0OSSS43JrRDhWQ+366/2jplkWEel0HnywbcffeqvPDS5IMtQTmzq5pqaZ3OD77ku8Pi8PJk1KIbFYRLJdbgXCmllORKTTmzCh9cfGl0AbPjzxPhMnNnOSaBQOPxz+9a/E23/2M82SIdJJ5FYgrBpqIiKdUnx5s6ayEZrSsATaypUwcmTd9t69Yd48X/GMaBTOOQcGDoQDDvDLUUf5hpxwArzxRvILvfRS6xooIlknp3KEo4SITFlPmKcJTT5MuVkiIp1Ac6m4seA1GvUxasMJUZsqf7ZyZYKViWaHA/jwQ1i3rvkGNzukLCK5ImcC4doplisGUFQ0mbLJoDBYRCT3NZcTvHixD4QjkcZBMKRY/izmgAN8wNtShYVw2GFw9dXBkLKIdAYppUaY2TfNbIOZbTSzaxNs38vMHjGzl81srZldku6GKj1YRKRzKS2FPn3gzTeb3i82ABsO+9SJhposfxYTjUKPHq0Lgs3g6adh7VoFwSKdTLOBsJnlA3cBpwFHAheY2ZENdvsxsM45NwQIA//XzIrS2VClB4uIdB6xidq2bUs8ygvQq1dcTi8+G+7ZZ/3ALPgb41KaFS4ahdGjYefOljd0yBB/UaXiiXRKqaRGjAQ2OufeAjCz+4GzgPhEKgf0NDMD9gS2AVXpbKimWBYR6TwWL068Pj8fZs6EGTMSbw+F4PXXW3ix+fNbeEBg0iRVhxDp5FIJhPsB78a93gKMarDPncDDwPtAT+A851xNWloYR1Msi4h0DhP7Ps0yTg5e1eU7pP0bvwsvhIULE2+bNg22b/fPJ0/2HzClpT5KnzhRaRAiXUAqgXCCjCwafpE1HngJ+AZwCPC/ZvaMc257vROZlQAlAF/72tda3FhAM8uJiOS60lLeXFhON45lF93wHzP59OoFt9/ehq59+nQf9B5yCNx2GyxZkjgINkue7lBSogBYpAtJJRDeAhwY97o/fuQ33iXAbc45B2w0s7eBrwP16tM450qBUoARI0YkyQprQl3pCD9sUFamYFhEJMdMv7GYOTS879qxfbtxxRUweHAruvbx4+vmXX7vPZ8TnJ+feN/vfU+fHSICpFY14jngMDM7KLgB7nx8GkS8d4CxAGb2FeAI4K10NhRQ6QgRkU7gwfL4lAiLe+6nPW5x115aWhcEx6uubryub1/l/YpIrWYDYedcFfATYCmwHnjAObfWzC43s8uD3WYCo81sDVAGTHfOfZz21qp0hIhIbotGmVD5P8ELR12mnX+MnyI5ZbNmpb7vX//awpOLSGeW0oQazrlHgUcbrLsn7vn7wLj0Ni0BlY4QEWmWmX0T+C2QD/zOOXdbg+0/ByYFLwuAQUBf59y2dm9cJMJsrgMc8yjBMLrxJVttfw7oV8ADD7Siay8vT22/efP0uSEi9aQ0oUa2iEZhViRENDxDnZmISAKp1H53zt3unBvqnBsKzACe7pAgGGq/2ZvNdXzKvnxCHz7gQKr22Id3vze9ZV17NAr77Qc7djS/77hxuglORBrJmUA4dp/c9df7x2g00y0SEclKtbXfnXMVQKz2ezIXAIs6pGXgBzEiEejfv/76zz+HOXN85YdUxCbJ2Lq1/vriYh/0xhs6NIVZN0SkK8qZQFj3yYmIpCRR7fd+iXY0sx7AN4Ek01u0jyghxhDhQDYznVvrb7z33tROcm3DqhOB/Hy46Sbo3t0/794d/uu/2tReEem8UsoRzgax++QqdjuK8qoI93kNGJzpZomIZJtUar/HfBt4NllaRFpqvzcQjcJJJ1ZTXXMwQG0ZNZ83DOyxR/MnKS2F5csTbzvnHN1PIiIpy5kR4VAIyuauYWbejZRVn0Jo6ijlR4iINJZK7feY82kiLcI5V+qcG+GcG9G3b9+0NC4yfzPVNbGyaT5mf5CJdTscfnjzJ/n97xOvj58SORTy8zQrCBaRJuRMIAwQKv8bM9ythGqeVX6EiEhiqdR+x8z2AsYAHVpPLMzT5FNFfOm0CfGZGcuW+RHfZKJReO65xutPPln1gUWkxXIqEFYdYRGRpqVY+x3gHGCZc+6LjmxfaPJhnJ/3Z4r5kj3ZwbRxLzE779/r77S4iZTlOXPAJcj0uO22xutERJqRMznCgPK+RERS0Fzt9+D1fcB9Hdcqb/qSEAtrjgdgN8DQYdD3Ali4sG6noUPrHxSN+n7/009hyZLGJ500SZ8HItIquRUIg+/s1OGJiOSkB/+0E+iGzw92PPinncz+Vs/6O/3zn3XPS0vh8ssTjwKDL5emlAgRaaXcSo0gmFRjlu6TExHJRRMOfjF45upef/hh/Z2WL4cLL4SBA+Gyy5IHwQDf+U67tFNEuoacGhGORmHsKdVUVBhFRY6yp/I1OCwikkPOntST/7u8kmoKyKeKsyf1hBf3b7xjfKpEMgMGaDRYRNokp0aEI/M3U7HbUe3yqNhdQ2T+5kw3SUREWiBSPhjyCoE8yCv0rydPbvmJ9t8fNm1Kd/NEpIvJqUA4zNMUUUE+lRRRSZinM90kERFpgXAYiorNF/8pNl/8JxSCIUNSO4GZn0L5gw/asZUi0lXkVGpEaPJhlP3hdCKVJxAufJbQ5FmZbpKIiLTQlPEfwPsfMPn7hYRCwQyhd98No0c3feCKFbpZWkTSKqcCYUIhQpFZhCIRCM9ShygikkNq7/PY3Zci9mLyS6fD4Fl11YBWrIApU+CNN/wBeXnQowcMH+7rBKvPF5E0y61AGFQ+TUQkR0UiUFFhVJNPBY5I5Ql+YCPWp4dC8PrrmWyiiHQxOZUjLCIiuSschoICMKopoJpw4bOaIVREMirnRoSjUV89IszThCYfptFhEZEc4iwPzOHyCuA//xNiOcIiIhmQU4FwXX5ZP4r4DmV/OJ1QRLnCIiK5IBKB6mpwzo8JR8oHo95bRDIpp1Ij6vLLCqigkEjlCX6liIhkvXAYiorwpdOKlBUhIpmXUyPCvhN1VOwO6ggXPuurR4iISNYLhaCsLC69jcNAY8IikkE5FQiHQlD2VD6R+VuCHGGlRYiI5JIQUUL/PRYqKuC/i3xkrH5cRDIkpwJhiFVPGwC0YkpOERHJLJ/j5pOFKyr8awXCIpIhOZUjXCsahVmz/KOIiOQOJQqLSBbJuRHhaOkaIj9+jHDNk4SKZ+prNRGRXFKbKBzxQbD6bxHJoJwKhKNRGPuTr1NRdQNFXEvZ7nH1ZyUSEZHspxlCRSRL5FRqRCQCFdUFdeXT8r6hr9VEREREpFVyakQ4HIaiYqNit6MoH8J3nqtZiURERESkVXIqEK5LLTPC4UJCCoJFREREpJVyKhCGILWMaDCjXFh5ZiIiuSQa1Y1yIpI1ci4Q9nfMBcXYi1SMXUQkZ0SjRMMziFSeQLhwBqGIJkUSkczKqZvlAKLz32DWrmuIVh9XV4xdRESyXnT+G4yteJTr3X8wtuJRovPfyHSTRKSLy6kR4WgUxt47iQrnKOIXlOWfTkhVI0REckKEMVRQFFT+cUQYg8aDRSSTcmpEOBKBiqp834laMZFL/1tfq4mI5Ijw5AEUFRv5Vk1RcR7hyQMy3SQR6eJyakQ4NjOnL59WQ3jY9kw3SUREUhQKQdlT+bpXTkSyRk4FwqEQlM1dQ+THfyZc/SShqS/AYN0sJyKSKzSpnIhkk5wKhAFC5X8j5G6FmmqoyPf5EupVRURERKSFci4Qjvb5FhHbSTjvSUJFL2iKZRGRHKIywiKSTXIqEI5GYezUwVRUH0WRXUfZlY8TUk8qIpITVAZeRLJN7lWN2O2odnlU1OQT+fULvmcVEZGsF4lAxa5qqqv9o8rAi0im5VQgHA5DUX4V+VRSRCXhmic1oYaISI4Ir72LIrfb9+FuN+G1d2W6SSLSxeVUIBwKQdmdrzGzYCZleeMIFStHWEQkV4RWzmUuVzOWMuZyNaGVczPdJBHp4nIqRxggVDIYgMjib8DEPoRCgzPcIhERSUV01FSmbryECop4hpMZPOpezSwnIhmVc4FwNApjrzqSigqj6GlH2WDdbCEikgsiR/2YCqum2uVTYUbkqB8rEBaRjMqp1AiAyPzNdTfM7a4hMn9zppskIiIpCIehoCgfM/+ozDYRybScC4TDPE0RFXU3zPF0ppskIiIpcq7+o4hIJuVcIByafBhlRacz026kLH88oWG7Mt0kERFJQSQC1dU+CK6uVtEfEcm8nAuECYVg6lSwPKip8c9VS1hEJOuFw34ijfx8/6jUCBHJtNy8We43Z1BR8y2KuI6y3eMIRSK6Y05EJMuFQlA2dw2RxeWEVfVHRLJAzgXCkQhUVBdQjVGBI5L3DUIaVhARyX7RKKGpYwlVVMAzRTBYcyyLSGblXGpEOAxFxUZ+Xg1FedWEfzpcHamISC6IRKCiwicIV1QoSVhEMi7nAuFQCOZe+aafmchdTeg/v6ccYRGRXKAkYRHJMjmXGhGNwtTffI2KmgE8wwkM3r1WOcIiIrkgFIKyMj8SHA6r3xaRjMu5QLhRjrCFlSMsIpIrQiEFwCKSNXIuNSIchqLCmroJNfKeyXSTRERERCQH5VwgHArB3NOWMpYnmcvVhGqe1Q0XIiI5oLQUxo/6hNJzHtW9HSKSFXIuNSIahamPjacCxzOcxGDboNQIEZEsV1oKl13mgL1Zxmnwtx9TshylSYhIRuXciHAkAhWVeVRTQAWFRNyYTDdJRESasXhx7Jn511Vn6ds8Ecm4lAJhM/ummW0ws41mdm2C7T83s5eC5VUzqzaz3ulvbpAjnF9VlyPsnlJnKiKS5SZOjD1z/nXBX1U+TUQyrtnUCDPLB+4C/g3YAjxnZg8759bF9nHO3Q7cHuz/beAa59y29mhwKARzr3mHxbe/yUT3F0IFz0H49va4lIiIpElJCYCx+PefMPGrUUqmXaS0CBHJuFRyhEcCG51zbwGY2f3AWcC6JPtfACxKT/Mai0Zh6m8HUuEG8AwnMthtQF2piEj2KymBkpJ9gNMz3RQRESC11Ih+wLtxr7cE6xoxsx7AN4HFSbaXmNlqM1u9devWlrYViM3QaXU5wlUnKjVCRERERFoslUDYEqxzSfb9NvBssrQI51ypc26Ec25E3759U21jPeEw5Bc4jGryqSactxz69GnVuURERESk60olEN4CHBj3uj/wfpJ9z6cd0yJiLC8fyPMRek0NTJ2qmpQiIiIi0iKpBMLPAYeZ2UFmVoQPdh9uuJOZ7QWMAf6a3ibWF4lAVRU4jCryibiTYfdupUeIiIiISIs0Gwg756qAnwBLgfXAA865tWZ2uZldHrfrOcAy59wX7dNULxyGoiLIsxoMRx8+9qPCSo8QEclq0dI1zBofIVq6JtNNEREBUpxZzjn3KPBog3X3NHh9H3BfuhqWTCgEc+fCT65wVLs8pvJbBts6QuXl7X1pEZGcYGbfBH4L5AO/c87dlmCfMDAXKAQ+dq59ZyeKlq5h7GWHUMEgipZVUMYaQiWD2/OSIiLNyrmZ5QDKy6GGPGpilSPyTlFhdhER6tV+Pw04ErjAzI5ssM/ewH8BZzrnjgLObe92RRaXU0FRXcWfxRq8EJHMy8lAOByG/PyauMoRz2S6SSIi2aK29rtzrgKI1X6P9z3gQefcOwDOuX+1d6PCE/tQREXdrKATlc4mIpmXUmpENrIaB5ivHFFV5W+W0yxFIiKJar+ParDP4UChmUWAnsBvnXPz27NRoZLBlLGGyOJywhP7KC1CRLJCTgbCkQhUVufhyKMSR8SdTEg3y4mIQGq13wuAY4GxQHcgamb/dM69Xu9EZiVACcDXvva1NjcsVDKYUEmbTyMikjY5mRrRpw/UYICjhnz6UO4Th0VEJJXa71uAx51zXzjnPgaWA0ManigdkyCJiGSznAyEy8shz3xqRB7VlNNH5dNERLxUar//FTjJzArMrAc+dWJ9B7dTRCTjcjI1IhyGgrwaKqsdBVQR5mko75XpZomIZJxzrsrMYrXf84E/xGq/B9vvcc6tN7PHgVeAGnyJtVcz12oRkczIyUAYwIIsOP/g4NNPM9cYEZEskmLt99uB2zuyXSIi2SYnUyMiEaisysORTyUFRAjDb34D0WimmyYiIiIiOSInA+HGN8t9XFdCTUREREQkBTkZCJeXQ16e4esI1/Aiw8E53TAnIiIiIinLyUA4HIaCAgCHI497uYQoIZVQExEREZGU5WQgHArBpZfGXlmQJzxGI8IiItksGoVZs3Q/h4hkjZytGjFsWOxZXJ7wi59msEUiIpJUNApjx0JFBRQVQVmZH9UQEcmgnBwRBp8FYfhJNYxqytk3000SEZFkIhEfBFdX+0fd3CwiWSBnA+E+fcAFlSNcbES4lybVEBHJSuGwHwnOz/eP4XCmWyQikruB8Isvxp75KTVeZDj83/+r3DMRkWwUChGdu5JZY58gOnel0iJEJCvkbI5wQtXVMH++OlgRkSwTjcLYqYN9ivAzUDZYXbWIZF7Ojgj7m+V8agTAMF7wGz78MFNNEhGRJJQiLCLZKGcD4YSpESIikpWUIiwi2ajTpEZ8yFf8k/33z2xDRESkkVAIyuauIbK4nPDEPoRCgzPdJBGR3B0RnjwZCgshlhrxd84gyvHxBYZFRCRbRKOEpo5iRtmphKaO0o3NIpIVcjYQDoXgjDNir4xKipjPZHjssUw2S0REElGSsIhkoZwNhBP5kK/AX/+qkQYRkWyjJGERyUKdKhAGwDmYMyfTrRARkXihkJ9WeeZMTa8sIlmjE9wsZ41XbdjQ8c0QEZGmhUIKgEUkq+T0iHDDAhHb6O2fFBd3fGNEREREJKfkdCA8ebJPN4tVjljOGEr5Abz8svKERURERKRJOR0Ih0Jw+OGxVz5F4vd8X3nCIiIiItKsnA6EAfr2hfg84W7s8k/qpp4TEREREWkk5wPh3r0bvGabf/LOO0qPEBEREZGkcj4QbmgTA/0T52D+/Iy2RURERESyV84Hwg0rR7zEMH/DHMC6dR3fIBERSSwahVmz9G2diGSNnA+EJ0+OfxV3wxzAq692eHtERCSBaBTGjoXrr/ePCoZFJAvkfCAcCsFhh9Vf9wn7+CfbtkFpacc3SkRE6otEoKICqqv9YySS6RaJiOR+IAywzz71X7/BoUQ53r+49daOb5CIiNQXDkNRkS/+XlTkX4uIZFinCIS///34VwbkMYef+5ebN+srOBGRTAuFoKwMZs70j5pqWUSyQKcIhEtKGpdRW86JdS80uYaISEZFozArEiIanqEgWESyRqcIhKFx9Yht9K2rHlFW1vENEhERQPfJiUj26jSB8NVXx7/y1SPmEqzcsUM3zYmIZIjukxORbNVpAuGSEujZs/66zXyt7sXPftaxDRIREUD3yYlI9uo0gTDAgQfWf/0lPZlOUDVixw648MKOb5SISBen++REJFt1qkA4UXrEXfyobtXChUpOExHJgFAIZug+ORHJMp0qEE5UPeILetXdNAfwox8hIiIiItKpAmHw09jX8aPCM7ilbtVLL2lUWEQkA6JR30erCxaRbNHpAuGSEujevf66eqXUAM46q2MbJSLSxamEmohko04XCAMcd1z8qwSjwlu36sY5EZEOpBJqIpKNOmUgfNttjdc1GhXWjXMiIh1GJdREJBt1ykA4FIJJk+LX+FHhnzG7/o5KkRAR6RChEJTNXcPMsRHK5q5R9QgRyQqdMhAGWLCgca7wDvbhQv67boVSJEREOkY0SmjqKGaUnUpo6ih9IyciWaHTBsIAV14Z/8qPCi/kIqIcX7daKRIiIu1PScIikoU6dSA8ezYUF8ev8cHwFO6rv+Ppp3dUk0REuiYlCYtIFurUgTA0nG3Oe4PD69849+mnMHBgRzVJRKTr0TzLIpKFOn0gPHs29O8fvyZBOTWAzZth1KgOa5eISJejeZZFJMt0+kAY4IEHGq4xttGX6dxaf/WqVTB9ekc1S0REREQyqEsEwqEQDBnSeP0cpte/cQ5gzhzdPCciIiLSBXSJQBjg7rsbrjHA+BF3Nd5Z9YVFREREOr0uEwg3nmQDwHiJYY1HhbduVb6wiIiISCeXUiBsZt80sw1mttHMrk2yT9jMXjKztWb2dHqbmR4LFkCvXg3XGmexpPHOq1bB+PEd0CoRERERyYRmA2EzywfuAk4DjgQuMLMjG+yzN/BfwJnOuaOAc9Pf1PS4/fbG67ayX/0Z52KWLYPS0vZvlIiIiIh0uFRGhEcCG51zbznnKoD7gYZJtN8DHnTOvQPgnPtXepuZPiUlMHJkw7XWeMa5mKuu6ohmiYiIiEgHSyUQ7ge8G/d6S7Au3uHAPmYWMbPnzWxyohOZWYmZrTaz1Vu3bm1di9Ng5UrYY4+Ga43vdnu48c67d2uyDREREZFOKJVA2BKscw1eFwDHAmcA44HrzezwRgc5V+qcG+GcG9G3b98WNzadfv3rxuu27OpL6YBbGm/QZBsiIiIinU4qgfAW4MC41/2B9xPs87hz7gvn3MfAciBB5d7sUVLScMY575qt18HeezfeoMk2RERERDqVVALh54DDzOwgMysCzgca5hD8FTjJzArMrAcwClif3qamX+MZ5+DLL2H84W8mPkCTbYiIiIh0Gs0Gws65KuAnwFJ8cPuAc26tmV1uZpcH+6wHHgdeAVYBv3POvdp+zU6PxLWFYdmq3kQn3Zn4oHHj2rdRIiKdUDQKs2ZpLEFEsos51zDdt2OMGDHCrV69OiPXbmjPPeGLL+qv698f3j1yvC+h1tCgQbBuXcc0TkSykpk975wbkel2dJS29NnRKIwdCxUVUFQEZWV+IEJEpKMk67O7zMxyTUl449wWuLDvUhgwoPHG9es12YaIZK3mJkEKJkD6LJgE6SUzu6E92xOJ+CC4uto/RiLteTURkdQpEMbfOHfooY3XL1wI0UWb/JBxQ8uW6eY5Eck6qUyCFHjGOTc0WG5uzzaFw5AXfNrk5fnXIiLZQIFwYP78xOu/+10Sp0eAbp4TkWyUyiRIHWrNGqis9M8rK/1rEZFsoEA4EArBtGmN12/ZAtOXJNkIunlORLJNKpMgAYTM7GUze8zMjkp0onRNgrR4cdOvRUQyRYFwnNmzE9cWnjMHomfPTjQ3M3z+ORxwQPs3TkQkNalMgvQCMMA5NwT4T2BJohOlaxKkiRObfi0ikikKhBtIVFsYYMoU/NzMiW6e+/BDTcMsItmi2UmQnHPbnXOfB88fBQrNbN/2alBJCcyb9ibjDn2LedPepKSkva4kItIyCoQbSFZb+I03oLQU2LQp8c1zmzcrGBaRbNDsJEhmtr+ZWfB8JP6zoLzdWhSNUvKfg1n69uGU/Odg3VshIllDgXACCxZAr16N119zTfAk2c1zmzfDkYluzhYR6RipTIIEfAd41cxeBu4AznftWVRe9dNEJEspEE7i9tsbr/vyy6B8cCgE8+YlPnD9ehg1ql3bJiLSFOfco865w51zhzjnbgnW3eOcuyd4fqdz7ijn3BDn3PHOuRXt2qBw2M+kkZ/vH1U/TUSyhALhJEpKEheEWLYs+FavpCR5MLxqlSbcEBGJCYX8dHIzZ2paORHJKgqEm7B0KeyxR+P1Z8UqcpaUJC+rtmwZXHhhu7VNRCSnhEIwY4aCYBHJKgqEm5Fo+uWtW+MGfGfPTnx3Hfip6TT7nIiIiEhWUiDcjJKSxOWDly0LqkiAv7su2cQac+YoGBaRLi8ahVmzVDBCRLKLAuEUrFyZOEWitooE+DyKRBEz+GBYOcMi0kVFozB2LFx/vX9UMCwi2UKBcIoSpUjUVpGIWbkSBg1KfIJlyxQMi0iXpOppIpKtFAinKKUUCYB16xLPPhfbWcGwiHQxffpAXp5fVD1NRLKJAuEWSJYicdVVDVZs2tT0yLDqDItIFxGNwtSpfjQ4Lw/mzlXhCBHJHgqEWyhRisTu3QkmlFu3LnnO8KpVCoZFpEuIpUXU1ICrrqb8xc2ZbpKISC0Fwi2ULEVi/foEWQ8rVyoYFpEuLRyGooJq8qmkyO0m/IcpultORLKGAuFWWLkS9t678fpG+cKxnRUMi0gXFQpB2SULmWk3UcZYQtX/0N1yIpI1FAi30qOPJl7fKF8YfDCcrM6wgmER6eRCkw9jRrffEMp/TnfLiUhWUSDcSqFQ4tmVE+YLg68znGwGulWrVE1CRDqvUAjKymDmTP+ou+VEJEsoEG6D2bNbkC8MTc9Ap9JqItKZhUIwY4aCYBHJKgqE26ipfOGEMysvXapgWERERCQLKBBOg2T5wnPmJLk5urlg+MIL09Y2EREREUlMgXAahELJ03+TxbssXZq8msTChRoZFhEREWlnCoTTZMGCxHHt55/DwIFJDmqqtJpmoBMRERFpVwqE02jlShgwoPH6zZtbGQyvWpWkBIWIiIiItJUC4TTbtAn23LPx+lYHw+vXN3GgiIiIiLSWAuF2sGxZ4vWtDoY3b4YDDkhH00REREQkoEC4HYRCMG9e4m2bNzeR+tvUDHQffgi9eqWlfSIiIiKiQLjdlJQknnkOfOpv0gppTc1At2MHFBcnqckmIiIiIi2hQLgdzZ6dPBheuLCJYHjBguQHVlTA6NFQWpqWNoqIiIh0VQqE21lzwXDC2ediB65YAUVFibdfdlkTB4uIZJloFGbN0jdaIpJVFAh3gNmzk6f+zpnTxOBuKAS7d0PPnskP1ix0IpLtolEYOxauv94/KhgWkSyhQLiDNDWR3GWXNfO5sH079O6deJtmoRORbBeJ+LSu6mr/GIlkukUiIoAC4Q61ciUMGpR42+mnN3NweTnsv3/ibcuWaeINEcla0T7fYpZdRzTvBJ/uFQ5nukkiIoAC4Q63bl3i2ec+/TSFeTM++CDxwaCJN0QkK0WjMHbqYK6v+Q/G5j9FdO5Kn/YlIpIFFAhnwKZNsPfejddv3pzCwO6mTcmHlTXxhohkmdqsiBqjoqaQSPngTDdJRKSWAuEMefTRxOvXr29iwo2YdeuannijT582tU1EJF3CYZ8NkZ+vrAgRyT4KhDOkqdnnVq1KYWS4qYk3tm3TxBsikhVCISgrg5kz/aOyIkQkmygQzqCmZp9bvz6FYDiViTdUa1hEMiwUghkzFASLSPZRIJxhs2cnH9hNKRiePTv50DL4WsMqryYimaYJNUQkCykQzgILFjQdDDdbDKKkpOlZ6FReTUQyKFq6hlknP0b03/+uCTVEJKsoEM4STQXDKRWDiM1Cl2zijfXrVVFCRDpcNApjf/J1rq+6gbE1y4juHq4JNUQkaygQziJNBcMpF4MoL09eXu3DD6FHD43GiEiHiUSgorqAagqooJBI3jdUOkJEsoYC4SzTVDC8bVuKwfC6dcnnc965UzfRiUiHCYehqNjIz3MUFUL4rnN115yIZA0FwlmoqWIQ27ZBr14pnGTlyuQRNfib6C68sFXtExFJVSgEc+fC2FONuXcWEirRhBoikj0UCGep2bP9/W8FBY237djh15eWNnOSBQuariixcKEqSohIu4pGYepUX0N46lRlZolIdlEgnMVCIVi+PPG26mq47LIUBnVjFSX23DPx9mXLUpjKTkSkdWqnWK72j7pPTkSyiQLhLBcKNV0ZLaVB3VDIDyMPGJB4+6pVKdRoExFpudoplvMcRXmVhPusyXSTRERqKRDOAbHKaD17Jt6ecpngTZuSV5TYvDnFO/FERFIXCkHZ3DXMzLuRsupTCE0dpfwIEckaCoRzyPbtsP/+ibelXCa4qYoS27ZBYWEKycciIqkLlf+NGe5WQjXPKj9CRLKKAuEc88EHTZcJLi5OYbBl5UoYNy7xtqoqn3ysm+hEJF1q8yPy/aPqCItIllAgnIPWrUsex1ZU+DLBzd5Et3Rp8hpt4PMtlDcsIukQCvmyETNn+kfVERaRLKFAOEctXdp0meCFC1PIG47VaOvePfH2zZs1E52IpEcoBDNmKAgWkayiQDiHxcoE5yX5La5f7+sNNzmJXCgEX36ZPPk4NhOdUiVERESkk0kpEDazb5rZBjPbaGbXJtgeNrPPzOylYLkh/U2VREpKfH3O3r0Tb6+u9pPINZvl8MEHyW+iA58q0bOnRodFpOWiUZg1S/2HiGSdZgNhM8sH7gJOA44ELjCzRF+6P+OcGxosN6e5ndKM8vLkN9GBz3LIy2tmdHjlyqbzhj//PMUEZBGRQDQKp5wCv/iFf1QwLCJZJJUR4ZHARufcW865CuB+4Kz2bZa0xrp1TecNO+dHhwsLmwiIY3nDyWaiA5+ArNFhEUnF/Pm+ELpz/nH+/Ey3SESkViqBcD/g3bjXW4J1DYXM7GUze8zMjkpL66TFFizwcezeeyffp6rKB8TduycpGRybia6pVInY6LByh0VERCRHpRIIW4J1rsHrF4ABzrkhwH8CSxKeyKzEzFab2eqtW7e2qKGSulAIPvmk6SwHgF27fMng/fZLMri7cqW/Gy8/P/lJli3z25vMuRCRLmvyZF872Mw/Tp6c6RaJiNRKJRDeAhwY97o/8H78Ds657c65z4PnjwKFZrZvwxM550qdcyOccyP69u3bhmZLKmbP9t9GDhjQ9H5bt/rB3QMPTBAQl5T4IeSmEpBravwQc3GxZqUTkfpCIT+T3C23+EeVTxORLJJKIPwccJiZHWRmRcD5wMPxO5jZ/mZmwfORwXnL091YaZ1Nm/zAbnFx0/tt2eID4qKiBAO869Y1PzpcUeGHmPfcUwGxiNRRDWERyVLNBsLOuSrgJ8BSYD3wgHNurZldbmaXB7t9B3jVzF4G7gDOd841TJ+QDCop8akQ06YlrzscU1npB3jNoE+fuJg2NjqcbFq7mC++8AFxwohaRLoclU8TkSxlmYpXR4wY4VavXp2Ra4uvgLZwYcuO6d3bf5aVlOA/0E4/HT79tPkDzeDf/s1PhyfSSZjZ8865EZluR0dpdZ8djcLYsf4bo6IiTbEsIhmRrM/WzHJd1IIFPn+4ucHdeNu2+YFeM+h2SojpJZ/4dInCwqYPdM7fVGfmp2zWKLFI1xGJ+CC4uto/RiKZbpGISC0Fwl3c0qU+Tm2q/nAiu3cH6ROXlWCVFeRRzSiebf7AnTvr8i722ku5xCLtoLnZQOP2O87Mqs3sO+3WmHDYjwTn5/vHcLjdLiUi0lIKhAWoGyGeN8/PldFSjjxWMRqjGqOq3nIYrxHl+MYHbd8eN8TcTSPFImmQ6mygwX6z8fd/tJsoIc45Yi2j9lhD6YTHlBYhIllFgbDUU1Li41Pn/I11RUUtPUMekB88+mUjhzOaZxsFyH6p9I+7v8Dm3Mpe9gmlVgKjRqX7rYl0FanOBnolsBj4V3s1JBqFk0+qZslLA1m1/etctvBkSqe/2V6XExFpMQXCktTs2XUzo06a1HTltMYswZKXYKkfNG9nby5jHrZqBWZVmFUHSw1mJF0S1kAW6ZqanQ3UzPoB5wD3NHWitk6CFIlAVXV8HwCLH0w0R5OISGYoEJaULFjgK6fF0id6927pGRIFxskWaBwkG35Cw9hSX6wGclPBcrKloMBX0RDpJFKZDXQuMN05V93Uido6CVI4DAX59f/fTpygypoikj0UCEuLlZRAebkPimPLuHE+qEydS7JA6sFyelRX+1JyrQmiU11ULEM6ULOzgQIjgPvNbBO+Dvx/mdnZ6W5IKATLn8nn7JPLGdn/feZNe4uS2Yek+zIiIq2mQFjSYulSP9NyfHDcdIAcH9Q6oCZYnyxAbm7JbvHFMnJ1UfpJzmh2NlDn3EHOuYHOuYHAX4AfOeeWtEdjQiF46LY3WPmj+ZSc3W7pyCIiraJAWNpVsgC5/pKHc/lMm2YUFRk+KK4BquOeN7UOcj1QzgVtST9p6VJYqHSV1kpxNtCOE5tQ4/rr/aP+mhKRLKJAWLJG3c15+cFSgJs0BZdXhKMgWArjnvtlEn8knwqaDpyrEyySraqq2j9dpTMH2865R51zhzvnDnHO3RKsu8c51+jmOOfcxc65v7RXW6Lz32DWrmuIVh+nCTVEJOsoEJbstmCBT+J1DlasgP79G+/CFKroljBITrwuthgrCNGfzUAVdaPL0hXEgu3iYs3r0l6iURh77ySud//BWMqI5p+oCTVEJKsUZLoBIikLheDduKpQ06fD3Ll+lKm1p+SfvMvAxBt794ZZs/zdgW0wfTrccQfs2tWm00g7qajw87pAm3/V0kAkAhVV+VQDFWZELv1vQqEBmW6WSKtUVlayZcsWdqkzz2rdunWjf//+FBYWprS/OZeZ/MkRI0a41atXZ+Ta0kl1RMTZvTtceaXP4+hCLrwQFi3y+d6d1bhxPqc9VWb2vHNuRPu1KLu0ps+ORuGUU/wfG0VF8NRTmlhOctfbb79Nz5496dOnD9ayMknSQZxzlJeXs2PHDg466KB625L12UqNkM5j9mxfniH+TryRI9N7jUTlHzpzsmkgPkOlvZckGTDtbuLEjr9mV+DHWhyuqgrWrMl0c0RabdeuXQqCs5yZ0adPnxaN2isQls5t5cr6UVbrZgNpWrI7uw47THfIt0IsA6Y9g+3YP4O8PP84b57SItpDJALVVQ7njOpqR+THf9b/CclpCoKzX0t/RwqEpWtJNBvItGnQrVv6r7VxY+N6Y3l5MGpU+q8lLRL7Z1Bd7R8VBLePcBiK8qvIp5IiKgnXPKmqESKtVF5eztChQxk6dCj7778//fr1q31d0cy9MqtXr+aqq65q8TVffPFFzIylLckbyzEKhEUSpVRMmgT5+em/lnOwalXj0eO99lLpAumUxoc+41h7kbl2DaHiF1Q1QqSV+vTpw0svvcRLL73E5ZdfzjXXXFP7uqioiKqqqqTHjhgxgjvuuKPF11y0aBEnnngiixYtakvTs5oCYZFEFizwKQ8dMXIMsH27L12g9ArpJKJRH/MuWd6HVe44rrI7ic5dqbvlpGuJRn31oXbqxy+++GJ++tOfcsoppzB9+nRWrVrF6NGjGTZsGKNHj2bDhg0ARCIRvvWtbwFw0003cemllxIOhzn44IOTBsjOOf7yl79w3333sWzZsnp5t3PmzGHw4MEMGTKEa6+9FoCNGzdy6qmnMmTIEIYPH86bb77ZLu853VQ+TSRVs2c3rhZRWgozZsC2be1zzVh6Rby8PDj11JaVOBDpYJEIVFY6/DTqUFGTR+TFXigMli4jNqtirGxKWVm7/CH4+uuv88QTT5Cfn8/27dtZvnw5BQUFPPHEE1x33XUsXry40TGvvfYaTz31FDt27OCII47giiuuaFRu7Nlnn+Wggw7ikEMOIRwO8+ijjzJhwgQee+wxlixZwsqVK+nRowfbgs+/SZMmce2113LOOeewa9cuanKkzJBGhEXaIlHOcSy1Iq+d/nvV1MCyZY1HjwsKOn31Cskd4TAUWDWxac4LqCbM0xlulUgHikR8EFxd3a6zKp577rnkB6l8n332Geeeey5HH30011xzDWvXrk14zBlnnEFxcTH77rsv++23Hx999FGjfRYtWsT5558PwPnnn1+bHvHEE09wySWX0KNHDwB69+7Njh07eO+99zjnnHMAX8s3tj3bKRAWaQ/J6o2NG+eD1vZQXZ24ekWPHr7GskgHcw1f9eqVoZaIZEA47EeC8/P9Yzvlx++xxx61z6+//npOOeUUXn31VR555JGkZcSKi4trn+fn5zfKL66urmbx4sXcfPPNDBw4kCuvvJLHHnuMHTt24JxrVJkhU3NSpIMCYZGOtHSpH9HtqNxjSFz72AwOPFD5x9JuIhGorsnDp0YYVRQQeWnvzDZKpCOFQj4dYubMdkuLaOizzz6jX79+ANx3332tPs8TTzzBkCFDePfdd9m0aRObN29m4sSJLFmyhHHjxvGHP/yBL7/8EoBt27bRq1cv+vfvz5IlSwDYvXt37fZsp0BYJNMSVa1o79FjgC1bGpd3U3qFpEk4DIX5NcRSI4qoJDz008w2SqSjhUL+PpIOukl02rRpzJgxgxNOOIHq6upWn2fRokW1aQ4xEydO5E9/+hPf/OY3OfPMMxkxYgRDhw7lV7/6FQB//OMfueOOOzjmmGMYPXo0H374YZveS0fRFMsiuSQahSlT4I03Ova6vXv7O59VcLeWplhuXvSK+cy/5wsAJtsCQrd8ywcFIjlo/fr1DBo0KNPNkBQk+l1pimWRziAUgtdf7/h5ibdta1zeTZODSDNCkw/j7uJruNt+TKjoedUQFpGso0BYpDNINi9xe+Yfa3IQSUXsW8ccvplGRDovBcIinVmy/OP2LO+WbHIQVa/oeubPh8pK/2+uqkrTK4tI1lEgLNIVJSrv1t7pFcmqV5hBnz4aRe5solH43e/qRoJravzvWUQkiygQFhEvWXrFpEm+DmZ7SpSDHMtDHj++fa8t7SMS8X9sxSsvz0hTRESSUSAsIk1bsMB/rZ2ovFt7cy7xLHoq9Zb9wmGIn7K1uFg3y4lI1lEgLCKts3Rp4pvzioo65vrJZtIz8zcIKh85s0IhPyp8+eV+eeqpDqulKtIZhcNhli5dWm/d3Llz+dGPftTkMbGyh6effjqffvppo31uuumm2lrAySxZsoR169bVvr7hhht44oknWtD6pl199dX069ePmpqatJ0zVQqERSR9Zs+G3bs7tnpFIrt3J89HVrpFxwmF4O67/aIgWKRNLrjgAu6///566+6//34uuOCClI5/9NFH2XvvvVt17YaB8M0338ypp57aqnM1VFNTw0MPPcSBBx7I8uXL03LOllAgLCLtL1n1io7KQY7XMN1CN+q1n2jUT8Siqbyli0rnf4HvfOc7/O1vf2P37t0AbNq0iffff58TTzyRK664ghEjRnDUUUdx4403Jjx+4MCBfPzxxwDccsstHHHEEZx66qls2LChdp//9//+H8cddxxDhgxh4sSJfPnll6xYsYKHH36Yn//85wwdOpQ333yTiy++mL/85S8AlJWVMWzYMAYPHsyll15a276BAwdy4403Mnz4cAYPHsxrr72WsF1PPfUURx99NFdccQWLFi2qXf/RRx9xzjnnMGTIEIYMGcKKFSsAmD9/PscccwxDhgzhoosuauNPVYGwiGRashxk52DkyPa/fuxGPQXD6RWNwtixcP31/lHBsHQx6f4v0KdPH0aOHMnjjz8O+NHg8847DzPjlltuYfXq1bzyyis8/fTTvPLKK0nP8/zzz3P//ffz4osv8uCDD/Lcc8/VbpswYQLPPfccL7/8MoMGDeL3v/89o0eP5swzz+T222/npZde4pBDDqndf9euXVx88cX8z//8D2vWrKGqqoq77767dvu+++7LCy+8wBVXXJE0/WLRokVccMEFnHPOOfztb3+jsrISgKuuuooxY8bw8ssv88ILL3DUUUexdu1abrnlFp588klefvllfvvb37bpZwoKhEUkm61cmThAbo9Sb4sXp/d8XV0kAhUVPpe7okI1hKXLaY//AvHpEfFpEQ888ADDhw9n2LBhrF27tl4aQ0PPPPMM55xzDj169KBXr16ceeaZtdteffVVTjrpJAYPHszChQtZu3Ztk+3ZsGEDBx10EIcffjgAU6ZMqZfeMGHCBACOPfZYNm3a1Oj4iooKHn30Uc4++2x69erFqFGjWLZsGQBPPvkkV1xxBQD5+fnstddePPnkk3znO99h3333BaB3795Nti8VCoRFJPckK/XmHMybBz17tvycEyemv51dWTjsb5zMz/ePqhghXUx7/Bc4++yzKSsr44UXXmDnzp0MHz6ct99+m1/96leUlZXxyiuvcMYZZ7Br164mz2NmCddffPHF3HnnnaxZs4Ybb7yx2fO4ZmaMLC4uBnwgW1VV1Wj7448/zmeffcbgwYMZOHAg//jHP+qlRyS6XrK2t5YCYRHpXEpK/Ox2iYLkRGXfevf2wXNJSWba21mFQlBWBjNn+kfdLCddTHv8F9hzzz0Jh8NceumltaPB27dvZ4899mCvvfbio48+4rHHHmvyHCeffDIPPfQQO3fuZMeOHTzyyCO123bs2MEBBxxAZWUlCxcurF3fs2dPduzY0ehcX//619m0aRMbN24E4I9//CNjxoxJ+f0sWrSI3/3ud2zatIlNmzbx9ttvs2zZMr788kvGjh1bm2ZRXV3N9u3bGTt2LA888ADlQU3ybdu2pXytZArafAYRkVzSoPyQtKNQSAGwdGnt8V/gggsuYMKECbUpEkOGDGHYsGEcddRRHHzwwZxwwglNHj98+HDOO+88hg4dyoABAzjppJNqt82cOZNRo0YxYMAABg8eXBv8nn/++fzwhz/kjjvuqL1JDqBbt27ce++9nHvuuVRVVXHcccdx+eWXp/Q+vvzyS5YuXcq8efNq1+2xxx6ceOKJPPLII/z2t7+lpKSE3//+9+Tn53P33XcTCoX4xS9+wZgxY8jPz2fYsGHcd999qf7oErLmhrXby4gRI1ystp2ISK4xs+edcyMy3Y6Ooj5burr169czaNCgTDdDUpDod5Wsz1ZqhIiIiIh0SQqERURERKRLUiAsIiIiIl2SAmERERGRFGTqvipJXUt/RwqERURERJrRrVs3ysvLFQxnMecc5eXldOvWLeVjVD5NREREpBn9+/dny5YtbN26NdNNkSZ069aN/i2YeVSBsIiIiEgzCgsLOeiggzLdDEkzpUaIiIiISJekQFhEREREuiQFwiIiIiLSJWVsimUz2wpsbsWh+wIfp7k5baU2pUZtSo3a1LxsaM8A51zfDLehw6jPbndqU2rUptSoTY0l7LMzFgi3lpmtTjRXdCapTalRm1KjNjUv29ojyWXj70ptSo3alBq1KTXZ2CZQaoSIiIiIdFEKhEVERESkS8rFQLg00w1IQG1KjdqUGrWpednWHkkuG39XalNq1KbUqE2pycY25V6OsIiIiIhIOuTiiLCIiIiISJvlTCBsZt80sw1mttHMru3A6x5oZk+Z2XozW2tmVwfre5vZ/5rZG8HjPnHHzAjaucHMxrdj2/LN7EUz+1s2tMnM9jazv5jZa8HPK5QFbbom+L29amaLzKxbR7fJzP5gZv8ys1fj1rW4DWZ2rJmtCbbdYWaW5jbdHvzuXjGzh8xs70y3KW7bz8zMmdm+HdkmaZtM9Nvqs1vUHvXZidugPruVbYrbljt9tnMu6xcgH3gTOBgoAl4Gjuygax8ADA+e9wReB44E5gDXBuuvBWYHz48M2lcMHBS0O7+d2vZT4E/A34LXGW0T8N/AD4LnRcDemWwT0A94G+gevH4AuLij2wScDAwHXo1b1+I2AKuAEGDAY8BpaW7TOKAgeD47G9oUrD8QWIqvYbtvR7ZJS5v+3Wek30Z9dkvaoz47cTvUZ7eyTcH6nOqzc2VEeCSw0Tn3lnOuArgfOKsjLuyc+8A590LwfAewHv+f9Sx8J0LweHbw/Czgfufcbufc28DGoP1pZWb9gTOA38WtzlibzKwX/j/F7wGccxXOuU8z2aZAAdDdzAqAHsD7Hd0m59xyYFuD1S1qg5kdAPRyzkWd7znmxx2TljY555Y556qCl/8E+me6TYHfANOA+BsaOqRN0iYZ6bfVZ6fcHvXZSajPbn2bAjnVZ+dKINwPeDfu9ZZgXYcys4HAMGAl8BXn3AfgO15gv2C3jmrrXPw/tJq4dZls08HAVuDe4Ku/35nZHplsk3PuPeBXwDvAB8BnzrllmWxTnJa2oV/wvCPaBnAp/i/zjLbJzM4E3nPOvdxgU7b8nCS5jPfb6rObpD67ZdRnpyAX++xcCYQT5Yt0aLkLM9sTWAxMdc5tb2rXBOvS2lYz+xbwL+fc86kekmBdun9+BfivSO52zg0DvsB/fZSxNgU5XGfhv4b5KrCHmV2YyTalIFkbOqxtZvYLoApYmMk2mVkP4BfADYk2Z6JN0iIZ/V2oz26W+uz0yHhfpD67bXIlEN6CzzmJ6Y//uqRDmFkhvkNd6Jx7MFj9UTCkT/D4rw5s6wnAmWa2Cf914zfMbEGG27QF2OKcWxm8/gu+k81km04F3nbObXXOVQIPAqMz3KaYlrZhC3Vfe7Vb28xsCvAtYFLwNVUm23QI/gPx5eDfen/gBTPbP4NtktRlrN9Wn50S9dktoz67ebnZZ7c0qTgTC/4v17fwP+DYTRdHddC1DZ+zMrfB+tupnzg/J3h+FPUTwt+inW68CK4Xpu7Gi4y2CXgGOCJ4flPQnoy1CRgFrMXnmRk+r+vKTLQJGEj9mxxa3AbgOeB46m4oOD3NbfomsA7o22C/jLWpwbZN1N140WFt0tLq32VG+m3UZ7ekLeqzk7elYf+oPjuFNjXYtokc6LM77EJp+Ed5Ov7u3zeBX3TgdU/ED9O/ArwULKcDfYAy4I3gsXfcMb8I2rmBdr77kfqdakbbBAwFVgc/qyXAPlnQpv8AXgNeBf4Y/Cfs0DYBi/D5bpX4v36/35o2ACOC9/EmcCfBhDhpbNNGfA5X7N/5PZluU4Ptmwg61Y5qk5Y2/9vv8H4b9dktactQ1GcnaoP67Fa2qcH2TeRAn62Z5URERESkS8qVHGERERERkbRSICwiIiIiXZICYRERERHpkhQIi4iIiEiXpEBYRERERLokBcIiIiIi0iUpEBYRERGRLkmBsIiIiIh0Sf8fmJmAejIUFfkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_2.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(range(n), (run_hist_2.history[\"accuracy\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_accuracy\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy is 0.766\n",
      "roc-auc is 0.830\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
    "y_pred_class_nn_2 = (y_pred_prob_nn_2>0.5).astype(int)\n",
    "print('')\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning Foundation (C) 2020 IBM Corporation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
